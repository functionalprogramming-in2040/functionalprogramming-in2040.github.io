<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2024-09-12T10:26:15+02:00</updated><id>/feed.xml</id><title type="html">IN2040 FP</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><author><name> </name></author><entry><title type="html">Recursion, primitive or otherwise</title><link href="/functionalprogramming/2024/09/12/ackermann.html" rel="alternate" type="text/html" title="Recursion, primitive or otherwise" /><published>2024-09-12T00:00:00+02:00</published><updated>2024-09-09T09:00:00+02:00</updated><id>/functionalprogramming/2024/09/12/ackermann</id><content type="html" xml:base="/functionalprogramming/2024/09/12/ackermann.html"><![CDATA[<p>The SICP textbook shows in <strong>Exercise 1.10</strong> a famous function known as <strong>Ackermann’s function</strong>. Actually the code there shows one version of that function; there are minor variations of it, all doing basically the same, and all known as Ackermann function. The exercise is not on the list of exercises officially discussed in the group sessions, but perhaps you have stumbled upon it or the group teacher discusses it.</p>

<p>As said, the function is very well known, and it’s always discussed in connection with a concept called primitive recursion (and also that is not on the pensum of the lecture). So if one reads about primitive recursion, invariably the Ackermann function is mentioned and if the Ackermann function is discussed, then it’s discussed in connection with primitive recursion, namely pointing out that Ackermann’s function is not primitive recursive. Actually, Exercise 1.10 in SICP is an exception to that rule, it gives the definition of the function and asks to observe how it behaves but does not mention primitive recursion.</p>

<h1 id="primitive-recursion">Primitive recursion</h1>

<p>Ackermann’s function is the first and most prominent example of a terminating function which is not primitive recursive. That is largely the reason why it is famous. It’s also known as example for a function that grows extremely fast (that can be observed by playing around with it in Exercise 1.10). Both facts hang together; abstractly speaking, it grows too fast for any possible primitive-recursive function, while still terminating. The function is not famous for being practically useful. Also for that it grows too fast.</p>

<p>So if one has ever heard of the Ackermann function at all, it’s probably exactly for that: it’s <strong>“the”</strong> example of a function that is not primitive recursive. Also googling around in the internet, starting maybe at Wikipedia and at various different other pages that offer wisdom and answers on various questions, will confirm that. You can look for questions like “What is an example of a total function that is not primitive recursive?” (answer “Ackermann”) or “what’s the Ackermann function” (answer: an example for a non-primitive-recursive function), and on and on.</p>

<p>Alright, got it, Ackermann is not primitive recursive.</p>

<div class="org-center">
<p>
<b>But that's actually not true!</b>
</p>
</div>

<p>Or maybe I should be more modest. It’s true under only under assumptions taken for granted and left often unmentioned. It’s an assumption that maybe never even crosses the mind of people who just “know” that Ackermann is not primitive-recursive and people who write web-pages explaining Ackermann, that in fact there <strong>is</strong> a restriction.</p>

<p>Participants of a course on functional programming, however, may not suffer from or at least should not suffer from that blind spot. What unspoken restriction are we talking about? I come to that in a moment, but before that, we need at least sketch what is actually meant by primitive recursion.</p>

<h3 id="primitive-recursive-functions">Primitive recursive functions</h3>

<p>General <strong>recursion</strong> is ubiquitous in the lecture, most functions halfway interesting use recursion. Primitive recursive functions are a restricted class of recursive functions. We don’t bother to give a precise definition of the concept; it’s easy to find it explained on the internet.</p>

<p>You will remember that SICP distinguishes between recursive procedures and recursive (resp. iterative) <em>processes</em>, where processes refers to what happens at run-time. Let’s focus on what the book calls “procedures”, the code representation, not the processes.</p>

<p>A recursive procedure is one that calls itself in its body. There is also indirect or mutual recursion, which is a situation where two or more procedures call each other; in software engineering circles that’s also sometimes called a “call-back” situation. Never mind. There are no restrictions on how procedures can recursively call themselves (or each other). In other words, Scheme and Lisp (and most other modern languages) support recursion in its general form, unrestricted.</p>

<p>One can use recursion to easily come up with functions that don’t terminate. The simplest example is the one from <strong>Exercise 1.5</strong>, which does in fact nothing else than recursively calling itself (and thus will never terminate):</p>

<div class="language-lisp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="nv">define</span> <span class="p">(</span><span class="nv">p</span><span class="p">)</span> <span class="p">(</span><span class="nv">p</span><span class="p">))</span>
</code></pre></div></div>

<p>One can then study restrictions on the use of recursion. One example is known as <strong>tail recursion</strong>. The book and the lecture uses that term in connection with the interpreter, stating that the scheme interpreter is an example of a <strong>tail recursive interpreter</strong>. More conventionally, one calls functions or procedures <strong>tail recursive</strong> and that characterizes functions, procedures, methods etc. which call themselves only “`at the end” of their body. In the terminology of SICP, that leads to an <em>iterative process</em>, not a <em>recursive process</em> (at least in an interpreter that knows how to deal with it adequately and efficiently).</p>

<p>So, a tail-recursive procedure is a restricted form of a recursive procedure.</p>

<p>But now to the restriction on recursion called <strong>primitive</strong>. The exact definition of primitive recursive functions involves fixing allowed elementary constructs, and projections and other details. The core of the concept, however, is the way recursion itself is allowed. It can be roughly stated as</p>

<blockquote>
  <p>A function can call itself recursively, but only on smaller arguments.</p>
</blockquote>

<p>Instead of giving the formal definition of the primitive recursion operator, we give a feeling what’s allowed and what’s not allowed by small examples. Primitive recursive functions are classically defined as functions on <strong>natural numbers</strong> as arguments and as return value. For that, being smaller is pretty obvious. Let’s look at the following function <code class="language-plaintext highlighter-rouge">f</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(define (f x y)
  (if (= x y) y
      (+ (f (+ x 1) y) 1)))

</code></pre></div></div>

<p>The function is supposed to take 2 natural numbers as argument. Additionally, let’s assume the argument for <code class="language-plaintext highlighter-rouge">x</code> is smaller or equal than <code class="language-plaintext highlighter-rouge">y</code>. Otherwise the corresponding process would not terminate. That’s a minor point, we can of course easily add a couple of lines, checking first whether the assumption is true, and if not, doing analogous calculation to cover also that situation, making it terminating for arbitrary natural numbers. But that’s not central to the discussion here.</p>

<p>Now, <code class="language-plaintext highlighter-rouge">f</code> is recursive, calling itself (and it’s not tail-recursive). Now, is the function primitive-recursive? The definition of <code class="language-plaintext highlighter-rouge">(f x y)</code> calls itself with <code class="language-plaintext highlighter-rouge">(f (+ x 1) y)</code> and that is <strong>forbidden</strong> in primitive recursive schemes. So does that mean the function is not primitive recursive?</p>

<p>Not so fast. The way it’s defined is certainly not the primitive-recursive way But in the same way, that one may transform non-tail-recursive procedure definitions into tail-recursive ones (the lecture had examples for that), one may reformulate sometimes non-primitive-recursive definitions so that they fit the schema. What function is it anyway, given above? It’s easy enough, it calculates <code class="language-plaintext highlighter-rouge">2y - x</code> (for <code class="language-plaintext highlighter-rouge">x</code> $\leq$ <code class="language-plaintext highlighter-rouge">y</code>).</p>

<p>It turns out that this function indeed is primitive-recursive, in that one can easily define it using primitive recursion schemes. Indeed, it’s straightforward since one can define multiplication and addition and minus easily via primitive recursion. Defining the calculation <code class="language-plaintext highlighter-rouge">2y-x</code> this way seems more natural than the slightly weird recursive definition where <code class="language-plaintext highlighter-rouge">f</code> calls itself on <code class="language-plaintext highlighter-rouge">(+ n 1)</code>, but the definition was given to illustrate what is <em>not</em> allowed.</p>

<p>To illustrate what <em>is</em> allowed, let’s sketch how addition of two natural numbers can be defined with primitive recursion. Actually, it corresponds to the most straightforward definition of addition (assuming that the successor function is given as a more basic operation, here written as <code class="language-plaintext highlighter-rouge">+1</code>. So <code class="language-plaintext highlighter-rouge">x +1</code> is not meant as using binary addition on <code class="language-plaintext highlighter-rouge">x</code> and 1 as arguments, but calculating the successor of <code class="language-plaintext highlighter-rouge">x</code>. We also use infix notation and equations, not Lisp-like prefix and code, though one easily could).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   0   + y = 0
(x +1) + y = (x + y) +1
</code></pre></div></div>

<p>The primitive recursion schema generally specifies a <strong>base case</strong> (the first line in the above example) and an <strong>induction</strong> case (the second line). In the case of addition, to define <code class="language-plaintext highlighter-rouge">(x +1) + y</code>, the recursion scheme can use on the right-hand side of the equation a function <code class="language-plaintext highlighter-rouge">h</code> that takes three arguments, and allowed as arguments are <code class="language-plaintext highlighter-rouge">x</code> <code class="language-plaintext highlighter-rouge">y</code>, and <code class="language-plaintext highlighter-rouge">(x + y)</code>. Besides it could rely on earlier defined functions and some primitive operations. In our very simple example, the <code class="language-plaintext highlighter-rouge">x</code> and <code class="language-plaintext highlighter-rouge">y</code> are not needed in the construction, <code class="language-plaintext highlighter-rouge">x + y</code> is the only relevant part and the successor function <code class="language-plaintext highlighter-rouge">+1</code> is built-in. (NB: to avoid confusion: the values of <code class="language-plaintext highlighter-rouge">x</code> and <code class="language-plaintext highlighter-rouge">y</code> are not needed individually and directly as argument to the function <code class="language-plaintext highlighter-rouge">h</code>, but of course they are needed indirectly in that their sum <code class="language-plaintext highlighter-rouge">x + y</code> is used).</p>

<p>So addition is defined recursively in that the definition calls itself, and under the restriction that for defining the outcome for <code class="language-plaintext highlighter-rouge">x+1</code> in the induction case, only <code class="language-plaintext highlighter-rouge">x+y</code> is used, not an arbitrary recursive call to plus.</p>

<p>The question then is:</p>

<blockquote>
  <p>Are all recursive functions also representable by primitive recursion. Or is being primitive recursive a restriction?</p>
</blockquote>

<p>The answer is <strong>yes</strong>, it’s a restriction for sure. All primitive recursive functions terminate, which is a consequence of the fact that the recursion calls the function on a smaller argument. On the other hand, general recursion easily allows non-terminating procedures. Earlier in this post, there was a minimal example for that.</p>

<h3 id="why-is-ackermann-not-primitive-recursive-in-the-standard-set-up">Why is Ackermann not primitive recursive (in the standard set-up)?</h3>

<p>So far so good. We got a feeling that being primitive is a restriction on general recursion. To see that the Ackermann function is not primitive recursive is not obvious. Note that it’s not good enough to observe that its definition does not follow the required primitive-recursive schema: One has to make the argument that it cannot somehow be written up in a different way that fits the scheme.</p>

<p>Generally speaking, the Ackermann function is not primitive-recursive as it <strong>“grows too fast”</strong>. We don’t provide the argument formally, but the idea is quite simple. Looking at the primitive recursive schema sketched above, it has the feel of an <strong>iterative loop</strong> with a fixed <strong>bound</strong>, like <code class="language-plaintext highlighter-rouge">for i = 0 to n do ...</code>. Programming with for-loops with a fixed bound results in terminating programs, analogous to the fact that all primitive-recursive programs are terming. That’s in contrast to programs using general “while” loop, resp. programs using general recursion.</p>

<p>A primitive recursive definition builds a new function using the primitive recursion schema corresponding to a for-loop iteration and using earlier defined primitive recursive functions as building block, which themselves are iterative schemes. That corresponds to a stack of nested iteration loops.</p>

<p>For illustration: as we have seen, addition can be defined using the successor function iteratively. One could continue to define multiplication as iterative addition. And exponentiation as iterated multiplication. SICP shows how that’s done in Scheme, though without mentioning that the recursions and iterations could be classified as “primitive” (see Sections 1.1.3 and 1.1.4)</p>

<p>At any rate, taking the successor function as basic, multiplication can be represented by one loop (or using one primitive recursion scheme), exponentiation using 2 nested loops, and one could continue with iterated exponentiation, and then iterate that, piling up layer after layer of looping in a nested fashion, each layer really adds expressiveness (and the potential of faster growing functions).</p>

<p>So, using only such bounded loops for programming then leads to a <strong>hierarchy</strong> of functions. Those programmable with a nesting depth of at most one (like multiplication), one with a nesting depth of 2 (for example, exponentiation), etc., all programs terminating. It can be shown that this hierarchy is <strong>infinite</strong>. In other words, it’s not that there is some maximal looping depth, after which one does not need further nesting.</p>

<p>But where does Ackermann fit in?</p>

<blockquote>
  <p><strong>Well, that’s the point: Ackermann does NOT fit into this looping hierarchy!</strong></p>
</blockquote>

<p>Ackermann’s function comes in different flavors, the one from Exercise 1.10 has 2 arguments and it’s not even the one most commonly found. There are also versions with 3 arguments and for the line of argument here, let’s assume for now we have a 3-argument formulation.</p>

<p>In all formulations, the Ackermann function has one argument that corresponds roughly to the nesting level of iterative loops resp. the amount of primitive-recursive schemes. So <code class="language-plaintext highlighter-rouge">Ack(x,y,1)</code> corresponds to one looping level, and in a properly formulated 3-argument version, <code class="language-plaintext highlighter-rouge">Ack(x,y,1)</code> is <code class="language-plaintext highlighter-rouge">x+y</code> (Wikipedia starts counting at 0 instead of 1, but never mind). Continuing like that, <code class="language-plaintext highlighter-rouge">Ack(x,y,2)</code> is exponentiation <code class="language-plaintext highlighter-rouge">exp(x, y)</code> etc. This is the <strong>core</strong> of Ackermann’s idea: Define a function where one argument controls the nesting-depth of loops or the level of primitive-recursive schemes.</p>

<p>And that immediately shows that Ackermann cannot be primitive-recursive. If it were, it could be written using a fixed amount of for-loops or a given amount of primitive-recursive schemes. But that’s impossible, since we said, the hierarchy of looping constructs is a real hierarchy, each new level of nesting really adds a new class of functions. Thus, <code class="language-plaintext highlighter-rouge">Ack</code> cannot fit into any specific layer, say level <code class="language-plaintext highlighter-rouge">m</code>, since <code class="language-plaintext highlighter-rouge">Ack(x,y,m+1)</code> would have to live in level <code class="language-plaintext highlighter-rouge">m+1</code>. This was meant when stating at the start of the post, that <code class="language-plaintext highlighter-rouge">Ack</code> grows too fast to be primitive recursive. Each layer limits the order of growth of functions inside that layer, but one argument of the Ackermann function, the one we called <code class="language-plaintext highlighter-rouge">m</code>, controls the growth rate of Ackermann, and since it’s the input of the function, we can make Ackermann’s function growing arbitrarily fast and in fact <strong>too fast</strong> to fit into any specific layer.</p>

<h3 id="wait-a-second-wasnt-that-a-convincing-argument-that-ackermann-is-not-primitive-recursive">Wait a second, wasn’t that a convincing argument that Ackermann is not primitive recursive?</h3>

<p>Indeed, that was the outline of the standard proof showing that Ackermann is <strong>not</strong> primitive recursive, and hopefully it was convincing. But then, why the claim that Ackermann <strong>can</strong> be captured primitive-recursively, it sure can’t be both ways?</p>

<p>The classic definition and the argument outlined here can be done more formally, exactly specifying what functions to use as primitive building blocks (basically successor and projection functions) and fixing exactly the format of the primitive recursion schema (which we only sketched here on using addition as very simple example). In its standard form, primitive recursion is used to define functions over natural numbers. So functions that take natural numbers as input, and return a natural number. For instance, the Ackermann function <code class="language-plaintext highlighter-rouge">Ack(x,m)</code> is a function of that type. (BTW: Let’s switch back to a two-argument version of Ackermann, but it is not crucial for what’s being said.) So this two argument Ackermann function is of type <code class="language-plaintext highlighter-rouge">Nat * Nat -&gt; Nat</code>, and the functions definable by primitive recursion are of type <code class="language-plaintext highlighter-rouge">Nat * Nat * ... * Nat -&gt; Nat</code> (though as argued, <code class="language-plaintext highlighter-rouge">Ack</code> is not definable by primitive recursion, but it would be at least of a fitting type.)</p>

<p>In this and the whole construction and set-up lies a <strong>restriction</strong>, though one that is seldom drawn attention to. Namely not only that we focus on functions over natural numbers (which is not a real restriction), but that we are dealing with <strong>first-order functions</strong> (over natural numbers)!</p>

<p>Ah, well, yaah, now that you mention it…</p>

<p>Is this important, are <strong>higher-order</strong> functions something to consider? Some may consider them as curious anomalies, but in a course about functional programming one sure is comfortable with higher-order functions, they are the bread and butter of functional programming. If embracing higher-order functions, instead of struggling to encode the first-order Ackermann function of type <code class="language-plaintext highlighter-rouge">Nat * Nat -&gt; Nat</code> primitive-recursively (and fail), we can look at Ackermann as a function of type <code class="language-plaintext highlighter-rouge">Nat -&gt; Nat -&gt; Nat</code>. That’s the type of a higher-order function. It’s a function that takes a natural number as argument and returns a function (of type <code class="language-plaintext highlighter-rouge">Nat -&gt; Nat</code>).</p>

<p>With this type, it’s not really the <em>same</em> function: one cannot use one version as drop-in replacement for the other. But it can be seen still as conceptionally the same function. It’s indeed easy to transform any function of type <code class="language-plaintext highlighter-rouge">A * B -&gt; C</code> into a function of type <code class="language-plaintext highlighter-rouge">A -&gt; B -&gt; C</code> and reversely. Actually, it’s not just easy to do the transformation manually, one can also easily write two functions that implement those two transformations. The transformations are known as <strong>currying</strong> and <strong>uncurrying</strong> in honor of <a href="https://en.wikipedia.org/wiki/Haskell_Curry">Haskell Brooks Curry</a> (that’s the name of a person, but of course there are also functional programming languages named after him, Haskell and the lesser known Brooks and Curry. In particular, Brooks is rather marginal. Note that Wikipedia in the article about H. Curry confuses the languages Brooks and Brook).</p>

<p>Now, with this switch of perspective and freeing one’s mind from the unspoken assumption that functions need to be first-order, one can observe:</p>

<blockquote>
  <p>With higher-order functions (and currying), <strong>Ackermann’s function can be defined by primitive recursion</strong>!</p>
</blockquote>

<p>That’s known, but I think it’s fair to say, it’s much lesser known than the common knowledge that “Ackermann is not primitive recursive.” For instance, when using Wikipedia as the great one-stop source of universal wisdom and reading up on <a href="https://en.wikipedia.org/wiki/Ackermann_function">Ackermann function</a>, one get’s a quite detailed exposition including introducing primitive recursion and discussing variations of the function and other technical background, but it’s never even mentioned that the <strong>curried version of Ackerman is primitive-recursive!</strong></p>

<p>Let’s wrap it up and simply show the primitive-recursive definition for (a version of) Ackermann. It corresponds to a two argument version of Ackermann, i.e., the uncurried, first-order version would have two arguments. The higher-order version has one argument, but gives back a function. Here it is:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ack(0)       = succ
Ack(m+1)     = Iter(Ack(m))

Iter(f)(0)   = f(1)
Iter(f)(m+1) = f(Iter(f)(m))
</code></pre></div></div>

<h3 id="how-to-do-that-in-scheme">How to do that in Scheme?</h3>

<p>Ackermann can be defined in Scheme using general recursion; Exercise 1.10 in SICP shows a straightforward piece of code for that. Can one encode it primitive-recursively in Scheme, as well? Well, Scheme sure supports <strong>higher-order functions</strong> and it supports <strong>currying</strong> (defining functions using lambda-abstractions). Thus one can quite easily translate the above primitive-recursive definition into Scheme, and that is left as an exercise…</p>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="functional programming" /><category term="IN2040" /><category term="scheme" /><category term="lisp" /><category term="Ackermann" /><category term="currying" /><category term="higher-order functions" /><category term="recursion" /><category term="primitive recursion" /><summary type="html"><![CDATA[A lesser known fact on Ackermann's function, and the power of higher-order functions]]></summary></entry><entry><title type="html">Processes and procedures</title><link href="/functionalprogramming/2024/09/09/processprocedure.html" rel="alternate" type="text/html" title="Processes and procedures" /><published>2024-09-09T00:00:00+02:00</published><updated>2022-10-10T00:00:00+02:00</updated><id>/functionalprogramming/2024/09/09/processprocedure</id><content type="html" xml:base="/functionalprogramming/2024/09/09/processprocedure.html"><![CDATA[<p>Previous semester I got feedback that the concepts of processes vs procedures and functions remained shady and a bit unclear (at least for some). Thus I write a few lines on that. I won’t repeat the examples and sentences from SICP; there is Section 1.2 (“Procedures and the processes generate”) which is intended to clarify the matter. Instead I “talk around” the concepts a bit.</p>

<p>To start with, it’s partly a terminology question, a question about (the use of) words. Using the correct words and using words correctly is of course important, one needs to know the technical terms to communicate efficiently and understand texts. But terminology is only useful up-to a point, and words may not and cannot be used 100% precisely; natural language is not as precise like a mathematical definition or a piece of code, so there is always some slack.</p>

<p>Additionally, different communities may use words differently. That applies also to the concepts discussed here, in particular “function” and “procedures”. In other programming languages, even in other Lisp/Scheme material, the words may be used slightly differently. In general, not only is Scheme a language that differs in many ways from many other languages, but the book SICP is partly quite idiosyncratic in its use of words, i.e., it makes choices sometimes to use words different from what the (programming languages) world outside the book does. Examples for that is the narrow definition of “tail-recursion” and the (non-)use of the word of “closures”. However, the book is <strong>consistent</strong> and <strong>clear</strong> in its choices and uses its words carefully.</p>

<h1 id="procedures-and-processes">Procedures and processes</h1>

<p>Now, what’s procedures and processes? Those are different concepts and can be discussed in connection with every programming language. Whether elsewhere they call the concept “procedure” or whether they discuss “processes” at all is a separate question. One can learn a language and to use it and solve problems without thinking about it, at least to some extent. Still, as long as the programming language one is studying is real in the sense of being run on a computer (interpreted on an interpreter or on a virtual machine or also compiled and then run), the concept of process exist:</p>

<blockquote>
  <p>a <strong>process is a (representation of a) piece of code under execution</strong></p>
</blockquote>

<p>and here, in this section, the code is arranged in a functional manner based on procedures. When saying the code is under execution, it’s not literally meant that the syntax of the program is transformed as it seems to be the case in the illustrations of the substitution model in the section discussing processes and procedures. It can also mean, that the code has been compiled to some machine code (in a compiled language), and it’s the machine code that is actually being run (as or in a process). Or some byte-code corresponding to the user code is run on a virtual machine, etc.</p>

<p>The discussion about processes and procedures is done in connection with recursion, in particular distinguishing between <strong>linear recursion</strong>, <strong>tail recursion</strong>, and <strong>tree recursion</strong>. That is done by looking at how corresponding pieces of code, the procedures, are <strong>“run”</strong>. That means, how they are <strong>evaluated</strong>. A procedure being run (or executed or evaluated) corresponds to a <strong>process</strong>. That’s why section 1.2 in SICP is also called “procedures and processes they generate”. And that’s why I said all programming languages will have the concept of “processes”, whether they use that particular word, or whether they discuss at all what happens when a program is run does not matter. As long as a piece of code is run, there is a <strong>run-time entity</strong> which we call process.</p>

<p>While other textbooks may do their presentation without mentioning of processes, SICP does. One should also keep in mind that the title of the book is not called “An introductory course to Scheme programming”, but “<strong>Structure and interpretation of computer programs</strong>”, so one important part is not just to learn Scheme, or to just learn to program in a functional way, but also to understand how programs are executed, in particular interpreted, i.e., run on an interpreter.</p>

<p>The pictures in Section 1.2 SICP are of course exactly that: pictorial representations (SICP also uses the word “visualization”) of what’s going on when a procedure (here <code class="language-plaintext highlighter-rouge">fac</code>, and the iterative version of <code class="language-plaintext highlighter-rouge">fac</code> and finally <code class="language-plaintext highlighter-rouge">fib</code>) is run. In that way the pictures describe (aspects of) the corresponding processes, resp. how those processes evolve.</p>

<p>While I said, that the concept of “process” exists in all programming languages insofar all programs in all languages are supposed to be run, the concrete pictures here are <strong>more specific</strong> for the current setting in SICP. The visualizations rely on the so-called <strong>substitution model</strong>. That’s an “explanation” of the behavior of a process where applying a procedures to values means <strong>substituting</strong> the formal parameters by the actual parameters (and then continue from there). The model as presented here not only relies on replacing formal parameters by the actual parameters. Additionally, it’s required that the arguments are evaluated first, i.e., the arguments are already <strong>values</strong>. This strategy thus corresponds to what is also known as <strong>call-by-value</strong>, one important, arguably the most important <strong>parameter passing</strong> mechanism for programming languages.</p>

<p>Using <strong>substitution</strong> as explanation of what happens when calling a function is also not unique for Scheme, one can use that also for other programming languages. But explaining program behavior via substitution is rarely done, as it works only in a purely functional setting, and most languages simply are not purely functional. Indeed, as soon as we introduce side-effects and things like <code class="language-plaintext highlighter-rouge">set!</code> in week 6, substitution as evaluation mechanism also breaks down for Scheme and has to be replaced by something more complex. Thus, it’s particular for the section <strong>here</strong> to use the substitution model when discussing the behavior of the processes.</p>

<p>The <strong>intention</strong> of the discussion and visualization is to give an impression of the <strong>memory usage</strong> (for instance comparing iterative vs. recursive versions of factorial). The illustration uses a sequence of S-expressions that evolves with substitutions (because that’s what we have seen so far). But even later, when we have abandoned the substitution model (or in other languages), the message that iterative processes (or loops) have a constant memory footprint, whereas recursive ones have a growing memory usage (also called the <strong>stack</strong>…) still holds true, independent from any visualization or model.</p>

<p>One could and probably should be more precise and saying that a process is a piece of <strong>sequential</strong> code under execution, at least in standard terminology. If one starts considering concurrency or parallelism, everything gets more complex. In the lecture, side-effects are presented as a drastic departure from the functional setting. But the departure would be only really radical, when introducing <strong>concurrency</strong> (and the terminology of <strong>process</strong> would need much more elaboration and would have a wider range of meanings). Concurrency and parallelism is a large field in its own and Scheme is not the language that comes first to one’s mind when talking about concurrency and parallelism. Though some Scheme variations support parallelism and concurrent programming, and functional languages hold the promise to be easily be parallelized. The lecture will only touch upon concurrency and parallelism in the most superficial way, and also in this text, we cannot go deeper and for instance discuss the word <strong>process</strong> in a concurrent or parallel setting. For us, being concurrent or parallel as the alternative is not even on the table for discussion, so we don’t even much mention that we are dealing sequential programs (though we do), and should a Scheme program be internally be executed in parallel, so the internal parallel evaluation would be invisible to us except that it may run faster.</p>

<h1 id="procedures-and-functions">Procedures and functions</h1>

<p>SICP uses the words procedures and functions in a clear way and consistently (which is a good thing, especially for a textbook). So things are pretty clear on that front (within SICP). Functions are meant in a mathematical way, whereas procedures consist of Scheme code (using <code class="language-plaintext highlighter-rouge">lambda</code> and often using <code class="language-plaintext highlighter-rouge">define</code> if one wants to give a name to a procedure). As one of the first examples in the lecture, we had the factorial. The mathematical function is written conventionally with an exclamation mark $!$ whereas the procedure, the corresponding Scheme code, was called <code class="language-plaintext highlighter-rouge">fac</code>. Actually we had 2 procedures, one that was linear-recursive and one tail-recursive, both calculating the same function.</p>

<p>Since those two concepts are closely related, and since the whole thing is not really confusing, one sometimes of course relaxes a bit and says that <code class="language-plaintext highlighter-rouge">fac</code> is a function, namely the factorial function instead of saying <code class="language-plaintext highlighter-rouge">fac</code> is a Scheme variable giving a name to a procedure that represents an entity that is known in mathematics as the factorial function…</p>

<p>Of course, since functions as mathematical concept have <strong>no side effects</strong>, one can have procedures that do not represent mathematical functions, namely those which are not purely functional. Side-effects, for instance via <code class="language-plaintext highlighter-rouge">set!</code> in Scheme, is one way of breaking with pure functions. Another one would be <strong>non-determinism</strong>, for instance, functions that return output influenced by <strong>randomness</strong>. The procedure <code class="language-plaintext highlighter-rouge">random</code>, built-in in many Scheme dialects (though not in R5RS) is an example. Such a procedure is not purely functional, but has no side-effects either. <strong>Referential transparency</strong>, which is a characteristic property of a purely functional setting, does not hold for procedures like <code class="language-plaintext highlighter-rouge">random</code>. Side remark: it’s correct that a procedure like <code class="language-plaintext highlighter-rouge">random</code> breaks referential transparency and has no side-effects. To be more precise, it has no side-effects visible to the outside, to the user of <code class="language-plaintext highlighter-rouge">random</code>. Often random-number generators, when realized in software, generate not real random numbers, but so-called <strong>pseudo random numbers</strong>, numbers that looks random, but in fact really are not. A possible implementation might well rely on an internal state which is changed after each call to <code class="language-plaintext highlighter-rouge">random</code>, so, programmed that way, the procedure would internally make use to commands like <code class="language-plaintext highlighter-rouge">set!</code>, only that this is encapsulated (like the internal state of our bank-account examples). If realized in that way, the use of <code class="language-plaintext highlighter-rouge">set!</code> is another piece of evidence why <code class="language-plaintext highlighter-rouge">random</code> is not a mathematical function.</p>

<p>Clear as the issue of functions vs. procedures is inside SICP, outside of the book and in other programming languages, the words are used often slightly differently, and one may stumble upon two other interpretations, themselves also slightly different. They don’t talk about functions in a mathematical sense at all, they focus on procedures or functions as programming constructions. One common interpretation is that procedures have <strong>no return value</strong>, and functions have a <strong>return value</strong>. Alternatively, one may find definitions that say functions don’t have <strong>side effects</strong>, procedures have. The latter is in line with our definition, because without side-effects, a procedure behaves like a mathematical function.</p>

<p>Both alternative definitions are slightly different, but hang together. If one has a procedure that does not return a value, then, to be useful at all, it will have side-effects (note that I/O or interacting with the environment count as side-effect). Analogously, if a procedures is not allowed to have side effects, it need to return a value. The only situation where the two definitions disagree is for procedures with side-effects <strong>and</strong> return values. One “definition” would call it a function, because of the returned value, the other definition would call it a procedure, because of its side-effect.</p>

<p>All is pretty simple (and actually not interesting). This terminology sometimes are not (just) refer to concepts, but to actual language constructs. For instance, the slighted dated language Pascal uses <code class="language-plaintext highlighter-rouge">procedure</code> and <code class="language-plaintext highlighter-rouge">function</code> as <strong>keywords</strong>. So one could have</p>

<div class="language-pascal highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">procedure</span> <span class="n">Hello</span><span class="p">;</span>
  <span class="k">begin</span>
     <span class="n">ShowMessage</span> <span class="p">(</span><span class="s">'Hello world!'</span><span class="p">);</span>
  <span class="k">end</span><span class="p">;</span>

  <span class="k">function</span> <span class="kt">Double</span> <span class="p">(</span><span class="k">Value</span><span class="p">:</span> <span class="kt">Integer</span><span class="p">)</span> <span class="p">:</span> <span class="kt">Integer</span><span class="p">;</span>
  <span class="k">begin</span>
     <span class="kt">Double</span> <span class="p">:=</span> <span class="k">Value</span> <span class="p">*</span> <span class="m">2</span><span class="p">;</span>
  <span class="k">end</span><span class="p">;</span>
</code></pre></div></div>

<p>Most languages don’t feel the need to introduce different language level constructs or keywords to make a distinction on the programming language level. C, actually, at least the C standard, does not even talk about procedures, everything procedural is a function (with or without side-effect, with or without value). And object-oriented languages mostly call their “procedural” mechanism <strong>method</strong> (though methods often have some extra features over procedures).</p>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="procedure" /><category term="process" /><category term="function" /><summary type="html"><![CDATA[and functions too]]></summary></entry><entry><title type="html">What’s in a name?</title><link href="/functionalprogramming/2024/09/01/bindingandscope.html" rel="alternate" type="text/html" title="What’s in a name?" /><published>2024-09-01T00:00:00+02:00</published><updated>2024-09-03T16:06:00+02:00</updated><id>/functionalprogramming/2024/09/01/bindingandscope</id><content type="html" xml:base="/functionalprogramming/2024/09/01/bindingandscope.html"><![CDATA[<p>In the break during the lecture in week 2, a question came up from the audience asking for more information and explanations in connection with some slide titled “Anecdote”. Discussed at (and around) that slide are formal parameters, <strong>free</strong> and <strong>bound</strong> variables, and the notion of <strong>scope</strong>. The slides state that the choice of names for variables is arbitrary, and it was mentioned that Scheme gives the user great freedom in what one can use as “name”.</p>

<p>Let’s recap some of the points on the slides here (with a mildly different example). Assume the following piece of code:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">n</span> <span class="mi">42</span><span class="p">)</span>            <span class="c1">;; define a number</span>
<span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">f</span> <span class="nv">x</span><span class="p">)</span> <span class="p">(</span><span class="nb">+</span> <span class="nv">x</span> <span class="nv">n</span><span class="p">))</span>   <span class="c1">;; function increases input by 42!</span>
</code></pre></div></div>

<p>Scheme would allow <code class="language-plaintext highlighter-rouge">*</code> as name of a formal parameter instead of <code class="language-plaintext highlighter-rouge">x</code>:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">n</span> <span class="mi">42</span><span class="p">)</span>            <span class="c1">;; define a number</span>
<span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">f</span> <span class="nv">*</span><span class="p">)</span> <span class="p">(</span><span class="nb">+</span> <span class="nv">*</span> <span class="nv">n</span><span class="p">))</span>   <span class="c1">;; same function,</span>
                         <span class="c1">;; but with idiotic formal parameter</span>
</code></pre></div></div>

<p>It’s a confusing choice, for sure, and one should not do it.</p>

<h1 id="variable-capture">Variable capture</h1>

<p>Things escalate from “confusing” to “wrong” if one would rename <code class="language-plaintext highlighter-rouge">x</code> to <code class="language-plaintext highlighter-rouge">n</code>, not to <code class="language-plaintext highlighter-rouge">*</code>:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">n</span> <span class="mi">42</span><span class="p">)</span>            <span class="c1">;; define a number</span>
<span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">f</span> <span class="nv">n</span><span class="p">)</span> <span class="p">(</span><span class="nb">+</span> <span class="nv">n</span> <span class="nv">n</span><span class="p">))</span>   <span class="c1">;; function doubles its input!</span>
</code></pre></div></div>

<p>With this renaming, the function <code class="language-plaintext highlighter-rouge">f</code> now implements <strong>doubling</strong> its input, no longer increasing it by $42$. What went wrong here is that one overlooked that <code class="language-plaintext highlighter-rouge">n</code> is already mentioned in the body; it originally occurs <strong>free</strong> in the body and is bound by a definition outside the body. After carelessly renaming <code class="language-plaintext highlighter-rouge">x</code> to <code class="language-plaintext highlighter-rouge">n</code>, however, the variable will no longer be free, it will have become a bound variable. This is called <strong>variable capture</strong>. As a consequence: the choice of variable names does not matter, only up-to a point. Renaming formal parameters that lead to variable capture <strong>changes</strong> what the program means.</p>

<p>Actually, all what’s been said so far should be known from the lecture, and that’s not what this post is about, it’s just the starting point. Indeed, there’s <strong>more</strong> to the issue of renaming, and that probably was the student’s question or at least related to it. What follows is <strong>not</strong> discussed on the slides.</p>

<h1 id="hidden-name-capture">Hidden name “capture”?</h1>

<p>Variable capture is the effect that renaming changes the status from a variable name from being “free” to being “bound”. That renaming is the programmer’s fault who carelessly edits (= <strong>rewrites</strong>) the program text manually. But one could wonder whether there are <strong>other ways</strong> by which a previously free variable name comes under the “influence” of a binder</p>

<p>And indeed, there are situations that look dangerous in this respect, and that is actual topic of this post. It’s a consequence of two aspects: first, procedures can contain in their body free variables; that was already part of the previous “variable capture” example (<code class="language-plaintext highlighter-rouge">n</code> was first free inside <code class="language-plaintext highlighter-rouge">f</code>, before becoming captured by stupidly renaming the formal parameter to <code class="language-plaintext highlighter-rouge">n</code>). The second aspect is that procedures or functions can “move” in a way: Scheme is a programming language supporting <strong>higher-order</strong> functions, which means that a procedure can be handed over as <strong>argument</strong> to another function, or <strong>returned from</strong> as result from a function. Handing over an argument to a function, i.e., by way of <strong>parameter passing</strong> can be seen as “moving” it into callee’s body. That analogy is in particular visible in the <strong>substitution model</strong>, which explains execution or evaluation as a sequence of substitutions or as <strong>rewriting</strong>. Rewriting the code is, of course, done by the interpreter or evaluator, not by a silly user who rewrites the code by changing variable names. In all fairness, interpreting a functional program is mostly not directly implemented by transforming literal source code, especially not the string of input text. That would be too inefficient. That’s why it’s not called not substitution <strong>implementation</strong> or substitution <strong>technique</strong>, but a substitution <strong>model</strong>, and the model gives a correct conceptual explanation of what’s going on.</p>

<p>Let’s look at the above example again. Note that procedures or functions (i.e., lambda expressions) are <strong>values</strong>:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">f</span> <span class="nv">x</span><span class="p">)</span> <span class="p">(</span><span class="nb">+</span> <span class="nv">x</span> <span class="nv">n</span><span class="p">))</span>  
</code></pre></div></div>

<p>The name or variable <code class="language-plaintext highlighter-rouge">f</code> is bound to <code class="language-plaintext highlighter-rouge">(lambda (x) (+ x n))</code>, which counts as <strong>value</strong> despite the fact that <code class="language-plaintext highlighter-rouge">n</code> is unresolved, i.e., <code class="language-plaintext highlighter-rouge">n</code> is not a value.</p>

<p>If we would apply some (higher-order) function <code class="language-plaintext highlighter-rouge">g</code> to <code class="language-plaintext highlighter-rouge">f</code>, executing <code class="language-plaintext highlighter-rouge">(g f)</code>, <strong>applicative order</strong> would evaluate <code class="language-plaintext highlighter-rouge">f</code> into the above lambda-expression (and <code class="language-plaintext highlighter-rouge">g</code> would have to be resolved as well). But, as said, <code class="language-plaintext highlighter-rouge">(lambda (x) (+ x n))</code> <strong>is a value</strong>, and would be handed over by parameter passing: being a value already, applicative order would <strong>not</strong> go on evaluating it for example by replacing <code class="language-plaintext highlighter-rouge">n</code> by <code class="language-plaintext highlighter-rouge">42</code> (neither would normal-order evaluation).</p>

<p>You may think, that’s weird: if something is called <strong>eager</strong> evaluation, one would expect that maybe also <code class="language-plaintext highlighter-rouge">n</code> in the body of <code class="language-plaintext highlighter-rouge">f</code> should be impatiently evaluated when defining <code class="language-plaintext highlighter-rouge">f</code>. But actually, that’s not done and it’s common in all programming languages. <strong>Defining</strong> a procedure, method, function or whatever <strong>does not trigger executing its body</strong> (even if it sometimes were possible to evaluate parts of it). It’s not that it’s never done, but executing code before the code is actually “activated” (like when actually <strong>calling</strong> a function with arguments) is called <strong>pre-computation</strong> and is an <strong>optimization technique</strong> used by some compilers. In an imperative setting, one would have to analyze if pre-computation is even meaningful. It’s possible if calculating some parts up-front gives the same result than not doing it (which is the case if one can establish the the pre-computed result would never change later on. In an imperative setting that could be possible, that’s why an analysis would be required. In a purely functional language, there is no danger of that, but still it’s standard to consider $\lambda$-expressions as evaluated, even if they contain unevaluated sub-expressions (and Scheme is not purely functional).</p>

<p>Now, in a situation as from the example above, when handing over <code class="language-plaintext highlighter-rouge">f</code> to some procedure, the (as yet unevaluated) <code class="language-plaintext highlighter-rouge">n</code> maybe end up inside another scope which by some coincidence binds <code class="language-plaintext highlighter-rouge">n</code>. So now it’s not that a manual stupid renaming leads to capture, but a free variable is “moved” into some scope, when running the code. And note, maybe the programmer who uses <code class="language-plaintext highlighter-rouge">g</code> when calling it with <code class="language-plaintext highlighter-rouge">f</code> as argument by writing <code class="language-plaintext highlighter-rouge">(g f)</code> does not <strong>know</strong> what (if any) local scope is used inside <code class="language-plaintext highlighter-rouge">g</code>. After all, it is better if <code class="language-plaintext highlighter-rouge">g</code> could be treated as <strong>black box</strong>: one should know what <code class="language-plaintext highlighter-rouge">g</code> is supposed to do, but not how it’s <strong>implemented</strong> and in particular not which variables the programmar of <code class="language-plaintext highlighter-rouge">g</code> has introduced locally. It’s laughable to try to play it safe and avoid variables like <code class="language-plaintext highlighter-rouge">x</code>, <code class="language-plaintext highlighter-rouge">y</code>, <code class="language-plaintext highlighter-rouge">n</code> (and opting for <code class="language-plaintext highlighter-rouge">xxxxx</code> and <code class="language-plaintext highlighter-rouge">yyyyy</code>, <code class="language-plaintext highlighter-rouge">nnnnn</code> insead) speculating that they are popular and are in high danger of being captured … Not much better is to require the user of procedures (for instance when using library functions) to read though the implementation of the used functions to make sure that no captures would occur. And maybe the source code of the (library) function is not even available.</p>

<p>To make the discussion more concrete again, let’s look at an example (and let’s use strings for a change, not numbers):</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">message</span>  <span class="s">"\nLive long and prosper"</span><span class="p">)</span>  
<span class="p">(</span><span class="k">define</span> <span class="nv">sendmessage</span> <span class="c1">;; proc. that returns "message"</span>
  <span class="p">(</span><span class="k">lambda</span> <span class="p">()</span>   <span class="nv">message</span><span class="p">))</span>    

<span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">sendtailormademessage</span> <span class="nv">f</span> <span class="nv">name</span><span class="p">)</span>    
  <span class="p">(</span><span class="k">let</span> <span class="p">((</span><span class="nf">message</span> <span class="s">" What's up"</span><span class="p">))</span> <span class="c1">;; local "re"-definition</span>
    <span class="p">(</span><span class="k">begin</span> <span class="p">(</span><span class="nb">display</span> <span class="p">(</span><span class="nf">f</span><span class="p">))</span>
	   <span class="p">(</span><span class="nb">display</span> <span class="s">", "</span><span class="p">)</span>
	   <span class="p">(</span><span class="nb">display</span> <span class="nv">name</span><span class="p">)</span>
	   <span class="p">(</span><span class="nb">display</span> <span class="s">", "</span><span class="p">)</span>
	   <span class="p">(</span><span class="nb">display</span> <span class="nv">message</span><span class="p">)</span>
	   <span class="p">(</span><span class="nb">display</span> <span class="s">"\n"</span><span class="p">))))</span>

<span class="p">(</span><span class="nf">sendtailormademessage</span> <span class="nv">sendmessage</span> <span class="s">"stranger"</span><span class="p">)</span> <span class="c1">;;; </span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">message</code> is a variable containing a string, which is used inside the procedure <code class="language-plaintext highlighter-rouge">sendmessage</code> but defined outside it. Actually, the program introduces <code class="language-plaintext highlighter-rouge">message</code> twice, once at the beginning and afterwards <strong>inside</strong> the higher-order procedure <code class="language-plaintext highlighter-rouge">sendtailormademessage</code>. The second time the name <code class="language-plaintext highlighter-rouge">message</code> is introduced via <code class="language-plaintext highlighter-rouge">let</code> (which is responsible to a scope for <code class="language-plaintext highlighter-rouge">message</code> which is nested <code class="language-plaintext highlighter-rouge">inside</code> the body of the procedure <code class="language-plaintext highlighter-rouge">sendtailormademessage</code>). It’s inside this nested scope that <code class="language-plaintext highlighter-rouge">sendmessage</code> ends up if we substitute it when calling <code class="language-plaintext highlighter-rouge">sendtailormademessage</code> in the last line of the example, and with it also the name <code class="language-plaintext highlighter-rouge">message</code> ends up there. Let binds variables the same way that formal parameter of a procedure binds variables. We could have written analogous examples with procedures, without let (which comes later in the lecture), but this way it’s a bit shorter or readable.</p>

<p>Now if we substitute <code class="language-plaintext highlighter-rouge">sendmessage</code> <strong>literally</strong> into the body of <code class="language-plaintext highlighter-rouge">sendtailormademessage</code>, <code class="language-plaintext highlighter-rouge">message</code> would end up inside the <code class="language-plaintext highlighter-rouge">let</code>-binding for <code class="language-plaintext highlighter-rouge">message</code> inside, it would be <strong>captured</strong>:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">message</span>  <span class="s">"\nLive long and prosper"</span><span class="p">)</span> <span class="c1">;; some string</span>
<span class="o">.....</span>
<span class="p">(</span><span class="k">let</span> <span class="p">((</span><span class="nf">message</span> <span class="s">"\nWhat's up"</span><span class="p">))</span> 
  <span class="p">(</span><span class="k">begin</span> <span class="p">(</span><span class="nb">display</span> <span class="p">((</span><span class="k">lambda</span> <span class="p">()</span>   <span class="nv">message</span><span class="p">)))</span>  
	 <span class="p">(</span><span class="nb">display</span> <span class="s">", "</span><span class="p">)</span>
	 <span class="p">(</span><span class="nb">display</span> <span class="s">"stranger"</span><span class="p">)</span>
	 <span class="p">(</span><span class="nb">display</span> <span class="s">", "</span><span class="p">)</span>
	 <span class="p">(</span><span class="nf">diplay</span> <span class="nv">message</span><span class="p">)</span>
	 <span class="p">(</span><span class="nb">display</span> <span class="s">"\n"</span><span class="p">))))</span>
</code></pre></div></div>

<p>If that happened, the output would be</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>What's up, stranger, What's up
</code></pre></div></div>

<p>However, if you test the program in Scheme, the output is something else:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Live long and prosper, stranger,  What's up
</code></pre></div></div>

<p>I.e., the when substituting <code class="language-plaintext highlighter-rouge">sendmessage</code> for <code class="language-plaintext highlighter-rouge">f</code>, the code is not really “textually” copied in. It’s done smarter, and a way of explaining it is that the substitution result is</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">message</span>  <span class="s">"\nLive long and prosper"</span><span class="p">)</span> <span class="c1">;; some string</span>
<span class="o">.....</span>
<span class="p">(</span><span class="k">let</span> <span class="p">((</span><span class="nf">message_new</span> <span class="s">"\nWhat's up"</span><span class="p">))</span> 
  <span class="p">(</span><span class="k">begin</span> <span class="p">(</span><span class="nb">display</span> <span class="p">((</span><span class="k">lambda</span> <span class="p">()</span>   <span class="nv">message</span><span class="p">)))</span>  
	 <span class="p">(</span><span class="nb">display</span> <span class="s">", "</span><span class="p">)</span>
	 <span class="p">(</span><span class="nb">display</span> <span class="s">"stranger"</span><span class="p">)</span>
	 <span class="p">(</span><span class="nb">display</span> <span class="s">", "</span><span class="p">)</span>	 
	 <span class="p">(</span><span class="nb">display</span> <span class="nv">message_new</span><span class="p">)</span>	 
	 <span class="p">(</span><span class="nb">display</span> <span class="s">"\n"</span><span class="p">))))</span>
</code></pre></div></div>

<p>The original let-bound local variable <code class="language-plaintext highlighter-rouge">message</code> is silently <strong>renamed</strong> to, say, <code class="language-plaintext highlighter-rouge">message_new</code> and consistently, it’s now <code class="language-plaintext highlighter-rouge">(display message_new)</code> towards the end. One can imagine that instead of using “dumb substitution”, the substitution model is based on what is known as <strong>capture-avoiding substitution</strong>. That is what is meant in the headline when writing <em>“fine print on substitution”</em>.</p>

<p>The alternative, namely that <code class="language-plaintext highlighter-rouge">message</code> is in fact captured also exists. It’s called <strong>dynamic scoping</strong> as opposed to the correct version, which is called <strong>static scoping</strong> or <strong>lexical scoping</strong> (and “dumb” and “capture-avoiding” substitution are explanations of how both work in a purely functional setting). There exist languages which use dynamic bindings, $\LaTeX$ is one, and earlier versions of Lisp. Scheme was the first Lisp variant based in lexical scoping, earlier ones used dynamic scoping, and some continued with that, though static scoping is now one option or even the default for many emacs version. Lexical scoping is also the standard for most languages.</p>

<p>Why was dynamic scoping the method of choice in older versions of Lisp supporting and not lexical? One must not forget that Lisp was a seriously pioneering language (with higher-order functions, garbage collection etc) at a time where people only started to “understand” high-level languages, the techniques required to implement such abstractions (and not work very close to the hardware) and, last not least, work with seriously restricted memory. Now, the message-example used to illustrate the issue is fairly simple; the variable <code class="language-plaintext highlighter-rouge">message</code> contains a string, which Scheme handles via lexical binding. One could make analogous examples the variable that is treated either statically/lexically or dynamically refers to a function. After all, we have a functional language, functions are first-class citizens, and rules for strings as data applys for functions as data in the same way.</p>

<p>It turns out that dynamic scoping, especially for functions, is considerable easier than lexical scoping. Already in the purely functional setting, one has the feeling that “dumb” substitution seems easier than capture avoiding substitution (though concrete implementations are not directly based on text-manipulations, dumb or otherwise, especially compilers can’t do that).</p>

<p>Later Lisp/Scheme version were not purely functional, so an implementation directly based on some form of substitution is not even an option. But lexical scoping with higher-order functions requires hanlding rather more complex data-structures at run-time (the so-called run-time environment), as is the case for dynamic binding (or the case for languages without higher-order procedures. Later we discuss the so-called <strong>environment model</strong> (which realizes lexical scoping and which replaces or generalizes the simple substitution model when one integrates side-effects), and what is needed are so-called <strong>closures</strong> (though the book does not use the word). And the more complex run-time environments and the closures may lead to higher memory usage plus degrading performance. In short, the time (and the knowledge, technology and hardware) may not yet have been ripe for higher-order functions + lexical scoping. Actually, John McCarthy in his 1979 paper “History of Lisp” even goes so far as characterizing dynamic scoping as bug, when descibing an early Lisp implementation:</p>

<blockquote>
  <p>.. In modern terminology, lexical scoping was wanted, and dynamic scoping was obtained. I must confess, I regarded this difficulty as just a bug and expressed confidence that Steve Russel would soon fix it…</p>
</blockquote>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="functional programming" /><category term="IN2040" /><category term="scheme" /><category term="lisp" /><category term="variables" /><category term="scope" /><category term="variable capture" /><category term="variable renaming" /><category term="static scoping" /><category term="dynamic scoping" /><summary type="html"><![CDATA[Some fineprint on substitution]]></summary></entry><entry><title type="html">Evaluation strategies</title><link href="/functionalprogramming/2024/08/29/evaluationstrategies.html" rel="alternate" type="text/html" title="Evaluation strategies" /><published>2024-08-29T00:00:00+02:00</published><updated>2024-08-29T06:13:00+02:00</updated><id>/functionalprogramming/2024/08/29/evaluationstrategies</id><content type="html" xml:base="/functionalprogramming/2024/08/29/evaluationstrategies.html"><![CDATA[<p>The post is about <strong>evaluation strategies</strong>. The concept is discussed in the lecture (in week 2) and in SICP. Especially <strong>applicative order</strong> evaluation is covered, as the standard evaluation strategy of Scheme. Also, an alternative to that is discussed, namely <strong>normal order</strong> evaluation, and that’s done in connection with things that show up later in the lecture, namely delayed evaluation, streams, and also in the context of the meta-circular evaluator. That’s a Scheme interpreter written in Scheme and for that it will be discussed what needs to be done to have a non-standard interpreter, namely one that does normal order evaluation.</p>

<blockquote>
  <p>But what’s evaluation anyway? And why does one need a strategy for that?</p>
</blockquote>

<h1 id="values-evaluation-and-execution">Values, evaluation, and execution</h1>

<p><em>Evaluation</em> means to determine the <strong>value</strong> of something (like ``e-<strong>value</strong>-ation”), for us, the value of an expression or of (a part of) a program. The concept of evaluation is eminently functional; in absence of side effects, the value of an expression, in particular of function applications, is independent from when its evaluated, it does not depend on some state (which may change) and so it’s always the same. That property is also known as <strong>referential transparency</strong>. Since the value of an expression is always the same means, an expression represents nothing else than the value, it’s only not yet calculated. Like: <code class="language-plaintext highlighter-rouge">(fac 5)</code> <strong>is</strong> the same as 120, though <code class="language-plaintext highlighter-rouge">(fac 5)</code> is an unevaluated expression, and <code class="language-plaintext highlighter-rouge">120</code> is an evaluated expression (there’s nothing more to do): in ordinary language, we simply say</p>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">(fac 5)</code> <strong>is</strong> 120</p>
</blockquote>

<p>or write as equation</p>

<blockquote>
  <p>5! = 120</p>
</blockquote>

<p>which is shorter than to say 120 is <strong>the value of</strong> <code class="language-plaintext highlighter-rouge">(fac 5)</code> (or of 5!). One can speak of “the” value of an expression, as opposed of “a” value of an expression, as in the absence of nondeterminism (random effects), there cannot be more than one value. Those observations are also underlying the <strong>substitution model</strong> from the lecture. Actually, not just from the lecture: substitution as explanation what happens when executing a program works as long as the program is purely functional, in Scheme or other languages. Substitution means replacement, and if two things are “the same”, one can replace one by the other without that it changes anything. For instance, if one calls a procedure, say <code class="language-plaintext highlighter-rouge">square</code> on <code class="language-plaintext highlighter-rouge">(fac 5)</code> as argument, then it in a way does not matter if the body of <code class="language-plaintext highlighter-rouge">square</code> does its calculating on <code class="language-plaintext highlighter-rouge">(fac 5)</code>, the unevaluated argument expression, or on 120, because both represent the same value (namely 120). And evaluating <code class="language-plaintext highlighter-rouge">(fac 5)</code> before handing over the calculating formal parameter <code class="language-plaintext highlighter-rouge">x</code>. And referential transparency guarantees that it does not matter whether <code class="language-plaintext highlighter-rouge">(fac 5)</code> is being evaluated to 120 beforehand, i.e. before handing it over to <code class="language-plaintext highlighter-rouge">square</code> or handing over <code class="language-plaintext highlighter-rouge">(fac 5)</code> unevaluated, and let it be evaluated when evaluating the body.</p>

<p>Evaluation thus refers to the “execution mechanism” for purely functional programs and expressions. Sometimes one calls evaluation also <em>reduction</em>, like that an unevaluated expression such as <code class="language-plaintext highlighter-rouge">(fac 5)</code> is reduced in a number of steps closer and closer to it ultimate value.</p>

<p>Of course, also imperative programs need to be executed. Those are not primarily run to obtain their value, but (also or mainly) for their side effects. Sometimes they don’t even result in a value, but are executed for side effects only.</p>

<p>Later in the lecture, we will encounter <code class="language-plaintext highlighter-rouge">set!</code>, which assigns a value to a variable. Assuming that a variable <code class="language-plaintext highlighter-rouge">x</code> is introduced (via <code class="language-plaintext highlighter-rouge">define</code>, via <code class="language-plaintext highlighter-rouge">let</code>, or as formal parameter) and has some value, then <code class="language-plaintext highlighter-rouge">(set! x (+ x 1))</code> <strong>changes</strong> the value or content of <code class="language-plaintext highlighter-rouge">x</code> and replaces it via the value increased by one.</p>

<p>The shown expression <code class="language-plaintext highlighter-rouge">(set! x (+ x 1))</code> in Scheme has <strong>no</strong> value, i.e., it’s executed for its side effect alone, and trying to do something like</p>

<div class="language-lisp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="nb">*</span> <span class="mi">10</span> <span class="p">(</span><span class="nv">set!</span> <span class="nv">x</span> <span class="p">(</span><span class="nb">+</span> <span class="nv">x</span> <span class="mi">1</span><span class="p">)))</span>
</code></pre></div></div>

<p>is meaningless i.e., leads to a runtime error. Being a functional language at its very core, imperative aspects take a bit of a backseat in Scheme/Lisp, and thus the syntax for assignment is specially marked by <code class="language-plaintext highlighter-rouge">!</code> (“bang”), at least in the Scheme dialect we are using, as a warning sign to the programmer, not to expect referential transparency any longer (and, connected to that, the substitution model breaks down, as well).</p>

<p>Of course, there are many languages not centered around procedures, functions etc. but are imperative at their core. Many widely used programming languages, including object-oriented ones, are imperative. Destructive assignment is taken so much for granted in most languages that it often does not even specifically mentioned, like “let’s introduce assignment as destructive operation”, the qualifier “destructive” will not show up in any textbook about Java, maybe not even “imperative”. Also the syntax for assignment is typically less conspicuous. Since imperative operations are just the standard way of programming there’s not need to highlight them with a warning <code class="language-plaintext highlighter-rouge">!</code>, and so <code class="language-plaintext highlighter-rouge">(set! x (+ x 1))</code> is just written as <code class="language-plaintext highlighter-rouge">x = x+1</code>, using <code class="language-plaintext highlighter-rouge">=</code> as symbol for assignment.</p>

<p>As a side remark: Especially disciples of functional programming find it unfortunate that the equality sign <code class="language-plaintext highlighter-rouge">=</code> is (mis-)used in many languages for something that is not equality, but imperative assignment. For example, in C-like languages, <code class="language-plaintext highlighter-rouge">==</code> represents equality, and <code class="language-plaintext highlighter-rouge">=</code> represents assignment, but there are other languages, where assignment may be written <code class="language-plaintext highlighter-rouge">:=</code> or similar.</p>

<p>Back to evaluation and execution: as explained, some programs result in no value but are executed for their side-effects only, some have side effects and result in a value, and some, purely functional ones, have only a value and no side-effects. Details of which constructions gives a value and which not may differ from language to language. For instance, as said, <code class="language-plaintext highlighter-rouge">(set! x (+ x 1))</code> does not result in a value in Scheme (of course the sub-expression <code class="language-plaintext highlighter-rouge">(+ x 1)</code> has a value, depending on the content of <code class="language-plaintext highlighter-rouge">x</code>), but in other languages, for instance Java and C, the corresponding assignment <code class="language-plaintext highlighter-rouge">x = x+1</code> has not only a side-effect, changing <code class="language-plaintext highlighter-rouge">x</code> but <strong>also</strong> results in a value. Consequently, one can use constructions like</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span> <span class="mi">10</span> <span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<p>even though it might not be a recommended coding style.</p>

<h1 id="what-about-strategies">What about strategies?</h1>

<p>Now that we know what evaluation is, determining the value of a (purely functional) piece of code and we know that in the presence of side-effects, one more typically speaks about execution instead (“running the program”). But why do we talk about strategies, especially evaluation strategies?</p>

<p>One speaks of strategies in situations when one faces <strong>choices</strong>, how to proceed, and a strategy is a plan to make those choices. As an example from a different field, given the task to explore a graph, one can do that in different ways, for instance following a strategy of <em>depth-first</em> traversal, or <em>breadth-first</em>, to name the two most prominent strategies. The depth-first strategy, after exploring one edge , faces the choice how to proceed: to explore subsequent edges first, or explore alternative, “sibling” edges first. Depth-first traversal consistently targets the subsequent edges first.</p>

<p>For evaluation, let’s look at a simple example, like</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(6 + 4) - (5 * 2)
</code></pre></div></div>

<p>or</p>

<div class="language-lisp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="nb">-</span> <span class="p">(</span><span class="nb">+</span> <span class="mi">6</span> <span class="mi">4</span><span class="p">)</span> <span class="p">(</span><span class="nb">*</span> <span class="mi">5</span> <span class="mi">2</span><span class="p">))</span>
</code></pre></div></div>

<p>in Scheme notation. The value of the expression obviously is 0, and it’s easy enough to calculate, i.e, easy enough to evaluate. However, thinking of the evaluation as a step-by-step process, one has a choice to either calculate <code class="language-plaintext highlighter-rouge">6 + 4</code> first and <code class="language-plaintext highlighter-rouge">5 * 2</code> afterwards (and then building the difference), or the other way around. Actually, if one had one interpreter of compiler using parallelism, one could even have the left and the right sub-expression evaluated <strong>in parallel</strong> (something we don’t really touch upon in the lecture)</p>

<h2 id="but-does-it-matter">But does it matter?</h2>

<p>That’s a legitimate question, and the answer is: yes and no. Looking at the above simple numeric expression, the outcome is 0, independent of whether one calculates <code class="language-plaintext highlighter-rouge">6 + 4</code> before <code class="language-plaintext highlighter-rouge">5 * 2</code>, or the other way around. That’s what referential transparency is about: the value of, for instance <code class="language-plaintext highlighter-rouge">6 + 4</code>, namely 10, is independent from whether it’s calculated before <code class="language-plaintext highlighter-rouge">5 * 2</code> or afterward (or in parallel …), so in that sense the evaluation strategy or order does not matter. Of course, an interpreter will choose typically a particular order, like evaluating expressions like the one shown from left to right. Or a compiler realizes the same evaluation order, generating (machine) code that calculates the result of the left sub-expression before it calculates that of the one on the right (and before calculating the end result), since it has to calculate them in <em>some</em> order (if not parallelizing the task and using some multi-core architecture or similar) .</p>

<p>That was an argument that the evaluation strategy does not matter, at least is such purely functional or mathematical expressions, but actually the numerical example does not even touch on the two strategies mentioned above, applicative order vs. normal order. The reason being that the example does not really uses procedures, at least not user-defined ones, but calls only primitive procedures or operations, like <code class="language-plaintext highlighter-rouge">+</code> that do whatever needs to be done, without that one knows how they do it or how their procedure body looks like. Perhaps an operation using <code class="language-plaintext highlighter-rouge">+</code> is not even evaluated inside Scheme or the programming language , but handed over ultimately to some arithmetic hardware.</p>

<p>As said, strategy is about making choices, and the “evaluate sub-expressions or arguments to a procedure from left to right” is a “strategic” choice that was not even mentioned in the lecture. Simply because it’s not really relevant. A left-to-right version of Scheme (or some other language) is not different from a right-to-left version, at least not in any relevant way that would justify to give it special attention or names like “l-order evaluation” or “r-order evaluation” (and Scheme standards are explicit about that the standard does <strong>not</strong> prescribe an order, so the programmer should not assume one particular one).</p>

<p>Of course, in a language with side-effects, calling a function on arguments, where the argument have side-effects or using expressions where sub-expressions have side effects, it matters insofar as changing the order of evaluating the arguments may well change the outcome. Indeed, some imperative programming language explicitly <em>specify</em> that the order of evaluating the arguments of a procedure is <em>unspecified</em>. In other words, a programmer should not rely on that arguments are evaluated from left to right. For arguments without side-effects it would not matter anyhow, and arguments with side effects are bad coding style anyway. And as said initially, the word “evaluation” is best use for side-effect-free expressions anyway, as only then one is interested exclusively in an expression’s value. With side-effects the word “evaluation” and thus evaluation strategy is not too fitting anyway.</p>

<p>The strategic decision connected to the evaluation order does not regulate what happens if a procedure has multiple arguments (that’s a boring decision, as argued), but</p>

<blockquote>
  <p><strong>when</strong> to evaluate an argument in a procedure application or function call (resp. the arguments of the application, if there are more than one)</p>
</blockquote>

<p>Let’s take the example of the square-function. In Scheme, it’s plausibly defined as</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">square</span> <span class="nv">n</span><span class="p">)</span> <span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="nv">n</span><span class="p">))</span>
</code></pre></div></div>

<p>a purely functional procedure with one formal parameter. We may apply that to a <code class="language-plaintext highlighter-rouge">(fac 5)</code>, like</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="p">(</span><span class="nf">square</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">))</span>
</code></pre></div></div>

<p>The argument <code class="language-plaintext highlighter-rouge">(fac 5)</code> represents <code class="language-plaintext highlighter-rouge">120</code> its only not evaluated yet. One strategic decision is, that when applying a function to an unevaluated argument, one needs to evaluate the argument first, and evaluate the body afterwards, with the formal parameter replaced (= <strong>substituted</strong>) by the value. In the above example, the argument evaluates, as said, to <code class="language-plaintext highlighter-rouge">120</code> and replacing <code class="language-plaintext highlighter-rouge">n</code> by that value in the body of <code class="language-plaintext highlighter-rouge">square</code> yields</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="nb">*</span> <span class="mi">120</span> <span class="mi">120</span><span class="p">)</span>
</code></pre></div></div>

<p>That’s not yet evaluated, and requires one multiplication to reach the corresponding value <code class="language-plaintext highlighter-rouge">14400</code>.</p>

<p>That’s how <strong>applicative order</strong> chooses to handle arguments in an application, namely evaluate them first. Alternatively, one can hand over the argument <code class="language-plaintext highlighter-rouge">(fac 5)</code> unevaluated, i.e. substituting the formal parameter in the body by <code class="language-plaintext highlighter-rouge">(fac 5)</code>, yielding</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="nb">*</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">)</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">))</span>
</code></pre></div></div>

<p>That requires a number of evaluation or reduction steps, one needs to calculate <code class="language-plaintext highlighter-rouge">(fac 5)</code>, actually one needs to calculate it two times, before <code class="language-plaintext highlighter-rouge">*</code> can do its thing. To leave unevaluated arguments unevaluated, but hands them over as is, that’s <strong>normal order</strong> evaluation</p>

<p>Note that that last step in the normal order evaluation example assumes that <code class="language-plaintext highlighter-rouge">*</code> is not a standard procedure, since the arguments <code class="language-plaintext highlighter-rouge">(fac 5)</code> are evaluated before being multiplied. While <code class="language-plaintext highlighter-rouge">square</code> in the example illustrates normal order evaluation, the multiplication is assumed to be built-in and is assumed to multiply numbers, i.e., numeric <strong>values</strong>, not unevaluated numeric expressions. We could alternatively assume that multiplication is not built-in, for instance implemented by a procedure <code class="language-plaintext highlighter-rouge">multiply</code> as follows (for simplicity, it works for non-negative arguments <code class="language-plaintext highlighter-rouge">n</code> only):</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">multiply</span> <span class="nv">n</span> <span class="nv">m</span><span class="p">)</span>
  <span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">0</span><span class="p">)</span>
      <span class="mi">0</span>
      <span class="p">(</span><span class="nb">+</span> <span class="nv">m</span> <span class="p">(</span><span class="nf">multiply</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">)</span> <span class="nv">m</span><span class="p">))))</span>
</code></pre></div></div>

<p>With that, <code class="language-plaintext highlighter-rouge">square</code> would be defined by <code class="language-plaintext highlighter-rouge">(define (square n) (multiply n n))</code> and calling <code class="language-plaintext highlighter-rouge">(square (fac 5))</code> leads with applicative order to</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="nf">multiply</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">)</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">))</span>
</code></pre></div></div>

<p>which in turn leads to</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">)</span> <span class="mi">0</span><span class="p">)</span>
    <span class="mi">0</span>
    <span class="p">(</span><span class="nb">+</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">)</span> <span class="p">(</span><span class="nf">multiply</span> <span class="p">(</span><span class="nb">-</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">)</span> <span class="mi">1</span><span class="p">)</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">))))</span>
</code></pre></div></div>

<p>One could continue from here, doing further steps. It would require to remember that <code class="language-plaintext highlighter-rouge">if</code> is a special form, not a standard procedure, and thus the rules of applicative or normal order don’t apply in their pure form. If we did the same for <code class="language-plaintext highlighter-rouge">+</code> as we did for <code class="language-plaintext highlighter-rouge">*</code> namely redefining it maybe calling it <code class="language-plaintext highlighter-rouge">plus</code>, the evaluation would continue substituting unevaluated expressions to <code class="language-plaintext highlighter-rouge">plus</code> and the other functions. But I won’t do a further exploration of the normal order evaluation process on the example here, coming back to the initial question: AO or NO, does it matter?</p>

<p>In some way, no, it does not matter. Like in the example before, where left-to-right or right-to-left evaluation of sub-expressions did not matter, also for the strategic choice between AO vs NO in the example <code class="language-plaintext highlighter-rouge">(square (fac 5))</code> does not matter, <strong>as far as the resulting value is concerned</strong>, namely <code class="language-plaintext highlighter-rouge">14400</code>. That’s a general observation for purely functional programs: if the program results in a value under AO and under NO, it’s the same value.</p>

<p>In other ways, the choice between AO and NO does indeed matter! The end value may be the same, but the two strategies make different choices how to get there and that could mean, some strategy may get there <strong>quicker</strong>. The <code class="language-plaintext highlighter-rouge">square</code> example is a good illustration of that. It multiplies in its body <code class="language-plaintext highlighter-rouge">(* n n)</code> the argument <code class="language-plaintext highlighter-rouge">n</code> with itself. If, following NO, one hands over an unevaluated expression, like <code class="language-plaintext highlighter-rouge">(fac 5)</code> it means that <code class="language-plaintext highlighter-rouge">(fac 5)</code> needs to be evaluated (at least) two times, maybe more, if one uses a self-made <code class="language-plaintext highlighter-rouge">multiply</code> instead of the built-in <code class="language-plaintext highlighter-rouge">*</code>. For NO, the argument is evaluated only once, namely before handing it over to the caller. To avoid the potential performance penalty of repeatedly evaluated an expression, one could of course use <strong>memoization</strong> and the combination of NO and memoization is called <strong>lazy evaluation</strong>. Memoization can be used with AO as well, but it’s less urgent there, and there seems no specific word for that combination.</p>

<p>Of course, evaluating an argument only later, when unavoidable, can also lead to a situation that an argument is not evaluated at all under NO, whereas AO insists on evaluating it even if it turns out not being needed. As an example, take the following procedure that takes two arguments but returning only the first.</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">first</span> <span class="nv">x</span> <span class="nv">y</span><span class="p">)</span> <span class="nv">x</span><span class="p">)</span>
</code></pre></div></div>

<p>If we apply that to 2 numeric expressions, say <code class="language-plaintext highlighter-rouge">42</code> and <code class="language-plaintext highlighter-rouge">(/ 10 0)</code>, then AO will crash with a division-by-zero error or numerical overflow, whereas NO gives back <code class="language-plaintext highlighter-rouge">42</code> without crashing as the crashing division is never evaluated.</p>

<p>Of course, one could make the argument that <code class="language-plaintext highlighter-rouge">(/ 10 0)</code> is not a numerical expression, at least not a proper one, insofar that it does <strong>not evaluate</strong> to some value, it raises an error and potentially derails the overall evaluation. Actually, one can make the argument, that what happens when <code class="language-plaintext highlighter-rouge">(/ 10 0)</code>, namely raising an exception, is <strong>not a purely functional behavior</strong>, and the “result”, the exception, is not a value, but a <strong>side-effect</strong>. Taking that view would basically say that it’s not a good example for distinguishing AO vs NO in the substitution model and for purely functional programs.</p>

<p>Fair enough, but the next example is harder to argue away. Instead of raising an error like division-by-zero, there are other programs that don’t yield a value. That’s programs that <strong>do not terminate</strong>. The simplest one in Scheme is probably a procedure without parameters that simply calls itself:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">infiniteloop</span><span class="p">)</span>  <span class="p">(</span><span class="nf">infiniteloop</span><span class="p">))</span>
  <span class="p">(</span><span class="nf">infiniteloop</span><span class="p">)</span>         <span class="c1">;; this never terminates</span>
</code></pre></div></div>

<p>It hard to argue that this should not be a purely functional program, it does not change any state with things like <code class="language-plaintext highlighter-rouge">set!</code>, it does not produces output like with <code class="language-plaintext highlighter-rouge">display</code>, it does not crash or raise an exception. It simply keeps on evaluating without ever producing a value. If we use the procedure <code class="language-plaintext highlighter-rouge">first</code> from above with the infinite-loop program as its second argument</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="nf">first</span> <span class="mi">42</span>   <span class="p">(</span><span class="nf">infiniteloop</span><span class="p">))</span>
</code></pre></div></div>

<p>it will not terminate under AO, but produces <code class="language-plaintext highlighter-rouge">42</code> under NO. That’s clearly an example where AO vs NO makes a difference. In a way it’s just an extreme example for the observation that AO and NO can make a difference in the number of steps it takes to reach at a value. If we had an program that takes an enormous amount of steps to evaluate and used the same set-up, like</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="nf">first</span> <span class="mi">42</span>   <span class="nv">expr-that-takes-super-long-to-evaluate</span><span class="p">)</span>
</code></pre></div></div>

<p>then NO terminates very quick to produce 42, whereas AP takes super long before it produces 42. In the infinite-loop example, that super-long just means “forever” or infinitely long.</p>

<h2 id="evaluation-strategies-in-imperative-programming-languages">Evaluation strategies in imperative programming languages?</h2>

<p>The discussion about evaluation strategies like AO and NO focused on functional languages, drawing examples mostly from the functional core of Scheme. Well, as explained evaluation is about reducing an expression to obtain its value. That’s an eminently functional way of explaining what happens when a program runs. Imperative programs may not result in a value, or if they yield a value, it’s the side-effects, like state-change, changing the value of variables, that is what primarily happens. Thus, we discussing a “standard” programming language (and most programming languages are imperative at their core), the word “evaluation” is seldom used, and no one speaks of evaluation strategies. A Java program is not evaluated, its run or executed, resp. it compiled mostly to byte-code and then run or executed, resp. interpreted on a virtual machine.</p>

<p>Not only is one much less interested in the resulting value of a program in an imperative, sequential setting, there is also not much room for (evaluation or execution) strategies. A strategy is a plan to resolve choices or alternatives, but in an sequential, imperative program, there is no room for such choices. Often code is arrange in sequences of <strong>statements</strong>, maybe using also loops and conditionals etc. The statements are separated (in many languages) syntactically by <code class="language-plaintext highlighter-rouge">;</code> (semicolon). The semicolon is also called the <strong>sequential composition</strong> operator. And it goes without saying that of course the statements are evaluated one after the other from the beginning to end, leaving no room for an “strategic decisions”. It’s just how a program is executed, from beginning to end, and there’s loops, then of course the running program starts at the beginning of the loop when reaching the end of the loop (if not exiting).</p>

<p>Note incidentally, that at the current state of the lecture (in week 2) we have not even used composition in Scheme! In a purely functional language, it somehow makes no sense in explicitly programming to do ``first-this, then that’’. One does not specify the evaluation order, as mostly it does not matter, and where it matters to some extent, with procedure calls, the chosen evaluation strategy fixes the order. In Scheme, AO. Only somewhat later in week 6, when we introduce imperative feature, then there will be a need for sequential composition, and we will introduce the corresponding Scheme syntax: it will not be <code class="language-plaintext highlighter-rouge">;</code>, but, you may guessed it, an S-expression. They keyword is <code class="language-plaintext highlighter-rouge">begin</code>, which you may guessed also that, is a <strong>special form</strong>…</p>

<p>Here is an example of some factorial in C, programmed very non-functional, and also doing input-output (something that we have not touched upon in Scheme).</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span> 
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
  <span class="kt">int</span> <span class="n">c</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">f</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
 
  <span class="n">printf</span><span class="p">(</span><span class="s">"Enter a number to calculate its factorial</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
  <span class="n">scanf</span><span class="p">(</span><span class="s">"%d"</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">n</span><span class="p">);</span>

  <span class="k">for</span> <span class="p">(</span><span class="n">c</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">c</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">;</span> <span class="n">c</span><span class="o">++</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">f</span> <span class="o">*</span> <span class="n">c</span><span class="p">;</span>
 
  <span class="n">printf</span><span class="p">(</span><span class="s">"Factorial of %d = %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">f</span><span class="p">);</span>
 
  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>However, when we said that there are no strategic decisions in an imperative language, like C, to make, that was an <strong>exaggeration</strong>. Also in imperative languages, one can nest expressions (as one commonly does on Scheme). Likewise one of course uses procedure calls, and of course can use procedures. Then the question arises: what is handed over when calling a function or procedure? The answer is often (like in C, Java, and most other languages): it’s a value of the argument expression, so the <strong>parameter passing</strong> mechanism is <strong>call-by-value</strong>. It corresponds to <strong>applicative order evaluation strategy</strong>, though, as said, in imperative languages, one does not much speak about evaluation (and consequently one does not speak about applicative order or normal order, as this refers to evaluation strategies).</p>

<p>So, call-by-value though it corresponds to AO, is not seen as an evaluation strategy, but a decision about <strong>parameter passing</strong>. And one main alternative to call-by-value is <strong>not</strong> something that corresponds to NO, but something called <strong>call-by-reference</strong> (which is never used in connection with Scheme). On the other hand, NO, which corresponds to the core of lazy evaluation, has <strong>no place</strong> in imperative languages. It’s not that it’s impossible to do, but basically imperative side effects and the loss of referential transparency messes things up, so to lazy evaluation unusable (it had been done, and called <strong>call-by-name</strong>, but abandoned as useless). That’s the reason why the only significant programming language based on lazy evaluation is <strong>purely</strong> function (Haskell). Scheme, and most other functional languages support side effects, and therefore <strong>must</strong> do call-by-value resp. applicative order.</p>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="functional programming" /><category term="IN2040" /><category term="scheme" /><category term="lisp" /><category term="evaluation strategy" /><category term="normal-order evaluation strategy" /><category term="applicative-order evaluation strategy" /><category term="referential transparency" /></entry><entry><title type="html">Welcome to Functional programming (IN2040), autumn 2024</title><link href="/functionalprogramming/2024/05/22/fpwelcome-2024.html" rel="alternate" type="text/html" title="Welcome to Functional programming (IN2040), autumn 2024" /><published>2024-05-22T00:00:00+02:00</published><updated>2024-05-22T12:40:00+02:00</updated><id>/functionalprogramming/2024/05/22/fpwelcome-2024</id><content type="html" xml:base="/functionalprogramming/2024/05/22/fpwelcome-2024.html"><![CDATA[<h1 id="about-this-semester">About this semester</h1>

<h3 id="lectures">Lectures</h3>

<p>Corona is a thing of the dim pasts and lectures will be held the way it used to be, in the lecture hall (Simula@OJD).</p>

<h3 id="youtube">Youtube</h3>

<p>One perhaps positive effect of the virus times was that many lectures produced video-ed versions of the presentations, like screencasts or recorded lectures. This lecture as well. We will not make a new version of the videos, there is no reason for doing that (and lot of effort went into it), but we will link in the versions produced mostly 2020, uploaded at youtube.</p>

<h3 id="language">Language</h3>

<p>The lecture will be given in Norwegian. 2 years ago, autumn 2022, it was actually was my first lecture ever given in Norwegian, so this is the third time. We’ll see how it goes, maybe my Norwegian improved. In these (inofficial) pages, however, I’ll write in English, it takes too much time otherwise.</p>

<h2 id="exercises-and-group-work">Exercises and group work</h2>

<p>The videos are fine as supplementary information and electronic format. Though reading the book and in particular doing the exercises and obligs is central for mastering the material. I like to compare that with learning how to play the guitar. No particular reason for exactly choosing guitars as comparison, except that since some time I try to learn doing that. Of course one can watch and listen to Eric Clapton, <a href="https://www.youtube.com/watch?v=RmdRCywCtbs">Andrés Segovia</a>, or Eddie van Halen on youtube (or whatever your top guitar hero might be), maybe watching the close-ups of the finger plays, or listening to some guitar teacher. All that may be instructive, it may help to correct the way you hold your guitar or place and move your fingers, or you may see new techniques, and it sure can be inspiring and motivating, to see and listen to some master or instructor.</p>

<p>Seing enough youtube and reading enough material, one may be able to convincingly talk about what’s important when playing a guitar, describe techniques, using terminology like a pro (finger picking, leganto, arpeggio, whatever). But a talk about how to play guitar is not a live gig. So <strong>unless one strums the six strings with one’s own fingers</strong>, starting with simple chords, and gradually advancing the level of difficulty, <strong>one will never get far</strong>.</p>

<p>Same here: talking about programs like a pro (tail-recursion, applicative order, higher-order functions, stream-programming, to mention a few topics covered by the lecture…) is not the same as programming. So, doing exercises is important!</p>

<blockquote>
  <p>Learning is not the product of teaching. Learning is the product of the activity of learners. (John Holt)</p>
</blockquote>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="functional programming" /><category term="IN2040" /><category term="scheme" /><category term="lisp" /><summary type="html"><![CDATA[]]></summary></entry></feed>