<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2024-05-22T11:08:51+02:00</updated><id>/feed.xml</id><title type="html">IN2040 FP</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><author><name> </name></author><entry><title type="html">How to prepare for an oral exam?</title><link href="/functionalprogramming/2024/01/11/howtopreparefororalfp.html" rel="alternate" type="text/html" title="How to prepare for an oral exam?" /><published>2024-01-11T00:00:00+01:00</published><updated>2024-01-12T15:40:00+01:00</updated><id>/functionalprogramming/2024/01/11/howtopreparefororalfp</id><content type="html" xml:base="/functionalprogramming/2024/01/11/howtopreparefororalfp.html"><![CDATA[<p>The standard exam for the course on <em>functional programming</em> is <strong>written</strong>. Except for the times under corona, where it was a variation of a written exam, a “home exam”. However, the <strong>repeat exams</strong> are regularly held as oral ones. One reason is simply expedience. There are not too many candidates who need another exam. A written exam requires <strong>a lot more</strong> preparation than an oral one, which also needs some. For a written exam, one has to come up with new questions (but not too new, they have to be comparable to those from previous semesters). Setting up a question set alone takes time and involves iterations. And the content ideally needs to be quality controlled, best actually not just read, but solved and worked through by a colleague and not any colleague, one that is more than a little familiar with the material and the course (and has time at that time of the year). The Norwegian text needs to be read and polished with the help of a Norwegian, as even with a lot of effort, I cannot reach the level of 99.5% clarity and smooth formulations and without small glitches and strange formulations. The result needs to be pressed into inspera, there needs to be a proposal for a solution and some grading instructions, to achieve uniform grading, as always at least 2 graders are involved. At least the inspera set-up need to be finished 10 days before the exam.</p>

<p>With the written exam scheduled for mid-January (the oral a bit later), all that needs to be done at a time of the year which is already filled up with <strong>grading</strong> the real exam, done in December and being graded till early January, resp. filled with giving feedback for the exam and preparing the new semester. That’s too much effort (especially if it’s for just a handful exams), and it’s basically not managable unless one has prepared already 2 exams in November. Consequently, many repeat exams (not only for IN2040) are oral.</p>

<p>In my eyes, it does not make oral exams a <strong>stopgap</strong> or <strong>nodløsning</strong>. It’s a valid form of exam for courses, independent from the number of participants. Of course with a growing number of candidates, there comes a point where an oral exam is more effort than a written one. Written exams, which may be more common at UiO, are officially called <a href="https://www.uio.no/studier/eksamen/inspera/">“skoleeksam”</a>, which, in my ears, sounds strange: we are a <strong>University</strong> not a school, and an oral exam is a valid form of examination at univiersties. One should not just be able to solve some little “exercises” that one has been trained to solve, but be able to explain concepts and shed light on a larger picture. Zoom exams and home exams under corona were a nodløsning, but oral exams are not; some of course may disagree, but I think anyway there is not one single form of exam that makes sense.</p>

<p>Anyway, it’s <strong>not</strong> that</p>

<blockquote>
  <p>an oral exam is like a written one, just oral and under enormous time pressure (each oral exam is planned for a time slot of <strong>40 minutes</strong>).</p>
</blockquote>

<p>The material and the pensum is of course the same, but an oral exam examines mastery of the material for slightly different skills. Consequently preparing for an oral exam and preparing for a written one is slightly different.</p>

<h1 id="about-this-text">About this text</h1>

<p>This post tries to give information about the oral exam, what to expect and how to prepare. It’s my view based on my personal experience. Experience from the time when I was a student and, of course, also from the many times I was examiner resp. assisting oral exams, like taking notes, doing the protocol, or being a sensor. In the Norwegian system, there exists the role of the <em>sensor</em>, some extra person who is able to understand what’s being asked and answered, and who plays a more influential role than just a silent note taker or witness.</p>

<p>Either way, I have been part of <strong>many</strong> oral exams, both as student as well as on the other side of the table. At earlier universities were I have been, outside Norway, oral exams in the computer science and physics curriculum were more common than here (at least at that time; I don’t know if that has changed). Basically, at master level, oral was the norm, below that level, written ones were also common. But even at lower levels, and even with large lectures, orals where likewise not uncommon, besides other exam forms like project work, (pro-)seminar presentations etc… At my first university, where I myself started, at that time beginner obligatory lectures had something like 450 or more students, and that’s a lot of orals…</p>

<p>So I’ve been to more than a handful oral exams as student, and, starting from my PhD-times, I must have been to literally hundreds or thousands of individual oral exams for quite a number of lectures of various sorts (my own or lectures of others).</p>

<p>The lecture here is <strong>functional programming</strong> with quite a number of technical content (like recursion, higher-order functions, environment model, evaluation strategies etc.), and focusing on <strong>problem solving</strong> (coding). That form of content influences to some extent the style of questioning.</p>

<p>Another influence is the <strong>examiner</strong>. I’ve seen quite a number of examiners, with different styles how to ask questions and how to structure the exam. Some give big freedom to the candidate, some favor precisely and narrowly formulated questions (maybe even written down) and expect a quite quick, narrow (and hopefully correct) answer. The style also depends on the content of the lecture. Some lectures are more about <strong>remembering</strong> stuff that has been covered. For instance I was a number of times involved in a lecture about communications architectures and network protocol layer standards, a lecture where one had a lot to remember), other are more about <strong>understanding</strong> concepts and/or being able to <strong>solve</strong> stuff. FP is more of the latter flavor. Below I will say a bit how <strong>I</strong> structure the exam and the form of questions and answers.</p>

<h1 id="what-to-expect-from-the-exam">What to expect from the exam?</h1>

<h2 id="goal-of-the-exam">Goal of the exam</h2>

<p>The topic is functional programming, resp. the aspects of functional programming (and not so functional programming) in Scheme covered by the lecture and SICP. The intent is to check <strong>breadth</strong> and <strong>depth</strong> of knowledge about that, the <strong>understanding</strong> of the concepts and checking the ability to <strong>solve problems</strong>. The goals influence the design of the exam (see below). Generally, we stress the <strong>understanding</strong> aspect.</p>

<p>To make an example: Let’s assume during an exam there’s the question “can you sketch an example of an environment model?”</p>

<p>If a candidate, who has thoroughly memo(r)ized everything, remembers the details of one of the figures that has been presented in the book or on the slides, draws the corresponding boxes, balls, and arrows, then that’s fine as such. But it’s expected that one can <strong>explain</strong> what it is. If the drawing is produced together with explanations what those boxes and arrows are and what it all means, that’s perfect. If one only remembers miracously the picture, but cannot explain even when asked, that’s not worth much. That’s a bit different in a written exam. Often one is just required to produce the answer, if its correct, it’s fine, no matter if the candidate knows what’s been done and can explain it or not.</p>

<p>That may sounds as if oral exams are harder. On the other hand, if the given solution contains errors (the picture from the example, or or some piece of code), that typically leads to deduced points; the errors are defects in the answer. Errors are of course don’t count positive in an oral one, but no one is expected to write don’t immediately a flawless answer. In a written exam, the end-result of an answer is graded (and one has decent time work out some answer and think it though and double-check it). For an oral, there is much less time, and it’s the <strong>process</strong> of arriving at an answer or solution or approaching it. If there is some error, there might be question (intended to clarify things), like: “look again at this arrow at the procedure object, it goes from where to where?” (maybe the arrow is the wrong way around or the arrow had is not drawn etc). And if the candidate then sees the error, explains what should have been there and why etc. then the whole glitch doesn’t count negative. As said, no one is expected to provide a flawess response on first attempt and without hesitation.</p>

<p>Of course, it depends a bit on how much helpful questions or outright help from the examinor is needed. If a halfway decent solution cannot be reached without major assistance from the sensor (giving hints, asking helpful questions etc), if that drags on too long that counts negative, already for the fact that it takes time and the amount of material that can be covered gets less.</p>

<h2 id="design-of-the-exam">Design of the exam</h2>

<p>The oral exam is a form of dialogue or interview with a fixed time. It’s also a <strong>structured</strong> or <strong>guided</strong> dialogue: the examiner asks and the candidate answers. It’s not 100% rigid, also the way the answers are given shapes the dialogue, leading to follow a up question, or resulting that the examiner gives help or hints, or tries to get to the answer by reformulating the question.</p>

<p>I have seem exams like this: at the beginning of the exam, the candidate is given one or maybe more than one question, and then having some minutes to think out or work out an answer or solution. During those minutes, perhaps the student is left alone to think undisturbed, before called back to present the solution.</p>

<p>We <strong>don’t do that</strong>, the questions won’t be of the nature that requires 10 minutes working out or solving something, resp. if it’s a question that refers to working out something, it will be like “how does one solve this-or-that”, and the intention is to see if the candidate knows how to approach the problems, which steps one would go through if one had the time, perhaps starting to <em>sketch</em> some steps, but mostly not carrying them through. There is simply not enough <strong>time</strong> to do that in many cases.</p>

<h3 id="covering-different-areas">Covering different areas</h3>

<p>As said, one goal is to check the <strong>breadth</strong> (to a certain extent). Of course we cannot ask everything, so there will be a selection. In other lectures, I often use 3 main sections of roughly equal duration (plus maybe a shorter general questioning section or side issues). For functional programming, it will be probably more, maybe <strong>4 sections</strong> or even more. Each of the sections is dedicated to one topic. Once the time for that slot is up, we shift to the next part: “ok, let’s move on to a different topic, say streams. For a start, tell me ….”. Strutcuring the exam that way is similar to the written exam; also there there is a number of problems, each covering mostly a specific area (sequence-operations, tail-recursion, procedure-based objects, streams etc), and some questions arranged in a number of sub-problems,</p>

<p>The reason why for functional programming (unlike for other lectures) are probably 4 sections or more, not 3 and maybe not as clearly separated is that the material and the kind of material does not lend itself too well to selecting 3 topics where one can go into deep.</p>

<h3 id="inside-an-topical-area">Inside an topical area.</h3>

<p>Inside some topical area, we typically try to steer the question from high-level to more low-level or more detailed ones. That’s to check the <strong>depth</strong>, how deep can we go.</p>

<p>At least in theory, since for some lectures that works better than for our lecture about functional programming. That’s because the material has not too much “conceptual depth”. It’s not meant to say, the lecture is not challenging or complex.</p>

<p>But if we start a line of questioning for “recursion”, one can follow-up with “tail-recursion vs. ordinary recursion and tree recursion”, but there’s not much “deeper” we can go in this linear line of question. One can dig deeper and pose a e questions involving <strong>code</strong> or maybe too, but that’s more or less how <em>deep</em> we can go. That means, even if <em>recursion</em> is a plausible question, the “field” is too small for one “section”, and in that section there will be other mildly related questions, but not necessarily deeper. If we also ask about tree recursion, or processes etc. it’s maybe in the same section, but it’s not really deeper, it’s just another question in that general area. So the questioning goes more sideways, not deeper sometimes. But still we want to structure and plan the session (per exam) somehow, not throwing random questions (small and big, from arbitrary places in the material) at the candidate.</p>

<p>Generally, trying to start a line of questioning from the top is done also for <strong>psychological</strong> reasons. If one starts right away with a very specific one, the chances are higher that maybe the candidates does not know the answer; that increases the nervousness, and then one may try a littler simpler, but still the answer not really going smooth, so in the end, the candidate cannot focus on anything else than thinking that already some early question were not done well, and that can influence the rest of the topic negatively. So, better is top-down, I guess (to the extent that’s possible here for our lecture).</p>

<p>Another reason why strict top-down lines of questionings, even if planned, not always works is that the answers shape the questioning. It can happen that I ask a question, and perhaps it turns out difficult to answer, so one backs off, making a more high-level or more general formulation instead, or a slighty other related issues (while sticking to the general “area”). That’s no immediate reason to worry either. To partly back off is meant to have something else to talk about, partly as assisting, because one can come back to the original question afterwards. When backing off a bit and talking about something a bit less specific or something slighty else, that often brings back ideas what is meant by the original question which then one can answer. It’s not uncommon, and as long as questions are answered it does not matter in which order.</p>

<h2 id="what-questions-to-expect">What questions to expect?</h2>

<p>I always say:</p>

<blockquote>
  <p><strong>The questions that will be asked are actually known!</strong></p>
</blockquote>

<p>Maybe not the exact wording of them. If one asks “look at this piece of code and tell me…”, the exact piece of code may not be known and vary. But apart from that, the pensum (the slides, the book, the exercises…) should give a comprehensive picture what will or can be asked.</p>

<p>Like: if there is a slide with header “memoizaition”, there can be a question “what’s memoization?”. If there is topical area or section called “<strong>streams</strong>”, so there can be a question “What’s a stream?”. The latter topic contains details like “delayed evaluation” and “implicit stream definitions”, so there might be in the exam the follow-up question “thanks for the explanation of streams, but can yo also explain implicit streams” (or give an example in code, or say what’s delayed evaluation is” or “We discussed <strong>memoization</strong> in the context of streams, can you elaborate? Maybe start what by saying what memoization is in general?” etc.</p>

<p>Being asked the original question about streams, a good way of answering it is, maybe after say what streams are in general is, to proceed by explaining also implicit streams or given an example or explain delayed evaluation. In other words: to <strong>“volunteer”</strong> additional elaboration instead of waiting until resp. if that follow-up will be asked. Remember: for most questions we don’t expect one-liners as answer, there is basically always meaningful further elaborations to add, and <strong>offering</strong> that (by continuing adding <strong>relevant related information</strong>) is good. If we think, that’s enough, let’s move on, we say so. Volunteering in this way for relevant elaboration does not only show that you know yourself <strong>what</strong> is additionally relevant for the questions, somehow getting the bigger picture and how things hang together, but (hopefully) represent also that additional material correctly. And that’s time used positively in the exam.</p>

<p>Of course, if one vaguely remembers, memoization was somehow discussed in connection with streams, but one cannot remember why that was and what memoization actually is, it’s a bad idea of course to volunteeringly mention “memoization” (because mentioning the word will trigger a follow-up), but rather hope the line of question stops there, or offering delayed evaluation of <code class="language-plaintext highlighter-rouge">stream-cons</code> instead (because one remembers that stuff). Or not elaborating on anything, waiting for whatever questions, if any, will be posed as follow-up (hopefully not memoization…).</p>

<p><strong>Offering additional relevant information</strong> is also good in connection with <strong>examples</strong>. For instance saying “Let me illustrate this with a small example”, that’s often a good way to demonstrate knowledge. And this way, you have <strong>control</strong> over the example. That may be preferable over waiting until or if the examiner ask “Look at this small example, can you explain the concept with it?” Already choosing a relevant, interesting example (and not too big) shows understanding. Of course, explaining a concept on a non-self-chosen example shows also understanding.</p>

<p>Now, back to the original point: <strong>what questions will there be?</strong>. I said, basically the questions are known (apart from details), and I mean it like that. In an earlier university where I worked as posts-doc, there was a professor from some other chair, who was known for publishing a long list of questions before the exam (on the internet and/or on the blackboard of his group, so the students could print them or make a copy). By coincidence, his lecture was about functional programming and it used SICP (I myself was not involved in the lecture, but was a few times involved in the exams about the material). Publishing the list of potential questions sounds weirder than it is.</p>

<p>Similarly, when I was a student myself, the student organization had collections of questions having been asked by this or that professor for this or that course. After surviving an exam, students were encouraged to note down the questions to the extent remembered during the exam (that’s not always easy) in order to help next year’s students. Welcome were also remarks commenting on the style of exam, like “that professor wants details, be careful, I had to solve things like XXX from the exercises in detail” or “the exam focused for me mostly on general stuff, I was over-prepared remembering tiny details and notation, but I was not even asked, but it went still ok”. After noting that down, one dropped that in the post-box of the student organization (nowadays via email or an “app” or a digital “løsning” no doubt…). So, when preparing for an oral exam, a smart thing to do was to go to the office of the student organisation for computer science, borrow the collection, and make a copy of the compiled questions of the last years.</p>

<p>So, since everything repeats more or less, the questions were more or less known. But even if a question is known, it may still be answered well or less well. And those lists where both helpful and, actually, not so helpful. They were not so helpful insofar that in principle, what’s being asked was clear to a good extent resp. should have been clear anyway. That’s why the public list of possible questions of the mentioned professor was not such a big deal. On the other hand, the lists were helpful. Not only because they contained (sometimes pieces of) information what kind of questions would typically occur and the style of exam, but giving the <strong>feeling</strong> one knows what to <strong>expect</strong>. Especially for the early semesters, if it’s one of the first oral exams, one could perhaps avoid loosing sleep speculating what on earth could happen. Seeing a (long) list of possible questions doen’t cut down the pensum, or make it easier to understand, but still it may feel more manageable.</p>

<h2 id="how-to-answer">How to answer?</h2>

<p>I mean, how to answer, beyond giving <strong>correct</strong> answers…</p>

<p>There are two points to keep in mind, one is the fact that the exam is <strong>time-limited</strong>. The second one is, that the questions almost never expect a <strong>one-liner</strong>. For illustration, assume a question “what’s tail-recursion?” and an answer</p>

<blockquote>
  <p>“That’s recursion at the tail!. End of message”</p>
</blockquote>

<p>That’s a, well, correct one-line answer, or at least a not incorrect one, but in this particular case is of course not very insightful either, almost an empty answer. So there will be a follow up, like “can you elaborate?”, or “what do you mean by tail?” or “what’s alternatives” etc. If the response to that is “What do you mean, I should elaborate in which way, can you ask more precise?” then the next question may be among other directions “What are other forms of recursion?” or “why is tail-recursion important?” or something related, just to obtain more information in connection with the initial question and to see whether the candidate understands what has been said.</p>

<p>This way of <strong>prodding</strong> interaction, trying to <strong>tease out</strong> information (with extra questions, help, or hints), is not ideal. For once it makes a better <strong>impression</strong>, if one elaborates relevant aspects in a structured manner oneself. Furthermore, it <strong>wastes time</strong>. Even if in the prodding-style, every single answer would ultimately be correct, not much ground would be covered. Before asking something more detailed or deeper or something else, the time for some batch of questions is over, and we start with a new line of asking, leaving many questions unquestioned.</p>

<p>Scratching only at the surface or covering only little ground, even if all answers are correct (or ultimately correct after trying to reformulate questions over and over), influences the outcome negatively.</p>

<p>For the same reason (avoiding waste of time), one should in answering <strong>not repeat</strong> information already given. Once answered, it’s done , and normally one gets signaled, that it’s answered (“ok, thanks about this, but what about that”) and then one should not say things about “this” again, maybe in different words: saying two times the same correct thing counts positive only once, the second time it’s a waste of time.</p>

<p>Of course not all follow-up questions by the examiners are <strong>prodding</strong> in a negative way, in fact many are not. So being asked an additional question as follow up is <strong>not</strong> a sign of having not volunteered enough elaboration. But if the questions consume more time than answers, it’s imbalanced.</p>

<h2 id="what-if-i-as-candidate-dont-understand-whats-being-asked-or-unsure-whats-expected">What if I (as candidate) don’t understand what’s being asked or unsure what’s expected?</h2>

<p>In such a case, just respond by “can you repeat/reformulate the question?” Or “Do you expect me that I do or explain the following?” “Does that question refer to ….?”.</p>

<h2 id="what-to-do-if-i-understand-the-question-but-dont-know-the-answer">What to do if I understand the question but don’t know the answer?</h2>

<p>Well, not ideal, but it can happen. One should avoid to panic, of course. I think it’s seldom that one is completely blank. One could either volunteer for information about (mildly) alternative and related issues (but one not already answered). Or putting it into more general context. Maybe that is accepted by the questioner, however, the original question will probably not be forgotten (“ok, thanks, that’s correct, let’s come back to the original question…”) But as long as correct and related (and not already covered) information is given, it’s not bad, better than saying nothing probably and waiting for the follow-up question which may be in the same direction.</p>

<p>Also, it may <strong>feel</strong> better than plainly saying “I don’t know” avoiding panic, and it may be the case, that while talking about on slight background- or side-issues in connection of the original question, in the back of the brain, the original question resp. an answer becomes clearer, and one can answer. That can be a good answering tactic, saying something relevant, but slightly off first, delaying slightly thereby and while talking the real answer comes to one’s mind. It can work. Of course, one should use it with care. So when asked about streams, one should <strong>not try</strong> an answer like “Streams are a topic in functional programming, so let me start by explaining what programming is and then functionanal programming …”. That form of digression is way off, but there is always a bit wiggling room.</p>

<h2 id="what-will-not-be-asked">What will not be asked?</h2>

<h3 id="no-trick-questions">No trick questions.</h3>

<p>From time to time, one has the impression, a candidate hesitates to answer a question, not because the answer is unknown but because a <strong>trap</strong> is suspected, a trick question. If the question is “what’s memoization”, then one sometimes see a dialogue like that (exaggerating for the purpose of presentation):</p>

<ul>
  <li>A: “what you mean!?! You mean just explain what it is or the definition?”.</li>
  <li>Q: Yes sure.</li>
  <li>A: “You mean like explaining in words? or making an example?”</li>
  <li>Q: “Yes, sure, whatever you prefer.”</li>
  <li>A: “An example, is it allowed to use one from the lecture?”</li>
  <li>Q: “Yes, sure, if you remember one from the lecture, fine, or a different one, but don’t make it too complex”.</li>
  <li>A: “So a small example would be enough?”</li>
</ul>

<p>In such situations, one has the impression, the candidate fears “there must be more to it, I understand what what’s being said, but that’s too obvious, I wonder what they <strong>really</strong> mean with this question, if I just say what memoization is, it’s probably a trick”.</p>

<p>But it’s <em>never</em> a trick question. It’s said, that some companies in IT use <strong>fancy</strong> questions. Microsoft especially is said to employ those as part of their recruiting (there are whole books collecting questions preparing for interviews with Microsoft or other companies that use that technique, like “how many ping-pong balls fit into an oil tanker?” or strange puzzles and brain teasers). Those questions are supposed to require imagination, improvisation, thinking on the spot and, an all time favorite “<strong>thinking out of the box</strong>”. There’s no thing as thinking out of the box at a university <code class="language-plaintext highlighter-rouge">;-)</code> So questions posed are meant the most <strong>obvious</strong> way. The task is not to guess or detect the hidden meaning behind a question, <strong>it’s to answer it</strong>.</p>

<p>At least a question is <strong>intended</strong> to be obvious and we don’t intend to speak in riddles. Whether the question factually <em>is</em> obvious, however, depends also on the one being asked. But if in a question like “what’s memoization” the word “memoization” remains unclear, that would be a sign of not having studied or understood that part and does not make the question a riddle. The normal reaction in that case would not be the above dialogue, it’s more like “I don’t know the answer, I skipped that part”, or “I can’t remember details, I just remember that…”.</p>

<h3 id="no-long-blind-alleys-and-maybe-no-too-long-thoroughfares-either">No long blind alleys (and maybe no too long thoroughfares either)</h3>

<p>When we see that a question is misunderstood or the answer goes into the wrong direction, we “intervene”. So, it will <strong>not</strong> happen that a answer runs for minutes down a <strong>blind alley</strong>, and after the answer is given, we say, thanks, and note it down as answered all wrong (and having wasted precious time). So we try to correct the course, and put the answer back on track.</p>

<p>That does not mean, that the millisecond the answer goes wrong, we shout “stop!”. I believe, being interrupted abruptly a few times in mid-sentence can cost nerves. So we keep our horses for a short while, until the answering sentence is finished or something, and only then interfere in some way. Note that if the answer is slightly off, we might let it pass and let the explanation take its course slightly longer, even if it does not 100% fit to the question asked (but we are still happy). In that case, since we are ok with the answer anyway, this would not count negatively or as “answer not given”. We might afterwards try to come back to the original question, or maybe not.</p>

<p>In case the answer is correct and well-formulated, on track, and proceeds smoothly, more interesting information is added etc., then we may <strong>let it run</strong> for a <strong>short</strong> while. Still we may pose additional questions, or also try to redirect or stop the argument. Sometimes we stop, because we have seen enough, it’s all good, the candidate sure knows the answer and the field, so no need to continue. Or if the argument, while still ok, has run it’s course, and the answer starts going in circles or covering ground that is more or less explored, so does not add much new information and it becomes a bit a waste of time. So we move on.</p>

<p>Finally, it sometimes happens that the argumentation goes <strong>too slow</strong>. For instance, one could see that sometimes when asking for an example or when the candidate offers an example: “let me sketch it with a piece of code or a figure”. In principle, that’s all good. But then, line by line, letter by letter, parenthesis by parenthesis, a code snippet slowly unfolds on the whiteboard or paper, hesitantly checking and rechecking the parentheses. That sometimes results in a bad use of the time, a low information transmission rate, so to say, especially, if someone works on the whiteboard <strong>silently</strong>, without additionally sharing information on what is being done and why.</p>

<p>Anyway, being “interrupted” in one way or the other or having the course of an answer re-directed is not necessarily a sign of a wrong answer, indeed, it’s quite common.</p>

<h2 id="can-i-answer-with-stuff-i-know-outside-the-pensum">Can I answer with stuff I know outside the pensum?</h2>

<p>That’s quite <strong>tricky</strong>, resp. it depends. You are not expected or required to know things outside the pensum, and we don’t pose corresponding questions.</p>

<p>If you <strong>know</strong> material outside the pensum, that you are sure is <strong>relevant</strong> for the question, and if you are sure that the examiners can <strong>understand</strong> what you are offering or at least get the clear impression that <strong>you know</strong> what are talking about and also get the impression that your answer is relevant for the question, then one may try that. If you happen to impress the examiners with relevant extra things outside the curriculum that nonetheless fit to a question, that counts in your favor.</p>

<p>Having said that: this is of course <strong>not</strong> (!) an advice to read up on all kinds of extra-curriculum stuff planning for a shock-and-awe strategy, dazzle the examiners with all kinds of additional related stuff. That has a very low return-on-investment ratio and may easily backfire… If one happens to know such extra stuff for one particular question or other for whatever reason, why not.</p>

<p>What one should definitely <strong>avoid</strong> is to offer <em>alternate</em> material <strong>instead of pensum material</strong>.</p>

<p>This quite seldomly happens, but still one sees it happening. Like “I don’t know what a message passing is according to the lecture, but I stumbled upon an interesting article on message passing on Wikipedia/on some paper” or “I could explain it for <a href="https://julialang.org/">Julia</a>; I like that language, and you sure know it too, right?”. Sometimes, it might not be a problem (but very seldomly so). One might for instance be tempted to try to illustrate tail-recursion, abstract data types etc. also with other languages (if one happens to knows that and is shaky on the SICP coverage) . To that extent it’s partly answered (to the extent that one has shown understading of tail-recursion etc). However, the lecture discusses those concepts with <em>Scheme</em> and that is also part of the pensum and material. At any case, answer deviating from the pensum or from halfway conventional terminology may to the least slow down communication, it may lead to misunderstanding and all that is not good.</p>

<p>Actually, it does not happen offten but sometimes people seem to use “alternative” explanations or definitions as <strong>evasive tactic</strong> claiming “but in some other book, message passing is used differently”. <em>Argumentation</em> like that is ill-advised, at least during the exam (it happens now and then), to the very least it wastes time. And as examiner it’s normally easy to see through that, if it’s used as evasive tactics. If there is really a significantly different definition from somewhere, maybe outside SICP or computer science and someone really know that material, then it’s not even relevant, and trying to explain what the alternative definition means may be successful (and in the end the examinor believes the candidate knows what’s being talked about), but also that wastes time (and is still probably irrelevant). Anyway, when it goes into that line of answering and we are not happy with that, we intervene anyway (as explained).</p>

<h2 id="how-fast-should-i-answer-how-long-should-i-think-before-the-answer">How fast should I answer, how long should I think before the answer?</h2>

<p>One should <strong>not</strong> feel obliged to <strong>blurt out</strong> an answer. Sometimes one sees candidates, they start talking before a question is even finished; there is not much gained by that. Better carefully listen to what’s being asked till the end of the question. And perhaps taking a breath while collecting one’s thoughts.</p>

<p>However, there is not much gained either in <strong>remaining silent for a long time</strong>, until one has found the <strong>best way</strong> to say things. There is no <strong>best answer</strong>, so no need to try to formulate one silently in one’s head, and start speaking only after the perfect one is mentally chiseled out. The only situation where I can imagine a “best” answer exists is for very precise and narrow questions: “Is this procedure tail-recursive or not?” “yes”, ‘nuff said. Actually, nothing wrong with saying something like “Let me see, here’s a procedure <code class="language-plaintext highlighter-rouge">proc</code> it calls itself here and here, and at this place it’s called inside a <code class="language-plaintext highlighter-rouge">cons</code> and therefore it’s not tail-recursive”. That’s a bit longer, but maybe even better (if not dragged out too long).</p>

<p>So for a question like “is this code tail-recursive or not””, one could of course say yes or no. If tail-recursion has not already been asked and answered, one could shape the answer like “Tail recursion is a specific form of recursion. It’s characterised by the fact ….blabla”. Maybe even offer its advantages, before coming to saying specifically something on the shown code. If the question is answered by a short “yes” or “no”, the <strong>follow up</strong> will anyway be (if tail-recursion has not been covered as concept already)</p>

<blockquote>
  <p>“why you think it’s not tail-recursive, can you elaborate, maybe start by saying what tail-recursion is?”.</p>
</blockquote>

<h2 id="how-precise-should-my-answer-be-resp-how-evasive-should--i-answer">How precise should my answer be, resp. how “evasive” should  I answer?</h2>

<p>Well, the more concise, the more to the point etc. the better. However, it depends also on the question. Some questions are more “loose”. So the precision of the answer should somehow fit to the precision of the question. To respond to a question</p>

<blockquote>
  <p>explain the concept of environment models</p>
</blockquote>

<p>by</p>

<blockquote>
  <p>let me start by illustrating the notion of interpreter, because Scheme is a interpreted language, so that I can more clearly position the role of the environment model afterwards…”</p>
</blockquote>

<p>is probably not a good move (besides the fact an actually environment models or run-time environments apply to compilers (and other languages, not just Scheme) as well). The reaction from the examinor will probably be, “wait a second, could you stick more closely to the question”. Offering to start by shedding light on a super-broad context feels like evading the question. And maybe hoping the question will be forgotten. Even if somehow I would let it slip, like allowing to starting with a broader context, the question will typically not be forgotten (except that in the end, time’s up, like being “saved by the bell…”). But it depends on the deviation. For instance, if the question is about <strong>streams</strong>, an answer starting like</p>

<blockquote>
  <p>“let me first shortly explain what evaluation strategies are, specifically what delayed vs. non-delayed evaluation means, before I clarify what it has to do with streams”</p>
</blockquote>

<p>that’s is probably ok (again if evaluation strategies have not been covered already), maybe even good because it shows that one knows that streams have something to do with delayed evaluation. Trying to shed light on the even broader of “interpretation” of programming languages or similar on the other hand would stretch it. Also starting by</p>

<blockquote>
  <p>Let me first explain first the substitution models before I come to the environment model</p>
</blockquote>

<p>feels evasive (though it shows knowledge that both model have some connection). Starting by explaining the environment model, addressing the question, and afterwards offering “this is more general than the so-called substitution model, namely in the following way…”, that’s not too bad, so one might be lucky to be allowed to continue explaining.</p>

<p>In general, as mentioned before, one should <strong>not ponder silently</strong> the best answer for long. Mostly there is no such thing than the <strong>best answer</strong>. Starting to say something meaningful and related things in the direction of a useful answer is preferable over remaining silent for long stretches. Silence counts for not much, saying something correct and in response to a question counts positively, even though one could have said it better or shorter or more understandable, given enough time to polish the answer. Therefore, also doing an <strong>mistake</strong> during an answer (especially if it’s about details of code) does actually count negative, everyone makes errors, provided one is able to either spot the error, resp. if the examiner points to it, recover from the error. It’s checking that you <strong>know</strong> and come up with the answer when thinking about it, not if you can know the answer by heart and immediately blurt it out fast in a stressful situation.</p>

<h2 id="what-kind-of-reactions-to-expect-from-the-examiner">What kind of reactions to expect from the examiner?</h2>

<p>I don’t have recordings of what <strong>I</strong> am saying or how I behave during the exam. So it’s just an “introspective” statement of what I intend to do and what I think I do. During an exam, I (and the sensor) must focus on the questions and answers, on what exactly is said, <strong>all concentration is on that</strong>. That’s also the reason why doing an oral exam is actually pretty exhausting (being questioned in an exam of course, as well). Anyway, one has no mental capacity to observe oneself. Afterwards, one can try to reflect on it, or the sensor remarks things (“I think your second question was not very clearly formulated” or “you should give the students more (or less) time to answer”, or whatever). But not during the exam.</p>

<p>Anyway, as examiner one gives <strong>feedback</strong>. Of course, when a candidate asks something like “can I illustrate it with an example?”, one says no (or more probably yes), that’s obvious.</p>

<p>But also without being asked there is feedback, an exam is also a dialogue, not an iterated monologue. There’s a couple of things I try to keep in mind. First, I don’t want to be too <strong>negative</strong>. I don’t want to communicate by body language, facial expressions, or words that it’s going bad, even if it is. Of course, if a question is misunderstood or an answer goes in the wrong direction, I need to try to put the answering process back on track (see the paragraph called “no dead alleys”). That’s done by words (“ok, I understand, before you continue, let me repeat and reformulate the question”), not by frowning, exchanging glances with the sensor and sharing a chuckle, or a face palm…</p>

<p>Actually, I have the impression, that a few candidates try to “read” the examiner, consciously or probably unconsciously. That may divert mental capacity from answering the question to the attempt to getting a feeling if the examiner is “happy with the answer”. But maybe some people have antennas for that and it’s natural and comes easy for them, I don’t know. Sometimes one sees people tentatively saying a partial answer, hesitatingly, without committing themselves, as if <strong>fishing for hints</strong> in which way to continue. I don’t know how successful it is, especially when it becomes too obvious… Anyway, try not to give too obvious body-language signals of what I think of an answer.</p>

<p>One the other hand, doing a complete robot-like poker-face during the exam to prevent fishing for answers is not possible. On top, it can create an <strong>uneasy atmosphere</strong>. It’s hard to talk to someone without receiving a slight nod here and there or a “Hmhm, ok, I see”. One can make people feel uncomfortable even stressful when showing no reaction at all. There’s even a name for it, it’s called the <strong><a href="https://en.wikipedia.org/wiki/Silent_treatment">silent treatment</a></strong>…</p>

<p>So we don’t do it. The above reactions like “ok, fine” or “Hmhm, I see” are <strong>not meant</strong> as “that’s correct” or “that is what I want to hear” as answer. As bottom line, “ok” simply means, I am still following, I have heard and understood what’s being said, and if I don’t intervene beyond “ok”, then I see not need for ending that line of answering.</p>

<p>If I say “ok, that was correct”, or “ok, very good”, <strong>that is confirmation</strong> that the answer was correct. Actually, people mostly don’t need this confirmation to <strong>know themselves</strong> that their answer is correct; but there’s no harm in saying it anyway. On the other hand, most people are also aware while answering when the answer is not correct or evasive, or wishy-washy or delaying the real answer, or when unsure about the answer. So one does not have to explicitly state “ok, you were swimming here”, people mostly are aware of that, I think (I know that for a fact for myself). I could say “ok, let’s look more concretely at…”. But the latter could also be asked as just follow up for more information, it’s not necessarily meant as to communicate “I think you’re swimming”.</p>

<h2 id="are-these-hints-useful-in-any-way">Are these hints useful in any way?</h2>

<p>Perhaps they are, perhaps you think “ok, good to know”. On the other hand, if you think about those pieces of observations, they might actually not really useful for <strong>preparing</strong>, like giving <strong>actionable advice</strong>. They just describe behavior that I see repeatedly during oral exams, some with positive effects some with negative. But there is anyway <strong>not just one proper way of answering</strong>, different people handle dialogue differently. For instance, when saying, it’s better not to blurt out an answer before even the question is finished, but it’s also not good to remain silently for five minute before coming up with a crisp and to-the point one-liner, well, sure. But it does not give guidance like “during exam, I should collect my thought for 10 seconds, that’s the best and recommended”.</p>

<p>That specific advice makes no sense, and one is not graded for how many seconds it takes to start an answer, for instance. But the <strong>smoothness</strong>, <strong>structuredness</strong> and, of course, <strong>correctness</strong> of an answer counts. And of course, if every small answer takes 10 minutes, not much ground is covered, and that’s also negative. The fact that answers come super-slow is mostly a <strong>symptom</strong> of not being familiar enough with the material. So it <strong>cannot</strong> be addressed (during preparation) by <strong>training how to speak quicker</strong>, it’s addressed by <strong>learning the material better</strong>.</p>

<p>That answers come slow (or hesitatingly or not directly or with a lot of hints etc) may have also a slightly different reason. There is to some extent the phenomenon “I know the answer, but I don’t know how to say it” (though I maintain to understand something really means to be able to explain it). This “I cannot properly say it” effect that can be addressed, and I talk about it in the “How to prepare for the exam?”.</p>

<h1 id="how-to-prepare-for-the-exam">How to prepare for the exam?</h1>

<p>Having discussed what to expect, the question is how to <strong>prepare</strong> for the exam. To some degree, it’s the same as would be for a written exam. The usual general advice, start-in-time, follow the material to some extent during the semester etcetc. Nothing new there.</p>

<h2 id="first-things-first-know-your-stuff">First things first: Know your stuff!</h2>

<p>That’s clear and generally not different from other forms of exams. There are, however differences what it means to know one’s stuff.</p>

<h2 id="drawing-a-parallel-to-written-exam-preparation">Drawing a parallel to written exam preparation</h2>

<p>Written exams can be <em>“open book”</em> or <em>“closed book”</em> exams (for FP it traditionally closed book). For open-book exams, certain questions make no sense, like “what’s memoization”. But for open book exam, it obviously makes no sense to ask that question.</p>

<p>But even being closed book, the written exam for FP is mostly about <strong>solving problems</strong>, similar to the ones from the exercises or obligs. A collection of the written exams of previous years is also available, so one can look at the kind of questions that have being asked.</p>

<p>Those problem sets are intended for a <strong>4 hour exam</strong>. The question are estimated to be solvable within 4 hours, <strong>provided</strong> one has solved or tried at least similar problems before, as preparation. Just “knowing the concepts” from the lecture without ever having done exercises oneself will probably be not good enough for a smooth sailing through the 4 hours (not even if it would be an open-book exam).</p>

<h2 id="anticipating-the-exam-and-planning-the-battle">Anticipating the exam and planning the battle</h2>

<p>Why talking about preparing written exams, when here it’s about an oral one. Because the underlying principles of how to prepare are the same. Some vary. Knowing the stuff, as said, is still the basics.</p>

<p>As mentioned, time is too short to solve a complete new programming task like one from a typical written exam, but still, there may be questions about “how to do this or that?”. That means one know how to address a problem, the direction of problem solving, something I sometimes called <strong>battle-plan</strong>.</p>

<p>Especially in a oral exam, if there are algorithmic problems to address, it’s not <strong>fancy</strong> ones, no problems that are large, or that requires some clever insight, no puzzles to be solved. It’s a bit like what I discussion also about <strong>“no trick questions</strong>”.</p>

<p>So there are standard problems, and one should be aware without much hesitation with what Scheme patterns one could address them (like when working at a list, one needs to do a list recursion, and one knows what typically the base case and the recursion case(s) is or are, and one has not to search long for such concepts).</p>

<p>One can then explain the problem, explain what steps should be taken, and why, while trying to sketch the code while taking. There is typically no time to actually code a fully a runnable solution (e.g. I will say: good enough, it’s fine). The point is to convincingly give the impression:</p>

<blockquote>
  <p>I <strong>can solve</strong> that, given enough time, with techniques from the lecture, and I can explain the steps it takes to do it.</p>
</blockquote>

<p>Concretely solving it as in a written exam, of course also gives a convincing impression that one can solve it, but that takes too long time.</p>

<p>Not all or not even the majority of questions in the oral will be problem solving, there will be also <strong>conceptual</strong> questions. Like: “what’s tail recursion? What’s memoization?” Those may lead to code or “programming” problems, of course.</p>

<p>Conceptual question also those need (additionally) a battle-plan of a slightly different kind than the problem-solving battle plans, like “when being asked about memoization,</p>

<blockquote>
  <p>What concretely do I say, how do I structure my answer? Which example will I offer. If I don’t offer an example, what will I say if the examinor asks me for one. What else could I say in that connection?, Do I know what memoization is good for?</p>
</blockquote>

<p>The battle plan is not reading about memoization one more time and nodding and thinking “all right, I think I get it”. It’s about being prepared for <strong>exam situation</strong>, <strong>anticipating</strong> it. Trying to concrete think about “what concrete words will I use when asked about memoization?”, even verbalizing it loud or writing it down: It’s more than . It’s good to “get it”, better is to double check “can I speak about it and explain it”. It’s like with preparing for a written exam. It’s not idea to read exam questions or exercises, read up the solution and nodding and thinking “all right, I think I get it”.</p>

<p>So hen preparing, one has to ask oneself “can I speak meaningful, relevant (and correct) things, for some time answering that question?”. Ideally in some structured form, like starting generally, going deeper, sketching some example etc. This may not the only way one can structure an answer, there can be others, but in general some structure is better than no structure, like hopping from one small piece of concept to another one, just in the order they pop up in the mind.</p>

<p>Even if they know one’s stuff, its for most not ideal if the actual exam is the very first time the words come out of the mouth. That’s what I meant that it’s a bit like</p>

<blockquote>
  <p>I know the thing you ask, I really do, but I never thought about how to say it, therefore I have a hard time now collecting my ideas, aligning my thoughts and actually saying it.</p>
</blockquote>

<p>Some people are naturals, knowing the stuff means directly being able to lay it out in words clear and crisp on any given topic. But not for everyone. Sometimes one hears (not just in the context of exams) things like “I know it basically very well, I just cannot say it”. That dubious. I really believe: if one really <em>knows</em> something, one can to some extent explain it, even if it may not be elegantly formulated, one may stutter or the answer is rather unstructured, but still, one can communicate it. In an exam, a messy answer (that may additionally need lot of help) is kind of a proof that the candidate “knows” the answer, and can “explain” it, but it still counts less as a smooth explanation.</p>

<p>But what I believe or not is actually not too relevant: An answer like “I know it but I cannot say it or write it down” (no matter the help) is not worth much. Even if it were true, how could one know.</p>

<p>That form of preparation helps in more than one way. Firstly, as said, it’s typically not a good idea if the actual exam is the first time one searches for words to express something. Secondly, if one is critical to oneself, the attempt to really say things can show where one perhaps should read up a bit more. Finally, just the fact that one forces oneself to verbalize stuff in an clear way helps actually <strong>learning</strong> the stuff itself. It’s not the only way to learn it, but it contributes.</p>

<p>Same can be the case <strong>writing</strong> it up in one’s own words. Of course that takes time, it’s not clear if that would be an efficient use of preparation time.</p>

<p>One could also try to compromise: not writing up everything, but condensing a topical area into a number of items, keywords or memorizable cues. That requires focusing on the important stuff, organizing and structuring it, distilling it, perhaps writing it up with tiny handwriting to a small memo paper or sticky note. That’s of course the good old <strong>cheat-sheet</strong> technique. Organizing material in such a way is a good way of memorizing it, and one can go through the cheat-sheet memos before the exam.</p>

<p>Of course, using cheat-sheets in the exam is not allowed (but for an oral it does not matter as one cannot use them anyway). But writing cheat-sheets and using them to learn, I think is still allowed…</p>

<p>I stressed that verbalizing answers is, in my eyes, a good thing. Additionally, I think, a very good way of verbalizing it is not for oneself, but with one or more fellow students, so</p>

<blockquote>
  <p>Explaining concepts <strong>to others</strong> in a good way of preparing. One can even play examiner and examinee. Both profit from that. The examinee is forced to give answers, and what is being asked is controlled by someone else (the “examiner”). Also for the examiner, already listening to the answers repeats the material, and one can learn from it (“That’s a good way for answering, I should remember that for my self”). The examiner can give constructive criticism, but already a “Frankly, that was pretty confusing, I did not get it” may be helpful.</p>
</blockquote>

<p>I think everyone profits from such a thing. Already going through the material (speaking or hearing) is a repetition. This form is <strong>not a replacement</strong> of first-time learning. One must have a certain level of learning progress and understanding before explaining things to each other or doing a mock exam. That’s clear, if no one has read Chapter 3, one cannot explain it to each other. Also if only one has read it but not the other, it may feel a bit <strong>unfair</strong>, so everyone should have at least some understanding.</p>

<h3 id="some-remarks-as-reaction-to-the-written-exam-2023">Some remarks as reaction to the written exam 2023</h3>

<p>The written exam, as basically always, also had some <strong>conceptual questions</strong>, This year, one small question of that type was <strong>what’s a procedure object?</strong>. That was the very first question, and there were some others later)</p>

<p>This question was answer disappointingly. Fact is, it was the question with the <strong>lowest percentage point score</strong> of the whole exam. To some lesser extent the other conceptual questions were answered not well.</p>

<p>For an oral exam, where conceptual questions that will play a larger role than in a written exam, the unability to <strong>explain</strong> things like that is problematic. In the written exams, where those questions had not many points riding on it, not much damage was done if one cannot say what a procedure object it. In an oral exam, the inability to explain things weighs heavier.</p>

<p>As illustration, let’s take a concept that everyone “knows”: <strong>recursion</strong>. That’s almost never asked in a written exam, one just assumes that everyone knows. Many of the coding problems in the exam will use recursion, and if one sees as grader that those problems are more or less solved, one can conclude the candidate can solve problems that involve recursion. And in that sense recursion is “understood”.</p>

<p>In an oral exam, one may start a line of question by just throwing in the question</p>

<blockquote>
  <p>What’s recursion?</p>
</blockquote>

<p>maybe intended as a soft-ball, warm-up question. Being unable to answer that makes a bad impression, probably worse than having missed maybe 2 out of hundred points that such a simple question would have harvested in a written exam.</p>

<p>The question (also in an oral exam) is intended as an easy one that should take not much time. Therefore, the best answer itself should be not concise (= not too long, correct, and precise). Of course, as explained, one could extend the answer by volonteering to add information about tail-recursion etc., but that’s not the same as being imprecise or short.</p>

<p>The lecture material seldomly gives explicit <strong>definitions</strong> (as one can sometimes find in theoretical, mathematical, maybe alor also other kind of lectures (maybe from the law faculties ect). So there is no statement one-liner in bold face, preceded by the something like “<strong>definition 2.3.5</strong>” like the following that one would be expected to <strong>remember</strong> (and perhaps reproduce) as the one and only correct one: <strong>“Being recusive for a procedure means it calls itself in its body, directly or indirectly. End of official definition</strong>”</p>

<p>But when asked the answer(s) and the follow ups are graded how well what’s being said is correct and shows understanding of the material. And clear and concise and structured is better than, well, unclear, wishy-washy, or confusing.</p>

<h3 id="what-about-code">What about code?</h3>

<p>A written exam is to a large part about coding small examples. The text and advice here contained large parts about how to structure answers, how to answer, and how not and how to prepare for an oral situation. As illustrations, often I used conceptual questions (“What’s memoization?”). It reflects the fact that such conceptual questions and examining for understanding concepts plays a larger role. And that there’s no time for posing an written-exam-style coding question and wait until it has been solved.</p>

<blockquote>
  <p>But that does not mean that code or sketching code or understanding code does not play a role in an oral exam.</p>
</blockquote>

<p>It will mostly not involve problems that need some challenging insight in the underlying problem itself. An example from the written exam might be the <strong>charity</strong> question. It had conventional patterns (let-over-lambda, procedure-based objects etc) that had been thoroughly covered, but also a twist, namely the two layers of encapsulation.</p>

<p>So solving it would including mastering the known patterns but applying it to a (mildly) novel situation. In the oral exam, the weight will not be on applying Scheme to really novel problems, but to more standard ones (however no garantee that all code examples show up literally on a slide or similar). Also the “coding question” may be not to code or sketch some Scheme code by the candidate, but that the examinor shows some code (which one may have seen in this or similar form), and asks to explain what the code does. The purpose is not to check if one remembers the code, but to see if one understands small pieces of code following known patterns from the lecture and one can make sense out of it conceptually. So a not-so-good answer is to “explain” things like “in the first line there is a <code class="language-plaintext highlighter-rouge">define</code> and it defines <code class="language-plaintext highlighter-rouge">fac</code> which I remember is something the lecture called factorial and then there is a newline and a parenthesis, and then an <code class="language-plaintext highlighter-rouge">if</code> following by more parentheses”. I am exaggarating for the purpose of illustration, but such low-level “explanations” show no deep understanding of what’s going on.</p>

<p>But also for possible questions or answer involving code (either when asked for code or as part of a conceptual question or when asked to explain a given piece of), one can prepare by anticipating that: “If I am asked to explain tree-recursion, and I am asked to give an example, which one would I take, and how would I sketch it and what do I say”.</p>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="exam preparation" /><category term="oral exam" /><category term="functional programming" /><category term="SICP" /><summary type="html"><![CDATA[like for instance for the functional programming course.]]></summary></entry><entry><title type="html">Implicit stream definitions</title><link href="/functionalprogramming/2023/12/05/implicitstreams.html" rel="alternate" type="text/html" title="Implicit stream definitions" /><published>2023-12-05T00:00:00+01:00</published><updated>2023-12-05T00:00:00+01:00</updated><id>/functionalprogramming/2023/12/05/implicitstreams</id><content type="html" xml:base="/functionalprogramming/2023/12/05/implicitstreams.html"><![CDATA[<p>The post was triggered by working out some solution to an older exam question (from 2017), about streams. This is not a straight answer to that exam question, for that it’s much too long, but it touches on different issues that are connected to streams, evaluation strategies, and it sheds perhaps some light on the two models discussed in the lectures.</p>

<p>So, starting point is streams, in particular streams define in a particular way, called <strong>implicit</strong> stream definitions in SICP. Those are introduced in Section 3.5.2 which discussed infinite streams. Maybe the simplest example is an infinite stream that repeats the same value over and over again:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">define</span> <span class="nv">ones</span> <span class="p">(</span><span class="nf">cons-stream</span> <span class="mi">1</span> <span class="nv">ones</span><span class="p">))</span>
</code></pre></div></div>

<p>That’s a recursive definition, in the sense that something, namely <code class="language-plaintext highlighter-rouge">ones</code> is defined in terms of itself. However, it’s in a form that “under normal circumstances” is illegal in Scheme. Especially illegal is if one used <code class="language-plaintext highlighter-rouge">cons</code> instead of <code class="language-plaintext highlighter-rouge">cons-stream</code>:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">define</span> <span class="nv">ones-gone-wrong</span> <span class="p">(</span><span class="nb">cons</span> <span class="mi">1</span> <span class="nv">ones-gone-wrong</span><span class="p">))</span>
</code></pre></div></div>

<p>Scheme, of course allows recursive definition, and as a functional language, one may even say, encourages them. But conventionally those are only acceptable when defining procedures, namely when a procedure calls itself in its body, or when a bunch of procedures calls each other in a pattern of mutual recursion. <code class="language-plaintext highlighter-rouge">ones</code> is not a procedure, and by looking at it, it is not that <code class="language-plaintext highlighter-rouge">ones</code> “calls itself”. Being not a procedure, no one can call it (and actually when one is mentioned on the right-hand side of the definition.</p>

<p>As a cautionary side remark: a nitpicking or paranoid mind may object that we don’t actually know whether <code class="language-plaintext highlighter-rouge">ones</code> is not a procedure. How so? We discussed that pairs can be implemented by higher-order procedures and that the built-in interface of <code class="language-plaintext highlighter-rouge">cons</code>, <code class="language-plaintext highlighter-rouge">car</code> and <code class="language-plaintext highlighter-rouge">cdr</code> (actually also <code class="language-plaintext highlighter-rouge">set-car!</code> and <code class="language-plaintext highlighter-rouge">set-cdr!</code>) can be (re-)implemented using higher-order procedures. When doing so, <code class="language-plaintext highlighter-rouge">cons</code> would return a procedure that behaves like a pair. We remarked that this is probably not the way that the built-in pairs are actually implemented. But when pairs are seen as an abstract data type with its constructors and selectors, its internal representation is hidden and without actually knowing how pairs are internally implemented, how can we claim that <code class="language-plaintext highlighter-rouge">ones</code> is not ultimately a procedure. For all we know, it might actually be the case. More on it later. For now, we accept that <code class="language-plaintext highlighter-rouge">ones</code> is not secretly a procedure (which is of course a fact in standard implementations).</p>

<p>Back to the stream-example, the definition of <code class="language-plaintext highlighter-rouge">one</code>. Such definitions are called <strong>implicit</strong> stream definitions (as opposed to the more “transparent” and less puzzling way of getting a stream, namely using a stream-generating procedure.) Calling it implicit of course not an explanation. Neither is it a full explanation to say Scheme (under normal circumstances) allows recursive patterns only for procedures. Of course one can take the latter at face value, but that gives no insight on why the definition of <code class="language-plaintext highlighter-rouge">ones</code> work, but the for <code class="language-plaintext highlighter-rouge">ones-gone-wrong</code> does not.</p>

<p>To look deeper we can turn to the models for expression <strong>evaluation</strong>. More concretely, we can look at it from the perspective of the <strong>substitution model</strong>, as the example does not involve side effects, and the <strong>environment model</strong>.</p>

<h1 id="substitution-model">Substitution model</h1>

<p>We start with the substitution model, being simpler and all. The substitution model is introduced in Section 1.1.5 of SICP, but looking at that we might realize the the expositions in the book is a bit wishy-washy resp. does make explicit all details which we would need to understand what’s going on with <code class="language-plaintext highlighter-rouge">ones</code>. When introduced in the book the model is used as explanation mainly for parameter passing and evaluation order, but the examples in that Section 1.1.5 are all <strong>without recursion</strong>. Neither is the treatment of <code class="language-plaintext highlighter-rouge">define</code> in the substitution model in the focus of the discussion, its mostly about parameter passing. Later, in Section 1.2 the substitution model is used to illustrate patterns of processes and there, the procedures there indeed are recursive. But the exposition is illustrative and handwaving: it uses for instance <code class="language-plaintext highlighter-rouge">fac</code> and <code class="language-plaintext highlighter-rouge">fac-iter</code> and the resulting processes using repeated substitution, without discussing explicit when to substitute. The question of <strong>when</strong> to substitute is a question about evaluated <strong>strategy</strong>, and that is not the focus of that later section 1.2, the focus is on dicussing the “shape” of iterative and recursive processes. The examples just shows what’s going on, and its plausible enough, but maybe here we want to point it out more explicitly</p>

<h1 id="why-is-sicp-wishy-washy-about-define-when-disucssing-the-substitution-model">Why is SICP wishy-washy about <code class="language-plaintext highlighter-rouge">define</code> when disucssing the substitution model?</h1>

<p>Of course I don’t know, so it’s a speculation. And actually SICP is very concise, so maybe “wishy-washy” is a bit tongue in cheek. The discussion of the substitution model is precise in what is being discussed, it’s only that -<code class="language-plaintext highlighter-rouge">define</code> is not really the focus. We know that the substitution model <strong>breaks down</strong>, when introducing <strong>mutation</strong>, like <code class="language-plaintext highlighter-rouge">set!</code>, or <code class="language-plaintext highlighter-rouge">set-car!</code> etc. That comes later in the book and the lecture, and we move on to the more complex environment model. So one might suspect that with Scheme, as presented up to that point, we are <strong>purely functional</strong> and we can understand everything based on the substitution model.</p>

<p>However, with <code class="language-plaintext highlighter-rouge">define</code> we have to be careful (and perhaps that’s the reason why SICP leave <code class="language-plaintext highlighter-rouge">define</code> more or less out of the discussion). Anyway, how would we expect that <code class="language-plaintext highlighter-rouge">define</code> behaves in the substitution model? If we write something like <code class="language-plaintext highlighter-rouge">(define x 42)</code> we could expect that <code class="language-plaintext highlighter-rouge">x</code> is a “name” for 42, and that everywhere that <code class="language-plaintext highlighter-rouge">x</code> is used afterwards, we could substitute it for <code class="language-plaintext highlighter-rouge">42</code>. That’s fair enough, but in that simplicity, it’s a bit naive. For instance, in Scheme it’s perfectly legal to do “re-define” a variable:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">x</span> <span class="mi">42</span><span class="p">)</span>
<span class="p">(</span><span class="nb">+</span> <span class="nv">x</span> <span class="mi">2</span><span class="p">)</span>        <span class="c1">;; -&gt; 44</span>
<span class="p">(</span><span class="k">define</span> <span class="nv">x</span> <span class="mi">17</span><span class="p">)</span>
<span class="p">(</span><span class="nf">x</span> <span class="nv">+</span> <span class="mi">3</span><span class="p">)</span>        <span class="c1">;; -&gt; 20</span>
</code></pre></div></div>

<p>In some programming languages, defining a variable twice might be illegal (and maybe in some Scheme or Lisp dialects is also outlawed), but otherwise Scheme accepts that. Now of course we cannot replace all occurrences of <code class="language-plaintext highlighter-rouge">x</code> after line 1 by 42. That would be wrong (and meaningless, if we also replace the <code class="language-plaintext highlighter-rouge">x</code> in <code class="language-plaintext highlighter-rouge">(define x 17)</code>.</p>

<p>One could realize at that point, that (of course) in examples like that, one would use substitution not just blindly but with more care. One could, for instance, speculate that a <code class="language-plaintext highlighter-rouge">define</code> works like <code class="language-plaintext highlighter-rouge">let</code> in that it introduces a new scope (for the rest of the file or module) and if there is a subsequent <code class="language-plaintext highlighter-rouge">define</code>, that acts like a nested scope. If the subsequent <code class="language-plaintext highlighter-rouge">define</code> is for a variable with the same name, then that new definition <strong>overshadows</strong> the old one (“shadowing” is a word that SICP uses to describe the situation; that is done in connection with the environment model, not the substitution model).</p>

<p>Along these lines, the above program with 2 times <code class="language-plaintext highlighter-rouge">define</code> could be written as follows with 2 nested <code class="language-plaintext highlighter-rouge">let</code> constructs:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">let</span> <span class="p">((</span><span class="nf">x</span> <span class="mi">42</span><span class="p">))</span>
  <span class="p">(</span><span class="nb">display</span> <span class="p">(</span><span class="nb">+</span> <span class="nv">x</span> <span class="mi">2</span><span class="p">))</span>     <span class="c1">;; print 44</span>
  <span class="p">(</span><span class="k">let</span> <span class="p">((</span><span class="nf">x</span> <span class="mi">17</span><span class="p">))</span>   
    <span class="p">(</span><span class="nb">display</span> <span class="p">(</span><span class="nb">+</span> <span class="nv">x</span> <span class="mi">3</span><span class="p">))))</span> <span class="c1">;; print 20</span>
</code></pre></div></div>

<p>This program uses <code class="language-plaintext highlighter-rouge">display</code> to show the value of the variable, as the value 44 in the middle would be “lost” and not shown.</p>

<p>Seeing multiple uses of <code class="language-plaintext highlighter-rouge">define</code> as a let-construction (only without being explicit about the scope, resp. assuming that the scope goes on until the end of the file or module, may be plausible. And if we take the “scoping” and “shadowing” into account, and do the substitution less naively, substitution is still a good model to explain the behavior of programs. Alas, this is <strong>wrong</strong>!</p>

<p>We can see that in the following slightly more complex example. Again it’s two definitions (of <code class="language-plaintext highlighter-rouge">x</code>), but in between there is definition of a function <code class="language-plaintext highlighter-rouge">f</code> which uses <code class="language-plaintext highlighter-rouge">x</code> and where the function is used before the redefinition of <code class="language-plaintext highlighter-rouge">x</code> and again afterwards:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">x</span> <span class="mi">42</span><span class="p">)</span>
<span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">f</span><span class="p">)</span> <span class="p">(</span><span class="nb">+</span> <span class="nv">x</span> <span class="mi">1</span><span class="p">))</span>
<span class="p">(</span><span class="nf">f</span><span class="p">)</span>            <span class="c1">;; -&gt; 43</span>
<span class="p">(</span><span class="k">define</span> <span class="nv">x</span> <span class="mi">17</span><span class="p">)</span>
<span class="p">(</span><span class="nf">f</span><span class="p">)</span>            <span class="c1">;; -&gt; 18</span>
</code></pre></div></div>

<p>The second call <code class="language-plaintext highlighter-rouge">(f)</code> to <code class="language-plaintext highlighter-rouge">f</code> sees the new value of <code class="language-plaintext highlighter-rouge">x</code> and thus returns <code class="language-plaintext highlighter-rouge">18</code>. If we do the analougous thing using <code class="language-plaintext highlighter-rouge">let</code> (and using <code class="language-plaintext highlighter-rouge">display</code> again), it looks like that:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="p">(</span><span class="k">let</span> <span class="p">((</span><span class="nf">x</span> <span class="mi">42</span><span class="p">))</span>
   <span class="p">(</span><span class="k">let</span> <span class="p">((</span><span class="nf">f</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">()</span> <span class="p">(</span><span class="nb">+</span> <span class="nv">x</span> <span class="mi">1</span><span class="p">))))</span>
     <span class="p">(</span><span class="nb">display</span> <span class="p">(</span><span class="nf">f</span><span class="p">))</span>           <span class="c1">;; print 43</span>
     <span class="p">(</span><span class="k">let</span> <span class="p">((</span><span class="nf">x</span> <span class="mi">17</span><span class="p">))</span>
       <span class="p">(</span><span class="nb">display</span> <span class="p">(</span><span class="nf">f</span><span class="p">)))))</span>      <span class="c1">;; print 43 </span>

</code></pre></div></div>

<p>The interesting part is the second call to <code class="language-plaintext highlighter-rouge">f</code>. This time with <code class="language-plaintext highlighter-rouge">let</code>, <code class="language-plaintext highlighter-rouge">x</code> is 43, which is <strong>different</strong> from the situation from before with <code class="language-plaintext highlighter-rouge">define</code>, where it was <code class="language-plaintext highlighter-rouge">18</code>. The fact that with <code class="language-plaintext highlighter-rouge">let</code>, the second <code class="language-plaintext highlighter-rouge">x</code> has 43 as value is a consequence of <strong>lexical scoping</strong> (or <strong>static binding</strong>). That’s of course not an explanation, just a word, but the substitution model makes it clear: the first let-binding binds <code class="language-plaintext highlighter-rouge">42</code> to <code class="language-plaintext highlighter-rouge">x</code>, and this we can substitute <code class="language-plaintext highlighter-rouge">x</code> by <code class="language-plaintext highlighter-rouge">42</code> in the scope of the let-expresion. Of course we are not naive or stupid, so of course we understand that we don’t substitute the <code class="language-plaintext highlighter-rouge">x</code> in the nested <code class="language-plaintext highlighter-rouge">(let ((x 17)) (display (f)))</code> expression. But after the substitution, the let-construct for <code class="language-plaintext highlighter-rouge">f</code> binds <code class="language-plaintext highlighter-rouge">f</code> to <code class="language-plaintext highlighter-rouge">(lambda () (+ x 43))</code>.</p>

<p>The innermost let-binding for <code class="language-plaintext highlighter-rouge">x</code> has actually no effect. In the light of the substitution model, the construct can be read as “substitute all occurrences of <code class="language-plaintext highlighter-rouge">x</code> in <code class="language-plaintext highlighter-rouge">(display (f))</code> with <code class="language-plaintext highlighter-rouge">17</code>”. Thing is, there is no occurence of <code class="language-plaintext highlighter-rouge">x</code> in there, so there’s nothing to be replaced. That <code class="language-plaintext highlighter-rouge">f</code> is a procedure whose body mentions <code class="language-plaintext highlighter-rouge">x</code> is irrelevant. That’s what static binding is all about: What counts for <code class="language-plaintext highlighter-rouge">x</code> in the body of the function is the scope where the procedure is defined, more precisely the scope of the <code class="language-plaintext highlighter-rouge">lambda</code> expression that (explicitly or implicitly) defines the procedure.</p>

<p>What does that mean? It means <code class="language-plaintext highlighter-rouge">define</code> is not the same as <code class="language-plaintext highlighter-rouge">lambda</code>. It also means we cannot explain the behavior of the define-version of the previous example using substitution! In other words</p>

<blockquote>
  <p><strong><code class="language-plaintext highlighter-rouge">define</code> destroys the substitution model!</strong></p>
</blockquote>

<p>The book or the lecture continues without worries for a while, before introducing imperative contructs like <code class="language-plaintext highlighter-rouge">set!</code> and then moving to the environment model. Though with <code class="language-plaintext highlighter-rouge">define</code> the way it’s used in Scheme, the substitution model was broken from the beginning!</p>

<p>Indeed the above examples with two times <code class="language-plaintext highlighter-rouge">define</code> in the same variable behave like using one <code class="language-plaintext highlighter-rouge">define</code> for the original introduction of the variable and <code class="language-plaintext highlighter-rouge">set!</code> for the second define. <code class="language-plaintext highlighter-rouge">define</code> behaves like <code class="language-plaintext highlighter-rouge">set!</code> (except for the first time one uses <code class="language-plaintext highlighter-rouge">define</code> on a given variable, as one cannot use <code class="language-plaintext highlighter-rouge">set!</code> on an undefined variable).</p>

<p>Since <code class="language-plaintext highlighter-rouge">define</code> is an aspect of Scheme that is <strong>not purely functional</strong> and for which the substitution model does not work, it’s understandable that the discussion of the substitution model is a bit vague on saying what’s going on with <code class="language-plaintext highlighter-rouge">define</code>. For lambda expressions and for application of that to arguments and for <code class="language-plaintext highlighter-rouge">let</code> (which is anyway just syntactic sugar), the substitution model is perfectly fine, and parameter passing and the shape of processes is anyway the focus of the discussion at that point.</p>

<p>But still is may feel disturbing. Sure <code class="language-plaintext highlighter-rouge">define</code> is quite important, that’s why it was one of the very first constructs introduced. Actually it seems necessary if we want to define recursive procedures. For instance, the following definition of the factorial function does not work:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">let</span> <span class="p">((</span><span class="nf">fac</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>
	       <span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">0</span><span class="p">)</span>
		   <span class="mi">1</span>
		   <span class="p">(</span><span class="nf">fac</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">))))))</span>
        <span class="p">(</span><span class="nf">fac</span> <span class="mi">3</span><span class="p">))</span> <span class="c1">;; -&gt; ?? 6</span>
	
</code></pre></div></div>

<p>Does that mean, <strong>purely</strong> functional programs are really <strong>impossible</strong>? At least not interesting ones, that use recursion? Perhaps one needs <code class="language-plaintext highlighter-rouge">define</code> and, as explained, that’s actually not purely functional?</p>

<p>The answer to that is no, but it’s complex. One can get recursion without <code class="language-plaintext highlighter-rouge">define</code>, just with <code class="language-plaintext highlighter-rouge">lambda</code> and appliction. Ultimately it leads to something called <strong>Y combinator</strong> and friends, but that’s a topic for another post…</p>

<p><strong>single assignment</strong></p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">x</span> <span class="mi">5</span><span class="p">)</span>
<span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">f</span><span class="p">)</span> <span class="p">(</span><span class="nb">+</span> <span class="nv">x</span> <span class="mi">1</span><span class="p">))</span>

<span class="p">(</span><span class="nf">f</span><span class="p">)</span>            <span class="c1">;; -&gt; 6</span>
<span class="p">(</span><span class="k">define</span> <span class="nv">x</span> <span class="mi">6</span><span class="p">)</span>
<span class="p">(</span><span class="nf">f</span><span class="p">)</span>            <span class="c1">;; -&gt; 7</span>

</code></pre></div></div>

<p><strong>variable capture.</strong></p>

<p>Especially wrt. when one has a recursive definition like the factorial \code{fac}, when and under which circumstances \code{fac} is replaced by its definition. In connection with that, the illustrations are working with definitions of the form \code{(define (fac n) …)}, which is syntactic sugar for \code{(define fac (lambda (n) …))}. The simplistic and naive explanation, that the meaning of \code{define} is that all occurrences of \code{fac} are replaced in the program by the right-hand side does not work in that simple form. When one replaces \code{fac} by its body \code{if (= n 0) 1 (fac (- n 1))}, then there is \code{fac} again. And then what, must be substituted that as well, or when? If we think that we need to replace it now, maybe so that the whole program text no longer contains \code{fac}, then of course that \emph{does not work}, the replacement treatment will never end.\footnote{It does not work as normally one excludes infinitely large expressions from considerations. If one would tolerate that, the picture would actually be fine, but as far as explanation of what’s going on, it would be more on the esotheric and theoretical side of things, not as a practical way of implementing an interpreter.} Indeed the examples from Section 1.2 substites, for instance \code{fac} not ``at once’’, but only ``by need’’ (one could say actually ``delayed’’, only when calling \code{fac} another time). All that is plausible enough, but the text in SICP 1.2 glosses over those details, as it focuses on the shape of processes and replaces, for instance \code{fac}.</p>

<p>If we accept that substitution is good model, that (especially for recursive definitions), substitution of the name being defined immediately and once and for all is impossible, and that it needs to be done ``by need’’ somehow, we need to figure out more clearly \emph{when} it is that we need to do the substitution.\footnote{unroll}. We substituted a variable by its definition, when we \emph{need} to know its definition, by not earlier. But then: \emph{when} do we need it?</p>

<p>That’s a question of the \emph{evaluation strategy,} which is \emph{applicative-order evaluation} for standard Scheme. Of course streams (especially \code{cons-stream} does not follows AO, \code{cons-stream} follows normal-order (lazy, call-by-name, call-by-need etc). That’s the reason why the shown definition of the stream \code{ones} works.</p>

<p>If one accepts the ``substitution-by-need’’ picture. it may also make plausible why something like \code{(define ones (cons 1 ones))} (using \code{cons}) does not work. Here, indeed, there is no “room” for delay.</p>

<h1 id="pairs-as-procedures">Pairs as procedures</h1>

<p>src/examcollection/2017/</p>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="functional programming" /><category term="IN2040" /><category term="Scheme" /><category term="substitution and environment model" /><category term="evaluation strategies" /><summary type="html"><![CDATA[Some elaboration,using fineprint from the substitution and environment model]]></summary></entry><entry><title type="html">(Not so) abstract syntax trees</title><link href="/functionalprogramming/2023/11/03/notsoast.html" rel="alternate" type="text/html" title="(Not so) abstract syntax trees" /><published>2023-11-03T00:00:00+01:00</published><updated>2023-10-09T00:00:00+02:00</updated><id>/functionalprogramming/2023/11/03/notsoast</id><content type="html" xml:base="/functionalprogramming/2023/11/03/notsoast.html"><![CDATA[<p>In weeks 11 and 12, we take a look at the <strong>meta-circular interpreter</strong> from Chapter 4 of SICP. There are different parts we discusses, the central one the mutually recursive procedure <code class="language-plaintext highlighter-rouge">eval</code> and <code class="language-plaintext highlighter-rouge">apply</code> (resp. <code class="language-plaintext highlighter-rouge">mc-eval</code> and <code class="language-plaintext highlighter-rouge">mc-apply</code> when we want to use the names as used in the slides).</p>

<p>But another part was dealing how to represent <strong>expressions</strong>, the <strong>syntax</strong> of “our” Scheme. In the lecture, I also called it <strong>abstract syntax</strong>, a word that also SICP briefly mentions in that context (on page 364). When browsing through the code of <code class="language-plaintext highlighter-rouge">evaluator.scm</code>, it all looks rather detailed and concrete and not really very abstract. Calling it “abstract” may sound puzzling:</p>

<p>But <strong>abstract syntax</strong> is a known concept and terminology for basically every implementation of every programming language, where by implementation we mean an interpreter (meta-circular or just a ordinary one) or a compiler for a given language. The <strong>user</strong> of the programming language normally does not to bother about what’s known as abstract syntax, only those who implement a compiler or an interpreter need to define and work with that. The standard programmer of course need to know how to write syntactically correct programs in the chosen language. The syntax the programmer experiences is called <strong>surface syntax</strong> or <strong>user syntax</strong> or <strong>concrete syntax</strong>. Actually, it’s mostly just called <strong>syntax</strong>, as users might not be aware that there is a second, internal level of syntax called abstract syntax, thus no need to call the user-level syntax “concrete”. But a interpreter- or compiler-writer distinguishes both.</p>

<p>Lisp or Scheme syntax is simple. Scheme is also simple in that it supports only a limited selection of constructs to the user. Of course Scheme or Lisp distributions may ship with large and complex libraries, but the core is pretty slender (a little bit of <strong>syntactic sugar</strong>, like <code class="language-plaintext highlighter-rouge">let</code>, notwithstanding). But that’s not the main reason why, as we said, Scheme’s concrete syntax is simple. Concrete syntax is what the user sees, abstract syntax is an <strong>internal data structure</strong> or representation of that syntax. What the user sees is the code in form of a string or a stream of characters (in one or more files). A string or similar is likewise a data structure, but it’s a very basic one, and a string is actually very <strong>unstructured</strong> in the sense that its structure (being an array of characters maybe) has <strong>nothing to do</strong> with the syntactic structure of programs in a programming language.</p>

<p>Also a user reading the code (represented by a string) does typically not mentally perceive the code as a large array of characters. The trained eye perceives in a piece of code a procedure, a loop, and a further loop nested in the other one that contains a case distinction followed by another loop, etc. Of course, not all strings correspond to proper programs in a given language. For instance, the following code snippet would be a string that represents a syntactically correct (part of a) JavaScript program</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="p">(</span><span class="kd">let</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="nx">text</span> <span class="o">+=</span> <span class="dl">"</span><span class="s2">The number is </span><span class="dl">"</span> <span class="o">+</span> <span class="nx">i</span> <span class="o">+</span> <span class="dl">"</span><span class="s2">&lt;br&gt;</span><span class="dl">"</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>but violates the rules for user syntax for many other languages. User-syntax is often designed to make the code easy to read for the programmer (though what exactly that entails depends on the taste, preferences and exprerience of the programmer).</p>

<p>So, concrete syntax is concerned with which strings are syntactically allowed representations of programs and which not. While having a program represented as a string may be useful for the programmer (having file editors and and browers at hand, and being used to read texts, even code in text form), strings are a bad idea when running or interpreting a program.</p>

<p>At the beginning of the lecture, we explained what happens when running a Scheme program by the so-called <strong>substitution model</strong> (that was when we were still in a purely functional setting). That’s based on substitution or replacement, and illustrated in the book or the slides by replacing step after step a formal parameter by the corresponding argument in the body of a procedure. That’s a purely textual manipulation of symbols written on the slide or the book, and thus it can be seen illustrating string manipulation (string replacement and string matching). Indeed, one could in principle come up with an interpreter that works like that, massaging the string that is writting in the langauge’s concrete syntax. That would work for a purely functional setting; for languages supporting side-effects (almost every language, that is) interpretation purely based on substitution would break down, one would need to implement structures like environments and frame. Still, one could use substitution for stepping through the code while maintaining and updating the enviroments for book-keeping of the (mutable) content of variables.</p>

<p>At any rate, basing interpretation on string substitution is a terrible idea, thus it’s not done. There are at least 2 reasons for that. One we have mentioned: strings as data structure are too unstructured for the purpose. Substitution is about replacing one piece of syntax by another piece of syntax. The piece of syntax being replaced in our contex is replacing a variable by an expression, for instance by another procedure in the following situation</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">((</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">f</span><span class="p">)</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">x</span><span class="p">)</span>  <span class="p">(</span><span class="nb">/</span> <span class="p">(</span><span class="nf">f</span> <span class="nv">x</span><span class="p">)</span> <span class="p">(</span><span class="nf">f</span> <span class="p">(</span><span class="nb">+</span> <span class="nv">x</span> <span class="mi">1</span><span class="p">)))))</span>
   <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">y</span><span class="p">)</span> <span class="p">(</span><span class="nb">*</span> <span class="nv">y</span> <span class="nv">y</span><span class="p">)))</span>
</code></pre></div></div>

<p>The expressions ultimately stands for the function $\frac{x^2}{(x+1)^2}$. To think of the step from the above lambda expression to the subsequent one, replacing <code class="language-plaintext highlighter-rouge">f</code>:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">x</span><span class="p">)</span>  <span class="p">(</span><span class="nb">/</span> <span class="p">((</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">y</span><span class="p">)</span> <span class="p">(</span><span class="nb">*</span> <span class="nv">y</span> <span class="nv">y</span><span class="p">))</span> <span class="nv">x</span><span class="p">)</span> <span class="p">((</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">y</span><span class="p">)</span> <span class="p">(</span><span class="nb">*</span> <span class="nv">y</span> <span class="nv">y</span><span class="p">))</span> <span class="p">(</span><span class="nb">+</span> <span class="nv">x</span> <span class="mi">1</span><span class="p">)))))</span>
</code></pre></div></div>

<p>as a string-manipulation is not helpful, and it’s not what a human reader normally does. The brain, with a little training and experience, is able to perceive the parts of string as anymous procedures, and mentally operate by replacing the formal parameter by the argument procedure to understand what’s going on. Thinking of it in terms of an array of characters is just not a useful level of abstraction. Even worse would be to think of it as manipulation of a bit-array (thinking of the characters as sequences of bits). On that even lower level, a computation step could be understood as a substitution of bit-sequence inside another, though maybe one should not use the word “understand” in that contect…. We said that when reading a piece of code like the above string, one perceives them (with some training) as procedures, applications, a multiplication expression etc, one can also say, one <strong>parses</strong> them into procedures etc. That use of the word “parse” fits to the definition the word (among slightly alternative readings of the word) one finds at <a href="https://merriam-webster.com/dictionary/parse">Merriam-webster</a>:</p>

<blockquote>
  <p>to divide (a sentence) into grammatical parts and identify the parts and their relations to each other.</p>
</blockquote>

<p>The grammar of a language is concerned with syntactical aspects of a language. So instead of grammatical parts, one could also say syntactic parts. So parsing a sentence is concerned with its syntax (identifying its syntactic part resp. rejecting the sentence as not following the grammatical rules governing the language). It’s not concerned with the <strong>meaning</strong> of the sentencr (or rejecting it as meaningless, but otherwise syntactically correct).</p>

<p>Parsing, as defined by Merriam-Webster, is a word used by linguists an describes what linguists believe what happens when someone is reading a text or a sentence in a natural language. In order to ultimately understand a sentence, one needs to identify its separate parts, subsentences, nouns, verbs, particular words and how they arrange to a full sentence. That involves figuring out where individual words start and end and determining whether a word is an actual word (maybe as listed in a dictionary). For written text, determining where a word starts and ends is relatively straightforward, as they are separated typically by some space (or maybe by a full stop or comma, which structures also sentences). For spoken languages its more complex, but separating and identifying individual words and then identifying the syntactical or grammatical structure over the words needs still to be done. As said, linguists call that parsing.</p>

<p>And of course, the problem exists also for <strong>programming languages</strong> and the task analysing and breaking up a text, i.e., the source code of program into, its syntactic constitutents, that task is called, as discussed <strong>parsing</strong>, and it’s done by the <strong>parser</strong>.</p>

<p>What the parser thereby does is taking the unstructured string which is written in the <strong>concrete syntax</strong> or user syntax, and turns it as a result of the parsing process in a data structure respresented as <strong>abstract syntax</strong>. Those data structures are trees, and they are called, unsurprisingly <strong>abstract syntax trees</strong>. For a concrete program, the root node of the abstract syntax tree represents the whole program, and each child node in that tree represents the immediate syntactic substructures. For instance, a possible tree for the JavaScript <code class="language-plaintext highlighter-rouge">for</code> node may have two children, one representing the loop-condition and the other one the loop-body. If JavaScript had also other kinds of loops, maybe a repeat-until-loop, the node must also contain the information, that it’s indeed a <code class="language-plaintext highlighter-rouge">while</code> loop and not a repeat-until loop. Structurally both syntax constructs may be analogous (two children: one a predicate, another one for the body), but for executing the tree representing the loops, one needs to distinguish them, as both kinds of loops behave differently.</p>

<p>So, abstract syntax refers to trees, and it’s called “abstract” as in the step from concrete syntax to abstract syntax trees, some details are typically omitted. For instance the whole “placement” of the individual characters (line numbers) is irrelevant, newlines and comments are omitted. To stick with the JavaScript example: the fact that the body of the loop is <strong>written</strong> in concrete syntax with <code class="language-plaintext highlighter-rouge">{</code> and <code class="language-plaintext highlighter-rouge">}</code> as marking the beginning and the end of the body is irrelevant (as is the fact that one has to write a <code class="language-plaintext highlighter-rouge">;</code> at the end of each statement) and will typically not be represented in the AST. Those details of the concrete syntax are left out, and the abstract syntax tree only contains the syntactic essence of the program, not its concrete textual string.</p>

<p>Now, how is it in Scheme? Scheme famously uses <strong>parenthetic prefix notation</strong>, something rarely used in other languages. As mentioned earlier, concrete syntax is meant to aid the coder and reader to read of a piece of code, so to say to make <strong>human parsing</strong> as easy as possible. Though, as also said, what’s easy and agreeable depends on personal experience and taste and for Lisp veterans, perhaps writing and reading piles of parentheses is easy and the most agreeable way of writing programs. For parsers, on the other hand, a parenthetic structure and the Lisp syntax is most agreeable indeed. For once it’s <strong>unambiguous</strong>. If your language allows to write a numerical expression like <code class="language-plaintext highlighter-rouge">2 + 3 * 4</code>, most people would understand after some calculation that this represents or results in the number <code class="language-plaintext highlighter-rouge">14</code>, since one has to perform the multiplication before the addition. That’s because most users are trained to read or parse such expressions in that particular way. Such syntactic ambiguities not only exist for mathematical infix symbols, but also other programming constructs may “suffer” from that. For the trained user, it’s hopefully not a problem, but for the parser it is, it need to be programmed to parse the concrete syntax “the right way”, that reflects the intentions of the designer of the language.</p>

<p>For Lisp or Scheme, there’s no such problem. The parentheses make very clear which things belong together and where an expression starts (at a left <code class="language-plaintext highlighter-rouge">(</code> parenthesis) and where it ends (at the corresponding right <code class="language-plaintext highlighter-rouge">)</code> parenthesis). In combination with the fact that this syntax is <strong>uniform</strong> makes parsing almost trivial. Uniform means there’s no special cases like other kinds of parentheses (like <code class="language-plaintext highlighter-rouge">(..}</code> for this purpose and <code class="language-plaintext highlighter-rouge">{..}</code>, <code class="language-plaintext highlighter-rouge">&lt;..&gt;</code>, and <code class="language-plaintext highlighter-rouge">[ ..]</code> for others, there is no sometimes infix notation, sometimes postfix. Nore are there hardly any <strong>restrictions</strong> on what kind of constructs can be used in combination with others. For instance in Java, one cannot define methods inside methods: one can (since quite some time) nest classes, but not methods. You can have a tuple as argument to a method, but not as return result. etc. All those are syntactic restrictions, that the parser has to implement, but for Scheme or Lisp, the problem is almost trivial. Amost as long as every opening parenthesis is matched by a closing one, the program is syntactically correct.</p>

<p>Even more: the parenthetic notation is not only a syntactic grouping mechanism, it’s also the notation for lists. And lists can be nested, in which case SICP calls it list structures. But as we discussed in the lecture, nested lists can be seen as <strong>trees</strong>. What it basically means is that, by coding in parenthetic prefix notation, the programmer <strong>directly writes abstract syntax trees</strong>. To say it differently, there’s no real distinction between abstract and concrete syntax, we also don’t have to puzzle how to best design abstract syntax trees, they are given anyway. All that benefits the parser and parser writer, whether it benefits the user may be up to debate, some people like the unabiguity and simplicity of Scheme syntax, some may prefer other notations.</p>

<p>Historically, this peculiar design of the (concrete) syntax is factually sort of an <strong>accident</strong>. Lisp is quite an old language, after Fortran the second oldest programming language still in use (Cobol is the third surviving veteran from approximately the same time, but came a bit later). Scheme was a pioneering design and was in many ways ahead of its time. For instance, supporting <strong>higher-order functions</strong> and <strong>garbage collection</strong>, when Fortran, for instance, not even supported recursion. It was also developed at a time, where hardware was seriously limited and where programming was not interactive. A Wikipedia article about the <a href="https://en.wikipedia.org/wiki/IBM_704">IBM 704</a>, the machine used for the first Lisp (and Fortran) implementation, gives an impression. While at it: one type of instruction format from that particular machine also gave name to the functions <code class="language-plaintext highlighter-rouge">car</code> and <code class="language-plaintext highlighter-rouge">cdr</code>, as cons-cells were implemented making use of the corresponding parts in registers (the address format had an “address” and a “decrement” part).</p>

<p>Not only was hardware limited, concepts and experience how to develop a programming language were missing, no prior languages existed to improve on (except machine-specific assembler) as those were the very first higher-level programming languages ever, no conceptual framework, no text books, no computer science curriculum, no nothing, just bare metal… One conceptual thing that was not yet well developed was a clear notion of how to specify and discuss the syntax of a language. That came only a bit later, in the context of Algol 60, where for the first time, the syntax of a programming language was clearly written down in a document (using what is known as a (context-free) grammar, written in so-called BNF format; such notation of grammars is a domain-specific language to describe syntax). Before that the “syntax” of a language was just what happened to be accepted by the compiler or interpreter. Of course, the developers reflected on it, and try to make good decisions. But there was also not yet a coherent body of parser technology and theory, so one had to program some program that somehow allowed to input a program (maybe from a bundle of punch cards), and then pick it up from there. The developers of early Scheme (and Fortran and other languages prior to Algol 60) would no even think explicitly about abstract syntax trees and concrete syntax trees (at least not use those words).</p>

<p><code class="language-plaintext highlighter-rouge">read</code></p>

<h1 id="s-expressions-and-m-expressions">S-expressions and M-expressions</h1>

<p>Coming back to Lisp or Scheme-syntax: the parenthetic expressions that represent the syntax of programs as well as lists are called <strong>S-expressions</strong>, and they are the concrete as well as abstract syntax for Lisp. One way of seeing it was that Lisp was and still is actually lacking user-syntax and instead let the user directly code in abstract syntax. Other languages at that time did not do that, and with time and after Algol 60, people were starting to think more systematically about how to carefully craft syntax, how to systematically parse it, and understanding what can be done by a parser and what not. There was attempts or initiatives to equip Scheme with a user-level syntax, on top of the S-expressions as notation for abstract syntax trees. This attempt is known as <a href="https://en.wikipedia.org/wiki/M-expression">M-expressions</a>, but it actually fizzled out. As McCarthy seem to indicate in <a href="https://www-formal.stanford.edu/jmc/history/lisp/lisp.html">History of Lisp</a>, users of Lisp had already gotten used to programming in S-expressions, and saw no benefit in adopting a different syntax and perhaps porting the growing code base to that newer format. In that sense the language design is a historic “accidence”: the abstract syntax came first, the initial and landmark design focused on the hard problems (higher-order function etc), not on notational matters, keeping parsing trivial, and despite some (feeble?) attempts to afterwards come up with a more conventional concrete syntax, Lisp had already taken off, and it was too late.</p>

<h1 id="abstract-syntax-as-abstract-data-type">Abstract syntax as abstract data type</h1>

<p>Of course</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> (+ 2 ()))
. #%app: missing procedure expression;
 probably originally (), which is an illegal empty application in: (#%app)
&gt; (+ 2 ))))
2
. read-syntax: unexpected `)`
&gt; 
read-syntax: unexpected `)`

(cons 4)
. . mcons: arity mismatch;
 the expected number of arguments does not match the given number
  expected: 2
  given: 1
  arguments...:
</code></pre></div></div>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="scheme" /><category term="meta-circular evaluator" /><category term="syntax" /><category term="abstract syntax" /><summary type="html"><![CDATA[Representation of expressions in the meta-circular evaluator]]></summary></entry><entry><title type="html">Y not code up $n!$ with no recursion and no Y tricks either?</title><link href="/functionalprogramming/2023/10/20/churchnums.html" rel="alternate" type="text/html" title="Y not code up $n!$ with no recursion and no Y tricks either?" /><published>2023-10-20T00:00:00+02:00</published><updated>2023-09-12T00:00:00+02:00</updated><id>/functionalprogramming/2023/10/20/churchnums</id><content type="html" xml:base="/functionalprogramming/2023/10/20/churchnums.html"><![CDATA[<p>In another post, I dissected how to program recursion using anonymous functions, only. This ultimately leads to the famous $Y$-combinator. Actually, there are multiple versions of it, all doing the recursion-trick by some form of self-application. The running example in that blog post was the inevitable factorial function.</p>

<p>If that was not weird enough, here is a different and, arguably, even stranger way to program factorial. Namely:</p>

<blockquote>
  <p><strong>without self-application</strong>, without any of the fix-point combinators like $Y$ (and of course without actual recursion and without other cheap tricks like using while or some loops that the Lisp/Scheme dialect may offer).</p>
</blockquote>

<p>In the last post, the solution for factorial was straightforwardly generalizable to any recursive function, and that generalization was the $Y$-combinator (and its variations). This time, we won’t be able to generalize the construction, at least <strong>not for all recursive functions</strong>.</p>

<p>Intuitively that’s easy to understand. The $Y$-combinator allows to cover all recursive definitions, including those that result in <strong>non-terminating</strong>-procedures. Recursion corresponds to a higher-order functional version of capturing the essence of <strong>while-loops</strong> from imperative languages. Those can lead to non-termination as well. There exist also looping constructs that are guaranteed to terminate. Those are conventionally called <strong>for-loops</strong>. Never mind that some concrete programming languages like Java use the keyword <code class="language-plaintext highlighter-rouge">for</code> for general loops, including those we (and others) call while-loops, to distinguish them from their “weaker” siblings, the for-loops.</p>

<p>If we come up with a scheme to capture something akin to for-loops it means we cannot expect to capture non-terminating functions. But the factorial will be fine.</p>

<p>The $Y$-combinator (and its variations) are somewhat convoluted expressions using only (anonymous) functions applied to themselves. They can be given in the untyped $λ$-calculus, and one can program $Y$ in Scheme, though one has to be careful to take into account that Scheme is an language using eager evaluation, an aspect not typically considered when dealing with a $λ$-calculus (though of course one could focus on an eager $λ$-calculus, if one is interested in that).</p>

<p>The factorial function has other aspects, which are not actually part of the purest of $λ$-calculi. Pure here not in the sense of purely functional and without side-effects. Pure in the sense of “functions only!”. Remember: the first two chapters of SICP cover “<strong>building abstractions with procedures</strong>” and “<strong>building abstractions with data</strong>”. Actually the treatment of procedures comes before treating (compound) data.</p>

<p>Of course, without data to calculate on, there are not many things procedure can work with and compute on. One can of course define weird and powerful stuff working purely with procedures, like the $Y$-combinator, but that’s hardly a way to start a book teaching functional programming (actually SICP hardly even mentions the $Y$-combinator, it just crops up in a footnote in some exercises). Besides, when $Y$ to some function, say $F$, it still does not compute some real stuff: $Y F$ <em>defines a function</em> that can behave recursively, but to run that, we need to give some further input. So in order to get going, the procedures need to have some non-procedural <strong>data</strong> to operate on.</p>

<p>Like all programming languages, Scheme supports a number of built-in primitive data types. The most readily available ones are perhaps numbers and that’s why many initial examples in SICP are “numerical” in nature (lists, for instance comes later). Maybe one walks away with the (initial) impression that Scheme’s prime application area is number crunching. That’s actually the more or less the opposite what Lisp (and thus Scheme) was originally intended for. It was originally touted as language for “symbolic” computations, working on symbols, and the language of choice for <em>artificial intelligence</em>. If we take the trinity of three early, major, and surviving programming languages, Fortran, COBOL, and Lisp, Fortran was for number crunching, COBOL for “business” and managing data records, and Lisp, as said, for symbolic computations and AI.</p>

<p>Ok, Scheme supports numbers, but the pure $λ$-calculus does not.</p>

<p>In the lecture, we saw that higher-order procedures are powerful. As discussed, one can express recursion with them. Also, in connection with <strong>data structures</strong>, it was shown how <strong>pairs</strong> can be expressed by higher-order procedures. Pairs, like numbers, are built-in in Scheme, but SICP and the lecture showed, how to program the constructor and selectors for pairs (<code class="language-plaintext highlighter-rouge">cons</code>, <code class="language-plaintext highlighter-rouge">car</code>, and <code class="language-plaintext highlighter-rouge">cdr</code>) using procedures. Not that there would be a need for that, as they are built in, but if wished, it can be done.</p>

<p>Ok, then, <strong>what about (natural) numbers</strong>? At this point one may have guessed what the answer will be: yes, natural numbers can be encoded in the $λ$-calculus. At a general level, it should not be too surprising. If one has heard that the $λ$-calculus is Turing-complete, i.e., is expressive enough to compute everything a Turing-machine can compute (and thus everything that a full-blown programming language can compute), it’s implicit that somehow it must be possible (but maybe tricky).</p>

<p>Encoding numbers by procedures may seem like a pointless thing to do and anyway not needed (in Scheme) as they are built-in. That’s a valid standpoint, but one should also not forget that built-in is not the same a God-given. Numbers and other data structures may be built-in, but they won’t be directly processable by the ultimate hardware or platform. There will be an encoding, and it’s likewise complex. To work on standard hardware, maybe not us, but someone ultimately needs to encode numbers by $0$’s and $1$’s and to encode operations on number like addition by some manipulations of those bits. The encoding of course goes on behind the scenes (by the compiler or interpreter), and we are operating on the numbers with standard notation and operations which behave the way we are used to. But someone has to take care of the encoding to maintain the convenient abstraction for us.</p>

<p>Encoding the numbers (and pairs and lists) as procedures inside Scheme is of course not advisable from a standpoint of <em>efficiency</em>. Typical hardware can manipulate standard binary encodings of numbers fast and some basic procedures like addition may directly be supported by hardware. Other procedures (like factorial) of course not. Ultimately also they need to be represented in binary form to be run on a machine (or the interpreter that runs the and encoded as binary, in machine code). Standard hardware maybe suited to calculate basic stuff on numbers but not to juggle higher-order functions, at least not directly. Interestingly, there had been attempts to do tailor-made computer hardware for Lisp, those were known as <a href="https://en.wikipedia.org/wiki/Lisp_machine">Lisp machines</a> (and they went the way of the dodo…)</p>

<p>Encoding numbers as procedures may seriously degrade performance, but it’s an interesting exercise, and it will allow to program factorial without recursion! The encoding is actually is well-known under the name <strong>Church numerals</strong>. The natural numbers is only one example of an infinite data structure, lists and trees are others that could be treated similarly. Actually, also finite data structure can be handled, for instance Booleans. All of those data structures could be encoded analogously, if one worked out the principles behind the Church numerals more clearly than we will do. The technique is also called <strong>Church encoding</strong>.</p>

<p>But we mostly stick to natural numbers as data structure. We approach the task from two angles: what’s the interface for numbers, and how are they represented. While we mostly stick to numbers concerning the encoding, later we will generalize beyond numbers as far as as interfaces are concerned.</p>

<h1 id="the-constructor-interface-of-the-encoding">The constructor interface of the encoding</h1>

<p>The interface angle should be familiar from the lecture material about <strong>data abstraction</strong>. The goal is to have an encoding that works like the usual one (only quite a bit slower perhaps) seen from the outside. Then what belongs to the interface for numbers? And as we did in other examples, for instance when encoding pairs, the first question to answer is: how can I get natural numbers? That are the <strong>constructors</strong> of the data structure?</p>

<blockquote>
  <p>The two constructors of natural numbers are $0$ and $\operatorname{succ}$, maybe called <code class="language-plaintext highlighter-rouge">zero</code> and <code class="language-plaintext highlighter-rouge">succ</code> in Scheme.</p>
</blockquote>

<p>Note, we are not meaning here the (built-in) number $0$, it’s meant that there are two procedures in the interface, and we call them, not unreasonably $0$ and $\mathit{succ}$ to remind us what they are intended for. We have not solved yet how to encode them properly, but once we solved the encoding, we obviously can represent all natural numbers, using that constructor interface. For instance (in Scheme) we could write</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">define</span> <span class="nv">seven</span> <span class="p">(</span><span class="nf">succ</span> <span class="p">(</span><span class="nf">succ</span> <span class="p">(</span><span class="nf">succ</span> <span class="p">(</span><span class="nf">succ</span> <span class="p">(</span><span class="nf">succ</span> <span class="p">(</span><span class="nf">succ</span> <span class="p">(</span><span class="nf">succ</span> <span class="nv">zero</span><span class="p">))))))))</span>
</code></pre></div></div>

<p>Fair enough, that looks like a plausible way of writing down the number we pronounce “seven” in English. We mentioned that the encoding will degrade the performance. Besides that the encoding is also not very space efficient, as the above construct is a value, it’s a notation for 7. We are used to so-called <strong>positional number systems</strong>, so much so that we tend not to think about it all. For instance $137$ is a fairly compact encoding for a number which would be fairly long if we were forced to write it as with a tower of <code class="language-plaintext highlighter-rouge">succ</code>’s… The encoding that the built in $137$ typically uses in hardware, the binary representation with $0$’s and $1$’s, is also short, thanks to the positional representation. One could see the <code class="language-plaintext highlighter-rouge">succ</code>-notation as an <strong>unary number system</strong> (like <a href="https://en.wikipedia.org/wiki/Tally_marks">tally marks</a>, a prehistoric ``number system’’). To say it again, $0$ and $\operatorname{succ}$, resp.\ <code class="language-plaintext highlighter-rouge">succ</code> and <code class="language-plaintext highlighter-rouge">zero</code> is not the solution how to encode them as procedures, it’s the interface, the <strong>symbolic names</strong> of the two central procedures, whose internal representation we have still to figure out.</p>

<h1 id="if-n-is-a-function-what-does-that-function-do">If $n$ is a function, what does that function do?</h1>

<p>Being able to write down numbers using those constructor names is all fine and good, but in isolation it is of little use. We need to be able to <strong>do</strong> something with them, like computing with them.</p>

<p>So, what do we want to do with them? The most obvious thing to do is to <strong>calculate with</strong> numbers, like adding two numbers, calculating the square of numbers etc. Sure, that’s what one often does with numbers.</p>

<p>But perhaps we should switch perspective. Asking how to calculate <strong>with</strong> numbers as inputs and outputs, combining them in different ways is too “conventional”, too closed-minded. Remember, we are doing functional programming, where the boundary between data and procedures is blurred. In particular in a pure (non-applied) $λ$-calculus, everything is a procedure and we intend to factually encoding numbers as functions. So not only that procedures are first-class citizens in the sense that procedures can be handled in the same way as ordinary data, like serving as input or output to other procedure in the same way as numbers. It’s even more radical: <strong>Everything</strong> is in fact a function, including those that we intend to represent as natural numbers.</p>

<p>We learned to think of numbers not as procedures, but as data. Silly us, but that was before we learned about higher-order function… If we are about to encode numbers as procedures, we need to make up our mind (and open up our mind) what kind of procedure for instance the number <code class="language-plaintext highlighter-rouge">(succ (succ (succ (zero)))</code> is. If a number is represented not as a bit string or number in decimal notation or some passive piece of conventional data) but as a function, the number can be used <strong>do something</strong> when applied to an argument. So the switch in perspective is</p>

<blockquote>
  <p><strong>Don’t ask what you want to do with numbers, ask what you want numbers to do for you!</strong></p>
</blockquote>

<p>Okeeeh… As everything in a purely functional setting are function, the question is what can a “procedural” natural number reasonably do when presented with a procedural argument? Church’s idea was roughly:</p>

<blockquote>
  <p>The number $n$ should be encoded as the function that, when given a function as input, <strong>iterates</strong> it $n$ times!</p>
</blockquote>

<p>The <strong>computational essence</strong> of a number is its potential to <strong>iterate</strong>, it represents a <strong>for-loop with $n$ rounds</strong> (resp. it functional equivalent, since for-loops are structure typical for imperative languages).</p>

<p>One may swallow that switch of perspective, but still may want to complain a bit. It may sound interesting to see numbers are some “loop”. Interesting as that looks, aren’t we missing out an important fact. There is a good reason that standard presentations or encodings of numbers treats them as <strong>data</strong>. After all, <strong>calculating</strong> with them, like doing additions, multiplications etc., that’s certainly at least as important as having numbers as iterators, or not?</p>

<p>But on second thought, there is no reason not to have both. After all, having numbers are procedures does not mean they cannot also be treated data as well. Procedures are first-class citizens, right, and data is functions and functions are data.</p>

<p>So let’s just do some good old calculations, like addition. But what’s addition of two number other than iterating the successor function: like $7 + 4$ would be $\mathit{succ}^7 (4)$ (or the other way around), where $\mathit{succ}^7$ is meant as applying $\mathit{succ}$ 7 times to (the encoding of) $4$. Similarly, after having defined addition, multiplication can be explained as iterated addition. This way it seems, standard calculations could be achieved.</p>

<p>Since the sketched idea of the construction corresponds to <code class="language-plaintext highlighter-rouge">for</code>-loops and iteration and not to <code class="language-plaintext highlighter-rouge">while</code>-loops resp. general recursion, it’s obvious that there are calculations on numbers that cannot be done. Impossible are in particular functions that do not terminate (on some or all inputs). Where exactly the boundary lies, what can be represented with Church-numerals and iteration only (and without doing general recursion) is a question, we don’t explore here. But the boundary is <strong>not</strong> that all terminating functions can be represented iteratively, and only the non-terminating ones are out of reach. There is another post on the Ackerman-function and primitive-recursive function that discusses some aspects of that question.</p>

<h1 id="the-encoding-itself">The encoding itself</h1>

<p>But then, what <strong>is</strong> the encoding? Actually it’s fairly easy. What we intend is a behavior as follows</p>

\[n f = f^n\]

<p>$n$ applied to a function $f$ corresponds to the $n$-time application of $f$. Another way of writing the same is</p>

\[n f = \lambda x. \underbrace{f( f (f \ldots (f}_n x)))\]

<p>The task then is to program $0$ and $\mathit{succ}$ accordingly (or <code class="language-plaintext highlighter-rouge">zero</code> and <code class="language-plaintext highlighter-rouge">succ</code> in Scheme). Here it is. Let’s start with $0$. It’s supposed to take a function to iterate $0$ times, so not at all. So $0\ f$ has no effect at all, and thus corresponds to the identify function $\lambda z. z$.</p>

<p>With $n$ as input, the successor returns $n+1$. Both numbers are encoded as iterators we are on the way of programming. In other words, with an $n$-iterator as input, $\mathit{succ}$ returns a function that iterates $n+1$. That leads to the following scheme:</p>

\[\begin{array}[t]{rcl} 0 &amp; = &amp; \lambda s. \lambda z. z \\ \mathit{succ} &amp; = &amp; \lambda n. \lambda s. \lambda z. s\ (n\ s\ z) \end{array}\]

<p>And here’s the same in Scheme</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">define</span> <span class="nv">zero</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">s</span><span class="p">)</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">z</span><span class="p">)</span> <span class="nv">z</span><span class="p">)))</span>
  <span class="p">(</span><span class="k">define</span> <span class="nv">succ</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>
		 <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">s</span><span class="p">)</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">z</span><span class="p">)</span>
			       <span class="p">(</span><span class="nf">s</span> <span class="p">((</span><span class="nf">n</span> <span class="nv">s</span><span class="p">)</span> <span class="nv">z</span><span class="p">))))))</span>
</code></pre></div></div>

<h1 id="the-factorial">The factorial</h1>

<p>Actually, it’s straightforward. Let’s start by repeating a conventional, recursive definition of the factorial procedure</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">fac</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>
	      <span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">0</span><span class="p">)</span>
		  <span class="mi">1</span>
		  <span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="p">(</span><span class="nf">fac</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">))))))</span>
</code></pre></div></div>

<p>Calculating the factorial on some input $n$ means, going through the body of the function multiple times, building up a large multiplication $n \times (n-1) \ldots 2 \times 1 \times 1$ until hitting the base case. And then calculating the result $n!$. So let’s first give a name for the function that calculates one round of going through the body of the factorial, let’s call it $F$.</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">F</span>
    <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">f</span><span class="p">)</span>
      <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>
	<span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">0</span><span class="p">)</span>
	    <span class="mi">1</span>
	    <span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="p">(</span><span class="nf">f</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">)))))))</span>
</code></pre></div></div>

<p>The body covers the base case, but for the recursion case, it uses its functional argument $f$ for a continuation. If we pile up $n$ of those $F$’s, we can go though the body $n$ times. However, if we need to go through the body more than the number of $F$’s piled up, we fall out at the bottom, and so we need to plug in some continuation for $f$ for that case.</p>

<p>Of course we don’t intend to fall out at the bottom by arranging for a pile of $F$ high enough for the concrete input. In other words, it should not matter what we choose for that. Let’s just raise an error in Scheme, and call the function <code class="language-plaintext highlighter-rouge">f0</code>:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">f0</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">x</span><span class="p">)</span> <span class="p">(</span><span class="nf">error</span> <span class="s">"Ouch! you should not see this..."</span><span class="p">)))</span>
</code></pre></div></div>

<p>This represents raising an error, and <strong>exceptions</strong> don’t fit well to pure forms of the $λ$-calculus. For instance, raising an error does not return a value, so errors don’t <strong>evaluate</strong> to something, they rather derail an ongoing evaluation. In the $λ$-calculus, non-termination is the only way to program a situation that don’t evaluate to something (and that would need recursion or something like the $Y$ combinator). At any rate, the traditional symbol for an “undefined” expression is $\bot$ (“bot” or “bottom”), and that’s what we use as well. If concerned that one would need recursion to achieve non-termination (representing being undefined), note that we simply need some function to plug in at the bottom and we don’t care which one, it can be any. So one can interpret $\bot$ also as being undefined in the sense of being not specified or arbitrary. And, as shown, in Scheme we raise an error.</p>

<p>As a side remark: note we have defined <code class="language-plaintext highlighter-rouge">f0</code> not as <code class="language-plaintext highlighter-rouge">(error "some message")</code>. Doing so would not work. Remember that Scheme is an <strong>eager</strong> language, using applicative order, and without the preceding <code class="language-plaintext highlighter-rouge">lambda</code>, the <code class="language-plaintext highlighter-rouge">f0</code> as argument would immediately raise the exception and derail the planned iteration before it even starts.</p>

<p>Now, to calculate $n!$, we need to iterate $F$ at least $n+1$ times, like that</p>

\[\underbrace{F (F (F .... (F}_{n+1} \ \bot)\]

<p>Since the church numerals exactly capture this form of iteration, we can simply write:</p>

\[\mathit{fac} = \lambda n. ((\mathit{succ}\ n)\ F)\ n\]

<p>Note: We would use the very same $F$, if we would use (a proper variant of) the famous <strong>$Y$-combinator</strong> instead of Church numerals, and <code class="language-plaintext highlighter-rouge">(Y F)</code> would give the factorial. That’s described in a different post.</p>

<h1 id="whats-missing-for-n-or-the-rest-of-the-interface">What’s missing for $n!$? Or: The rest of the interface</h1>

<p>We will not spell out the rest of the solution in full detail and only sketch what would need to be done. The above iteration of $F$ works fine, but we have not properly written up the body of $F$.</p>

<p>To say it differently: we have encoded or implemented $\operatorname{succ}$ and $0$, we also have hinted at that addition and multiplication can straightforwardly be defined, plus as iterated successor and multiplication as iterated addition. So we have covered the two <strong>constructors</strong> from the interface for natural numbers and we were able to do some more useful functions like $+$ and $\times$, but lacking are two other central aspects of the interface: the <strong>selectors</strong> and <strong>predicates</strong>. What we and SICP calls selectors is sometimes also called <strong>destructors</strong> (for instance in the Haskell community). One has to be a bit careful, also C++ and similar languages use the word “destructor” in connection with (object-oriented) data structures. But there it means something unrelated and has to do with object finalization and memory management, releasing memory at the end of a lifespan of some object. Functional languages, from the beginning, starting with Lisp, have automatic memory management, i.e., garbage collection, no functional programmer need to clean up personally…</p>

<p>Selectors are the inverse of constructors, constructors compose a larger composed structure from smaller parts, and selectors, also to access the parts from a composed one. As far as Lisp and Scheme are concerned, the constructor for pairs is <code class="language-plaintext highlighter-rouge">cons</code>, and the two destructors are <code class="language-plaintext highlighter-rouge">car</code> and <code class="language-plaintext highlighter-rouge">cdr</code>. For lists, the constructors are <code class="language-plaintext highlighter-rouge">'()</code> and <code class="language-plaintext highlighter-rouge">cons</code>, and the destructors are called same as for pairs. It might be clearer if one had used separate names, like <code class="language-plaintext highlighter-rouge">left</code> and <code class="language-plaintext highlighter-rouge">right</code> for the selectors for pairs and <code class="language-plaintext highlighter-rouge">head</code> and <code class="language-plaintext highlighter-rouge">tail</code> for the selectors for lists. Many (typed) functional languages would insist that two different abstract data type use a different set of constructors, so a <code class="language-plaintext highlighter-rouge">cons</code> (or whatever name or notation would be used for the constructor) would either construct a pair or a list, it can’t represent both constructions (even if internally both might be represented by something like cons-cells). Lisp and Scheme, being statically untyped, see nothing wrong with it.</p>

<p>So then what’s the selectors for natural numbers? The selectors have to give access to ``sub-structures’’ of a compound data structure. $0$ is not compound, it has no parts. So there is no selector corresponding to that. Numbers $n&gt;0$ are structured, there are constructed as $\operatorname{succ} (n-1)$, with $n-1$ taking the role of a substructure. A good name for the destructor or selector this is $\operatorname{pred}$ for <strong>predecessor</strong>.</p>

<p>Of course the predecessor of $0$ is undefined, $0$ is the smallest number. Analogously the selectors for lists can be applied to non-empty lists only, and applying <code class="language-plaintext highlighter-rouge">car</code> or <code class="language-plaintext highlighter-rouge">cdr</code> to the empty list <code class="language-plaintext highlighter-rouge">'()</code> is undefined, resp. raises an error. So, natural numbers have one selector, the predecessor, and it is indeed the inverse of the constructor:</p>

\[\operatorname{pred} (\operatorname{succ} n) = n \quad \operatorname{succ} (\operatorname{pred} n) = n \quad (\text{for $n&gt;0$})\]

<p>Note that we have not spelled out the <strong>implementation</strong> of $\operatorname{pred}$ as $λ$-expression or in Scheme. We <strong>specified</strong> its behavior in terms of how it works together with the constructors (inverting their effect). So that’s the <strong>interface contract</strong> the implementation of $\operatorname{pred}$ has to fulfill.</p>

<p>We won’t give an actual encoding or implementation for $\operatorname{pred}$ in our Church numerals here, it’s not really hard, but a bit more convoluted (and inefficient). If interested it can easily be found on the internet. The actual encoding is an interesting exercise, of more general interest are the underlying principles, like that the central ingredients of the structures interface are grouped into <strong>constructors</strong> and <strong>selectors/destructors</strong> with the requirement that one they are each others inverses. That principle generalizes also to other such data structure, they are generally called <strong>inductive data types</strong>.</p>

<p>$+$ and $\times$ are also important functions when talking about numbers. Useful as they are, they are not central to the inductive data type, they are build on top, and a natural number package could of course have very many useful functions besides $+$ and $\times$, for instance $n!$ etc.</p>

<p>But besides constructors and selectors, there is a <strong>third</strong> class of functions central to the interface (and used in $F$). In order to be generally useful, one needs a way of “comparing” numbers. At the very <strong>core</strong> of this is: we need to <strong>check if a number equals $0$ or not</strong>. Without that, we cannot separate the base case from the “recursion” case. As discussed at the beginning of this text, we are in a setting without the full power of recursion and we mentioned, that the selector/constructor way of presenting data structures leads to inductive data types. Thus, the recursion case(s) are alternatively also called <strong>induction</strong> or <strong>inductive</strong> case(s). Basically we doing <strong>inductive definitions</strong>, with induction being a restricted, more disciplined form of recursion, working on, well, inductive data types) Induction as proof principle (over natural numbers or over other inductively given structures) is likewise closely connected…</p>

<p>At any rate, for the natural numbers, the most basic form of “comparison” is the one for zero-ness. It’s a predicate that checks whether the base case applies or not. That’s exactly what we also need to program $F$ for the factorial.</p>

<p>With this basic predicate covered, other comparisons and useful predicates can be defined, like $n =^? m$ or also $n \leq^? m$ etc.</p>

<p>The check itself is encoded actually pretty simple. Remember that $0$ is an iterator, actually one that iterates it first argument function $0$-times, which means not at all, and thus gives back it’s second argument. For $n&gt;0$, the first argument is iterated at least one time. So we have just to arrange that the second argument corresponds to true, and in all other situations we have to return false:</p>

\[\operatorname{iszero?} = \lambda n.n\ (\lambda x.\operatorname{false})\ \operatorname{true}\]

<p>or in Scheme.</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">iszero?</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>
		 <span class="p">((</span><span class="nf">n</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">x</span><span class="p">)</span> <span class="no">#f</span><span class="p">))</span> <span class="no">#t</span><span class="p">)))</span>
</code></pre></div></div>

<h1 id="how-to-generalize--beyond-n-and-numbers-inductive-data-types-and-pattern-matching">How to generalize  beyond $n!$ and numbers: inductive data types and pattern matching</h1>

<p>The Church numerals is on the one hand a perhaps strange exercise in exploring the power of higher-order functions, and not useful as actual implementation of numbers. But encoding is not “arbitrary”, if follows patterns that opens the way to likewise encode other data structures. For instance, lists could be done like that (which is another inductive data structure) or also Booleans. In the above code we allowed ourselves to use the built-in <code class="language-plaintext highlighter-rouge">#t</code> and <code class="language-plaintext highlighter-rouge">#f</code>, but we could have pushed further and encoded also Booleans. We could do so by asking the same question we started with: what can Booleans <strong>do</strong> when not seeing them as data, but as procedure (and the answer would be: make a decision between two alternatives).</p>

<p>The general principles behind such encodings may get buried underneath mountains of parentheses and $\lambda$’s. More interesting seems to me to focus on the <strong>interface</strong> talking about the three crucial ingredient of such structures, <strong>constructors</strong>, <strong>selectors</strong>, and basic <strong>predicates</strong>. The latter need to discriminate between various constructors, making the appropriate case distinctions.</p>

<p>In Scheme, when designing and implementing structured data, such as trees, etc, one of course does not do a Church encoding of those. One relies on recursion, builds say, trees, using symbols as tags, and checks the tags by properly programmed predicates. The centrally built in data structure of lists, which conceptually is an inductive data structure, of course also has the corresponding predicate called <code class="language-plaintext highlighter-rouge">null?</code>. So the flexibility of Scheme allows to build inductive data structures in a disciplined manner (mostly relying on the flexibility of nested lists). Not that it’s recommended, but as discussed one could even push Scheme’s flexibility to the limit and use Church’s numerals as inspiration to encode the data structures not by the built-in lists but by procedures.</p>

<p>Not all functional languages allowed the almost boundless flexibility of Scheme. In particular typed functional languages impose much more discipline on the programmer. For instance, the $Y$ combinator will in all likelihood no longer be programmable in a type-safe manner, and also Church tricks run into trouble and may no longer be accepted by the type system which in itself seems like not a big loss… However, the type system might easily get into the way to forbid nesting lists in flexible ways to serve as some disciplined inductive data type.</p>

<p>But inductive data structures are eminently important and an programming language need to support or at least allow them, without the type system getting into the way. Type functional language typically “integrate” inductive types as part of <strong>type system</strong>. After all, the structures are called abstract or inductive data <strong>types</strong> for good reason. In Scheme, without a static type level that would imposing some discipline, following some discipline is the programmer’s responsibility, coming up with a collection of procedures, perhaps grouping them personally into selectors, constructors, and predicates and conceptually think of all that as (inductive) data type. But for Scheme, it’s all procedures and a collection of lists and cons-pairs and it falls on the shoulders of the programmer to disciplined enough to use the interface, and not use directly combinations of <code class="language-plaintext highlighter-rouge">cons</code>, <code class="language-plaintext highlighter-rouge">car</code> and <code class="language-plaintext highlighter-rouge">cdr</code>, knowing how the interface is implemented using nested lists… Type systems supporting such data types enforce the discipline.</p>

<p>Using some concrete typed functional language as example, one could define the natural number inductively as follows. The code concretely is in ocaml, some ML-inspired language, but many typed functional language will support more or less similar notations.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>type num =  Zero | Succ of num
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Zero</code> and <code class="language-plaintext highlighter-rouge">Succ</code> are the two constructors (constructors have to start with capitals, at least in ocaml), and <code class="language-plaintext highlighter-rouge">num</code> is the name given to the inductive data type it. We are no longer talking about of church numerals, which is mainly about <strong>encoding</strong> such inductive data structures in fancy way. We focus on the principles underlying the interface of such structures that we distilled when discussing the encoding. Of course the interpreter and the compiler will have to come up with some encoding, we don’t really care how it’s done, but we can be pretty sure, it’s not encoded by higher-order procedures …</p>

<p>Of course also ocaml or similar languages have numbers built in already, so we would actually of course not need to define the type <code class="language-plaintext highlighter-rouge">num</code>. We use it for illustration.</p>

<p>With the type definition we have covered the <strong>constructors</strong> of the interface. We can construct number like <code class="language-plaintext highlighter-rouge">Succ (Succ (Succ Zero))</code> as representation of for $3$. Of course, the numbers won’t work as iterators (and we actually don’t miss that aspect much either). But what about <strong>selectors</strong> and <strong>predicates</strong>?</p>

<p>Actually, those are conventionally combined in an elegant manner in typed functional languages, namely by <strong>pattern matching</strong>. A typical use is in combination with a “case switch” to cover different shapes of the data structure, for our nats there are two cases, one base case and one inductive case (and using recursion):</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">plus</span> <span class="n">n</span> <span class="n">m</span> <span class="o">=</span>
  <span class="k">match</span> <span class="n">n</span> <span class="k">with</span>  <span class="o">//</span> <span class="n">matching</span>
    <span class="nc">Zero</span> <span class="o">-&gt;</span> <span class="n">m</span>
  <span class="o">|</span> <span class="nc">Succ</span> <span class="n">n'</span> <span class="o">-&gt;</span> <span class="nc">Succ</span> <span class="p">((</span><span class="n">plus</span> <span class="n">n'</span><span class="p">)</span> <span class="n">m</span><span class="p">)</span>
</code></pre></div></div>

<p>In Scheme, we used the predicate <code class="language-plaintext highlighter-rouge">iszero?</code> which covers the base case. The match here explicitly checks both possible cases, and note how the <strong>pattern match</strong> combines the check which case it is with the <strong>selection</strong> or <strong>deconstruction</strong> of $n$: the predecessor $n’$ of the argument is just mentioned in the matching expression.</p>

<p>If we would explicitly need the predecessor selector mentioned earlier, we could program it as shown below. Typically one would see no need in doing so, as its functionality is typically exploited in combination with matching and with a case distinction. Not just because it’s “elegant”, but to protect against <strong>run-time errors</strong>. Remember that <code class="language-plaintext highlighter-rouge">pred</code> on $0$ is an error, so it’s good practice to combine the use of <code class="language-plaintext highlighter-rouge">pred</code> with a prior check whether <code class="language-plaintext highlighter-rouge">iszero?</code> is false. And that’s exactly what the above body of <code class="language-plaintext highlighter-rouge">plus</code> does with the match and the case branches.</p>

<p>Anyway, if one needs the unsafe <code class="language-plaintext highlighter-rouge">pred</code>, the selector that does not care checking if there’s something to select, one could simply write</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">let</span> <span class="n">pred</span> <span class="p">(</span><span class="nc">Succ</span> <span class="n">n'</span><span class="p">)</span> <span class="o">=</span> <span class="n">n'</span><span class="p">;;</span>
</code></pre></div></div>

<p>The real selection functionality in done by matching the argument against the pattern <code class="language-plaintext highlighter-rouge">Succ n'</code>, so that’s elegant enough as selection mechanism. That’s why we said above that one typically might not even see the need to give that match a name like <code class="language-plaintext highlighter-rouge">pred</code>.</p>

<p>The type system may prevent the flexibility offered by Scheme, but on the other hand it can warn us, if we have uncovered cases, for instance for the definition of <code class="language-plaintext highlighter-rouge">pred</code> it warns us:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Warning [partial-match]: this pattern-matching is not exhaustive.
Here is an example of a case that is not matched: Zero
</code></pre></div></div>

<p>We could get rid of the warning by issuing a tailor-made error message (or doing something else for $0$).</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">pred</span> <span class="n">n</span> <span class="o">-&gt;</span>
    <span class="k">match</span> <span class="n">n</span> <span class="k">with</span>
      <span class="o">|</span> <span class="nc">Succ</span> <span class="n">n'</span> <span class="o">-&gt;</span> <span class="n">n'</span>
      <span class="o">|</span> <span class="n">_</span> <span class="k">raise</span> <span class="p">(</span><span class="nc">Failure</span> <span class="s2">"Pred of Zero undefined"</span><span class="p">);;</span>
</code></pre></div></div>

<p>Still, <code class="language-plaintext highlighter-rouge">pred</code> is only partially defined, but as long as we don’t go to negative numbers as well, something does not fit if we really want the predecessor of $0$. And as said, the selection is best done in combination with a case match covering all cases, to avoid running into those troubles.</p>

<h1 id="to-sum-up">To sum up</h1>

<p>We have sketched the idea of Church numerals, a procedural encoding of natural numbers. Each number $n$ is represented as a function that corresponds to an iterator or a loop of length $n$. All numbers can be defined by two constructors, we could call $0$ and $\operatorname{succ}$. Since these number are actually iterators, one can use the numbers to define further useful function (by iteration). The full power of recursion can’t be done this way, all procedures will terminate, but it’s enough to program factorial.</p>

<p>Focusing on the interface, we stressed that besides constructors, the core of the interface of a data structure like <code class="language-plaintext highlighter-rouge">nat</code> involves selectors and predicates to make the necessary case distinctions. Those kind of data structures are called <strong>inductive data types</strong>. Typed languages support constructors allowing to introduce types by specifying the constructors. The functionality of selectors and predicates is achieve in a combined manner by <strong>pattern matching</strong>.</p>

<h1 id="theres-still-something-missing">There’s still something missing</h1>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="Church numerals" /><category term="lambda calculus" /><category term="induction" /><category term="for loops" /><category term="recursion" /><category term="foundations" /><category term="pattern matching" /><category term="inductive data types" /><summary type="html"><![CDATA[A glance at Church numerals, inductive data types, and pattern matching]]></summary></entry><entry><title type="html">Y Y?</title><link href="/functionalprogramming/2023/10/09/ycombinator.html" rel="alternate" type="text/html" title="Y Y?" /><published>2023-10-09T00:00:00+02:00</published><updated>2023-10-09T00:00:00+02:00</updated><id>/functionalprogramming/2023/10/09/ycombinator</id><content type="html" xml:base="/functionalprogramming/2023/10/09/ycombinator.html"><![CDATA[<p>This is another post in connection with some slides shown in the lecture, which may have been a bit obscure.</p>

<p>The text here is concretely triggered by a slide in week 9 about “recursion with anonymous procedures”. The slide showed a version of the factorial function programmed in a way unlike any we have seen before (and unlike any we will see afterwards). And programmed in a rather obscure way. The factorial is programmed <strong>without recursion</strong>, in that there’s no procedure that calls itself, at least not in an obvious way. It only uses $λ$-expressions, i.e., only <strong>anonymous</strong> functions.</p>

<h1 id="recap-coding-factorial-using-only-anonymous-functions">Recap: Coding factorial using only anonymous functions</h1>

<p>Let’s start out with a recursive definition of <code class="language-plaintext highlighter-rouge">fac</code>. <code class="language-plaintext highlighter-rouge">fac</code> is bound to a $λ$-abstraction, and in the procedure body, <code class="language-plaintext highlighter-rouge">fac</code> is mentioned and called. Probably we got used to recursive definitions meanwhile that we don’t puzzle about that too much.</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">fac</span>
    <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>
      <span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">)</span>
	  <span class="mi">1</span>
	  <span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="p">(</span><span class="nf">fac</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">))))))</span>
</code></pre></div></div>

<p>Perhaps it’s worth to point out a crucial difference between <code class="language-plaintext highlighter-rouge">define</code> and <code class="language-plaintext highlighter-rouge">let</code>. It’s not possible to define <code class="language-plaintext highlighter-rouge">fac</code> using let as follows:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">let</span> <span class="p">((</span><span class="nf">fac</span>
       <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>
	 <span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">)</span>
	     <span class="mi">1</span>
	     <span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="p">(</span><span class="nf">fac</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">)))))))</span>  <span class="c1">;; note that fac is</span>
                                      <span class="c1">;; introduced via</span>
                                      <span class="c1">;; let!</span>
  <span class="nv">&lt;scope</span> <span class="nv">where</span> <span class="nv">fac</span> <span class="nv">is</span> <span class="nv">intended</span> <span class="nv">to</span> <span class="nv">be</span> <span class="nv">used&gt;</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Let</code> works similarly as <code class="language-plaintext highlighter-rouge">define</code> (though it has an explicitly specified scope): it binds <code class="language-plaintext highlighter-rouge">fac</code> to this lambda-expression. However, this time it won’t work as intended, as <code class="language-plaintext highlighter-rouge">fac</code> is not yet defined. If you try that example yourself in some scheme interpreter, make sure that <code class="language-plaintext highlighter-rouge">fac</code> has not already been defined earlier, otherwise it will look as if it worked insofar the correct value comes out. But in that case, the <code class="language-plaintext highlighter-rouge">fac</code> introduced via <code class="language-plaintext highlighter-rouge">let</code> simply calls the previously defined <code class="language-plaintext highlighter-rouge">let</code>, it’s not a recursive (re-)definition.</p>

<p>While at it: there exists a variant (not discussed in the lecture) of <code class="language-plaintext highlighter-rouge">let</code> which would work, it’s called <code class="language-plaintext highlighter-rouge">letrec</code> and that would allow an intended recursive definition of <code class="language-plaintext highlighter-rouge">fac</code> (and in that respect works analogous to <code class="language-plaintext highlighter-rouge">define</code>).</p>

<p>So far so good (and known from the lecture). But now we no longer want to use <code class="language-plaintext highlighter-rouge">define</code> to program factorial as above at least not recursively. Nor <code class="language-plaintext highlighter-rouge">letrec</code> obviously, nor <code class="language-plaintext highlighter-rouge">while</code> or other looping constructs that you favorite Scheme dialect may support (<code class="language-plaintext highlighter-rouge">while</code> is often supported. Additionally one can program <code class="language-plaintext highlighter-rouge">while</code> easily oneself (using recursion) so that would not help).</p>

<p>Now: let’s look at the $λ$-abstraction in isolation, i.e., the above standard definition just without giving it a name with <code class="language-plaintext highlighter-rouge">define</code>.</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>
   <span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">0</span><span class="p">)</span>
       <span class="mi">1</span>
       <span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="p">(</span><span class="nf">fac</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">)))))</span>
</code></pre></div></div>

<p>The base case is covered, but the branch that corresponds to the recursion case is not. For $n&gt;0$, the body invokes <code class="language-plaintext highlighter-rouge">fac</code> which is undefined, resp. if it happens to be defined by coincidence from earlier, it’s probably not the factorial, as we are still struggling to get it defined. So let’s don’t rely on some unknown thing called <code class="language-plaintext highlighter-rouge">fac</code> coming from outside and probably undefined anyway, let’s hand over the missing continuation to cover the recursion case as functional argument:</p>

<p><a id="org8a8a022"></a></p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">f</span><span class="p">)</span>    <span class="c1">;; let's refer to the whole</span>
    <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>  <span class="c1">;; construction here (a higher-</span>
      <span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">0</span><span class="p">)</span><span class="c1">;; order function) as F</span>
	  <span class="mi">1</span>
	  <span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="p">(</span><span class="nf">f</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">))))))</span>
</code></pre></div></div>

<p>NB: the term “continuation” has a specific meaning in functional programming and there exists a style of programming which is called CPS, continuation passing style. We are not claiming that the above code is strictly CPS, but there is a connection: We hand over a function that describes how to continue at the end of the function body, here at least that the one possible end that corresponds to the recursive case.</p>

<p>At any rate, let’s refer to the above function as $F$. Given a continuation function $f$ as argument, it corresponds to the body of the factorial.</p>

<p>The base case is covered, and in the recursion case, the body uses the argument $f$ to calculate the return value. Since $f$ is an argument, it can be anything, but what is needed for $n\geq 1$, where recursion should kick in, is to calculate $F$ <strong>again</strong>, this time with the numerical argument $n-1$. And going through the body of $F$ one more round would probably not be enough. So in the next-round’s recursion case, the same problem would present itself, namely how to continue just another layer of the body, and the solution would be the same yet again: do $F$ one more time, and if needed, still another round, and on and on.</p>

<p>That can be achieved by doing the following in the recursion case, calling $F$ and feeding to that next call to $F$ the function $F$ again, should that next round not be enough:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="p">((</span><span class="nf">F</span> <span class="nv">F</span><span class="p">)</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">)))</span>  <span class="c1">;; recursion case in the body of F</span>
</code></pre></div></div>

<p>Since $F$ is not only called but additionally handed over as further continuation in the next recursion case, the pattern repeats itself and the pattern can continue arbitrarily long. And for the factorial function, at least with a non-negative input, after a finite amount of repeating itself, the schema will hit the base case for $n=0$, and the correct value of $n!$ will be returned.</p>

<p>We are, however, not out of the woods yet. The previous code snippet mentions $F$, resp. $F F$ in the recursion case. Note that we have <strong>not officially named</strong> the higher-order function from the <a href="#org8a8a022">above Listing</a> by the name $F$ (doing <code class="language-plaintext highlighter-rouge">(define F ....)</code>: we agreed among ourselves to call it $F$ in the explanatory text, but not as part of the program.</p>

<p>We could have given the anonymous function officially the name $F$ with <code class="language-plaintext highlighter-rouge">define</code>, but what we discussed was that $F$ is used as <strong>argument</strong> to that function, i.e., in place for the formal parameter $f$. Besides, if we had introduced the name $F$ for the function and then used in the the recursion case, that would be a case of direct recursion using a function’s name, that’s exactly what we don’t want to do.</p>

<p>So: how can we use $F$ as argument to itself, without relying on direct recursion? That’s actually not hard, we just <strong>program it two times</strong>, and feed the second copy as argument to the first. However, as explained above, we need in the body something to the effect of <code class="language-plaintext highlighter-rouge">(* n (F F) (- n 1))</code>. That means, we need to <strong>massage</strong> the implementation $F$ in such a way, that $n-1$ is not fed as argument to $f$ (as done in $F$ and in the factorial function), but fed as argument to $f f$. That leads to the following massaged version of $F$</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">f</span><span class="p">)</span>    <span class="c1">;; new variant of F</span>
   <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>
     <span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">0</span><span class="p">)</span>
	 <span class="mi">1</span>
	 <span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="p">((</span><span class="nf">f</span> <span class="nv">f</span><span class="p">)</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">)))))</span>  <span class="c1">;; self-application of argument f</span>
</code></pre></div></div>

<p>And if we apply that version to itself, we get the following function.</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">((</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">f</span><span class="p">)</span>     
   <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>
     <span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">0</span><span class="p">)</span>
	 <span class="mi">1</span>
	 <span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="p">((</span><span class="nf">f</span> <span class="nv">f</span><span class="p">)</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">))))))</span>
 <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">f</span><span class="p">)</span>    
   <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>
     <span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">0</span><span class="p">)</span>
	 <span class="mi">1</span>
	<span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="p">((</span><span class="nf">f</span> <span class="nv">f</span><span class="p">)</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">)))))))</span>
</code></pre></div></div>

<blockquote>
  <p><strong>And we are done, that’s the factorial!</strong></p>
</blockquote>

<p>One can test it easily on some input. Of course it looks a bit unelegant, so let’s clean it up a bit. We can introduce a name $F’$ for the massaged version of $F$ and using <code class="language-plaintext highlighter-rouge">let</code> to avoid repeating the code, and finally we can give the whole construction a conventional name, namely <code class="language-plaintext highlighter-rouge">fac</code>. Note that neither <code class="language-plaintext highlighter-rouge">let</code> nor the use of <code class="language-plaintext highlighter-rouge">define</code> for <code class="language-plaintext highlighter-rouge">fac</code> involves recursion.</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">fac</span> <span class="p">(</span><span class="k">let</span> <span class="p">((</span><span class="nf">F</span><span class="o">'</span>  <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">f</span><span class="p">)</span>    
			 <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>
			   <span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">0</span><span class="p">)</span>
			       <span class="mi">1</span>
			       <span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="p">((</span><span class="nf">f</span> <span class="nv">f</span><span class="p">)</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">))))))))</span>
	      <span class="p">(</span><span class="nf">F</span><span class="o">'</span> <span class="nv">F</span><span class="o">'</span><span class="p">)))</span>
</code></pre></div></div>

<h1 id="factorial-is-fine-and-good-but-how-to-generalize-that">Factorial is fine and good, but how to generalize that?</h1>

<p>The above construction is concretely done for the factorial. Fine as it is, we are interested in doing it <strong>generally</strong>, i.e., given a recursive definition of a function and turning it to one that works without recursion. And it’s not good enough to understand the way it worked for <code class="language-plaintext highlighter-rouge">fac</code>, and when dealing with another recursive definition, do the same trick again for the body of that new function. A <strong>convincing</strong> generalization would be one that does not involve us, fiddling with the code, like retyping the body $F$ into the massaged version $F’$. Instead,</p>

<blockquote>
  <p>we want to define a Scheme procedure that takes the body $F$ and <strong>directly</strong> returns the recursive procedure that corresponds to $F$!</p>
</blockquote>

<p>Also that is easy to do (kind of…), though we run into another (small) problem, at least in Scheme and similar settings.</p>

<p>It’s not just desirable to avoid to massage the code of $F$ in $F’$, it is necessary to do the whole trick without having access of the actual code of $F$, because $F$ is a formal parameter of the procedure. This we are forced to treat the functional argument as <strong>black box</strong>.</p>

<p>Turning $F$ to $F’$ without having access to the code of $F$ is actually quite easy. In the concrete factorial example, the code massage from $F$ to $F’$ “rewrites” the code so that a self-application $f\ f$ was used in $F’$ instead of $f$, as in $F$. We can achieve the same effect <strong>from the outside</strong>. Instead of feeding $F’$ into $F’$ and have $F’$’s body duplicate the argument $F’$ into a self-application $F’\ F’$, we just do the self-application outside and hand over $F\ F$ <strong>as argument</strong>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  (lambda (f) (F (f f)))   ;; corresponds (somehow) to F'
</code></pre></div></div>

<p>Now we can apply that construction to itself <code class="language-plaintext highlighter-rouge">((lambda (f) (F (f f))) (lambda (f) (F (f f))))</code>, doing the same trick as before in the special setting where $F$ represented the effect of the body of the factorial function. The only thing left to do is to have $F$ as argument to the construction, like the following</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(lambda (F)                ;;  F as argument
  (lambda (f) (F (f f)))   ;; corresponds (somehow) to F'
  (lambda (f) (F (f f)))   ;; and is applied to itself
</code></pre></div></div>

<p>We may write it also in math-notation, i.e., as expression from the $λ$-calculus, and it looks like this</p>

<p><a id="org9055c5c"></a> \(\lambda F. ((\lambda f. F\ (f\ f))\ (\lambda f. F\ (f\ f)))\)</p>

<p>[NB: the conventions for when and how to use parentheses in the $λ$-calculus are different from the conventions in Lisp or Scheme. One just has to be careful with that. For instance, if we had written above $F\ f \ f$ instead of $F\ (f\ f)$, it would look as if that corresponded to <code class="language-plaintext highlighter-rouge">(F f f)</code> in Scheme, but it does not; it would correspond to <code class="language-plaintext highlighter-rouge">((F f) f)</code> in Scheme (and would not do the job). Just something one needs to keep in mind.]</p>

<p>Anyway, this expression is known in the $λ$-calculus as […drum rolls…]</p>

<blockquote>
  <p><strong>the $Y$-combinator</strong>!</p>
</blockquote>

<p>There are slight reformulations of that doing the same (for instance using <code class="language-plaintext highlighter-rouge">let</code>). And there are other such functions to achieve recursion, but doing it differently in a more serious manner, one of which we will (have to) look at.</p>

<p>First, let’s take the above $Y$ and try it out in Scheme, giving it its traditional name first</p>

<p><a id="org76de89c"></a></p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">define</span> <span class="nv">Y</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">F</span><span class="p">)</span>
    <span class="p">((</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">x</span><span class="p">)</span> <span class="p">(</span><span class="nf">F</span> <span class="p">(</span><span class="nf">x</span> <span class="nv">x</span><span class="p">)))</span>
     <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">x</span><span class="p">)</span> <span class="p">(</span><span class="nf">F</span> <span class="p">(</span><span class="nf">x</span> <span class="nv">x</span><span class="p">)))))</span>
</code></pre></div></div>

<p>resp. let’s use an equivalent reformulation with let, which is slightly shorter</p>

<p><a id="org70dca9b"></a></p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">define</span> <span class="nv">Y</span>
    <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">F</span><span class="p">)</span>
      <span class="p">(</span><span class="k">let</span> <span class="p">((</span><span class="nf">f</span>  <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">x</span><span class="p">)</span> <span class="p">(</span><span class="nf">F</span> <span class="p">(</span><span class="nf">x</span> <span class="nv">x</span><span class="p">)))))</span>
	<span class="p">(</span><span class="nf">f</span> <span class="nv">f</span><span class="p">))))</span>
</code></pre></div></div>

<p>So, it took some meandering, we finally came up with a Scheme procedure that corresponds to the $Y$-combinator, which is known to achieve our goal: turn a procedure body like $F$ into a <strong>recursive</strong> procedure.</p>

<p>Then let’s reward ourselves and use it to run a version of factorial using the $Y$ combinator. Here’s again the body of the factorial from the beginning (see <a href="#org8a8a022">here</a>):</p>

<p><a id="orgd327be2"></a></p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">define</span> <span class="nv">F</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">f</span><span class="p">)</span>    
	      <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">n</span><span class="p">)</span>
		<span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">0</span><span class="p">)</span>
		    <span class="mi">1</span>
		    <span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="p">(</span><span class="nf">f</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">)))))))</span>
</code></pre></div></div>

<p>and then proudly apply our $Y$ combinator to it:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  (Y F)
</code></pre></div></div>

<p>Ouch! That <strong>crashes</strong> the interpreter with a stack overflow. That’s bad news.</p>

<h1 id="wait-a-second-not-so-eagerly">Wait a second, not so eagerly.</h1>

<p>Crashing the interpreter is sure not desirable, but always look at the bright side: it’s <strong>good news too!</strong> The application is <em>non-terminating</em>, resp. in practice, it runs out of stack memory. That’s indeed a good sign, namely a <strong>sign of a recursion.</strong> Unfortunately a recursion gone wrong.</p>

<p>At first sight, it might be puzzling: we have encoded the famous $Y$ combinator but it does not work. As mentioned, however, $Y$ is not the only combinator to achieve the trick, there are variations of the general idea of <strong>self application</strong>.</p>

<p>The equation for $Y$ from <a href="#org9055c5c">above</a> was written as term of the $λ$-calculus. Scheme can be seen as an implementation of the $λ$-calculus (with additional features needed for practical programming such as I/O etc). To be precise, there are also different $λ$-calculi, including many different typed versions, but Scheme most closely resembles an <strong>untyped</strong> $λ$-calculus.</p>

<p>But Scheme is a programming language, executed in a particular way, namely doing <strong>applicative order</strong>: arguments in an application need to be <strong>evaluated first</strong> before handed over in a procedure call. $λ$-calculi are often presented without fixing an evaluation strategy, resp. the evaluation strategy is left open and arbitrary. As presented in the lecture, for purely functional settings, the evaluation is based on <strong>substitution</strong>, the so-called <strong>substitution model</strong> from SICP. An expression can have multiple places where do so a substitution, i.e., multiple opportunities to apply a procedure to its argument(s), and an evaluation strategy fixes which one(s) should or could be taken. The lecture covered <strong>applicative</strong> and <strong>normal</strong> order evaluation, as the two practically relevant one for functional languages, but for the $λ$-calculus one can study more strategies (which involves where to evaluate and when to stop. Some strategies even allow multiple places in parallel or allow random choices). As a side remark, for $λ$-calculi one often speaks also of <strong>reduction strategies</strong> instead of evaluation strategies, and the basic substitution step is called a $β$-reduction step (but it’s another word for substituting the formal parameter of a function by its actual argument), and evaluation means “reducing” an expression to its value.</p>

<p>Scheme uses applicative order, it follows <strong>eager evaluation</strong>. And that’s the <strong>problem</strong> here. If we apply $Y$ to $F$, $F$ gets substituted into the body of $Y$, which is another (self-)application, that needs to be evaluated. After substitution, there is another (self-)application, so the process never ends, there is each time still another application as argument, and eager evaluation requires that the argument needs to be evaluated, so it never stops:</p>

\[\begin{array}[t]{l@{\qqad}l} Y\ F &amp; \rightarrow \\ \mathit{let}\ f = \lambda x. F (x\ x) \mathit{in}\ f\ f &amp; \rightarrow \\ (\lambda x. F (x\ x))\ (\lambda x. F (x\ x))&amp; \rightarrow \\ F\ ((\lambda x. F (x\ x))\ (\lambda x. F (x\ x))) &amp; \rightarrow \\ F\ (F\ ((\lambda x. F (x\ x))\ (\lambda x. F (x\ x)))) &amp; \rightarrow \ldots \end{array}\]

<p>My bad, it’s recursion, but useless…</p>

<p>But it can be repaired. What’s needed is to <strong>delay</strong> the further evaluation of self-application argument, something like</p>

\[\begin{array}[t]{rl} (\lambda x. F\ (\mathbf{delay}\ (x\ x)))\ (\lambda x. F\ (\mathbf{delay}\ (x\ x))) &amp; \rightarrow \\ F\ (\mathbf{delay}\ ( \begin{array}[t]{l} (\lambda x. F\ (\mathbf{delay}\ (x\ x))) \\ (\lambda x. F\ (\mathbf{delay}\ (x\ x))))) \end{array} \end{array}\]

<p>At that point, the argument of the outermost $F$ is not further explored, but handed over as value to $F$. After that substitution step, its an expression that looks like:</p>

\[\begin{array}[t]{lll} \lambda n. &amp; \mathit{if}\ &amp; n= 0 \\ &amp; \mathit{then}\ &amp; 1 \\ &amp; \mathit{else} &amp; n \times \langle\text{self-application again (with delay)}\rangle (n-1) \end{array}\]

<p>That’s a function that takes a number as argument, and does the body of the factorial and uses itself again as continuation in the recursion case. In particular, the body after $\lambda n$ is not further evaluated. It only starts getting into action when we provide a numerical argument. But this time, when giving a numerical argument, the recursion will stop, as at some point it will hit the base case, (at least for arguments $\geq 0$), just as the factorial does.</p>

<p>Now how do we do that form of delaying? Not evaluating arguments in a procedure call also underlies normal-order evaluation and the closely related notion of <strong>lazy evaluation</strong>. It also called delayed evaluation (or call-by-need), just what we are looking for. The lecture discusses two special forms <code class="language-plaintext highlighter-rouge">delay</code> and <code class="language-plaintext highlighter-rouge">force</code> in that context, but we also discuss how one can delay evaluation without relying on those built-in special forms.</p>

<p>It goes like this: First observe that a $λ$-expression like $\lambda x. e$ is a value, it counts as <strong>evaluated</strong>. In the $λ$-calculus, one might find places in the body $e$ where one could reduce, if one allowed substitutions to be done at any place inside an expression, not only on the top-level, but that’s not how it works in Scheme (or programming languages in general). Procedures only get evaluated when and if actually called. Now suppose that $e$ represents itself a function. It could itself be an application but after some evaluation steps it will evolve into a function. But by adding a $\lambda$ in front and applying $e$ to the formal argument $x$, we can delay the evaluation of $e$:</p>

\[\lambda x. e\ x\]

<p>That’s the trick that delays the evaluation of $e$ until an actual argument is provided. NB: in the $λ$-calculus, $e$ and $\lambda x. e\ x$ are said to be $η$-equivalent (“eta-equivalent”). Of course, it’s required that $e$ does not by coincidence mentions $x$ as free variable. But we can also pick another variable instead of $x$ if need be.</p>

<p>The trick make sense only if $e$ corresponds to a function, so <code class="language-plaintext highlighter-rouge">(lambda (x) (1 x))</code> is not really meaningful. In the 100% pure and theoretical $λ$-calculus, everything is a function anyway and one needs not to worry. In Scheme $1$ is not a function, so we would have to be careful, but thankfully, the self-application $x x$ represents a function. So we can use the $η$-delay trick and write it up like that:</p>

<p><a id="org6f66e77"></a> \(Y' = \lambda F. ((\lambda x. F\ (\lambda y. x\ x\ y))\ (\lambda x. F\ (\lambda y. x\ x\ y)))\)</p>

<p>That’s also known as the <strong>strict</strong> variation of the $Y$ combinator, as it does the job for eager functional languages like Scheme (and strict means following eager / applicative order evaluation).</p>

<p>And now, we are really done! For good measure, let’s just give the corresponding Scheme code.</p>

<p><a id="org66a0935"></a></p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="nv">Y</span><span class="o">'</span>
  <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">F</span><span class="p">)</span>
    <span class="p">(</span><span class="k">let</span> <span class="p">((</span><span class="nf">f</span>  <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">x</span><span class="p">)</span> <span class="p">(</span><span class="nf">F</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="nf">y</span><span class="p">)</span> <span class="p">((</span><span class="nf">x</span> <span class="nv">x</span><span class="p">)</span> <span class="nv">y</span><span class="p">))))))</span>
      <span class="p">(</span><span class="nf">f</span> <span class="nv">f</span><span class="p">))))</span>
</code></pre></div></div>

<h1 id="wrapping-up-some-loose-ends">Wrapping up some loose ends</h1>

<p>The $Y$-combinator is also called Curry’s <strong>paradoxical combinator</strong> (after Haskell Curry), and $Y$ and its variants are known as <strong>fixpoint combinators</strong>. Ultimately, those are just complicated functions or procedures, exploiting self-application in one way or the other. But why combinators? There’s no deep meaning behind it. Ultimately (and for historical reasons) a $λ$-term without free variables is called a combinator. With this terminology, <code class="language-plaintext highlighter-rouge">(lambda (x) (* x x))</code> is a combinator that calculates squares as there are no free variables. Of course if we count <code class="language-plaintext highlighter-rouge">*</code> as free variable, which we should if we take it 100% exact, then it’s not a combinator, but let’s ignore that here and no one speaks like that anyway and says “square-combinator”…. Anyway, there are versions of the $λ$-calculus that do away with variables <strong>altogether</strong>. One cannot even write down “procedures” with formal parameters, as there are <strong>no variables at all</strong> and one is forced to work with combinators only. The calculus looks quite alien, and it’s connected to <strong>combinatory logic</strong>. Indeed, the $λ$-calculus (both typed and untyped) have roots and deep connections (also) in and to logics.</p>

<p>Why is it called <strong>paradoxical</strong> combinator? That has to do with said connections to logic. Curry and others invented and investigated such combinators in connection with (foundations of) logics, and $Y$ and its friends have connections to <strong>logical paradoxes</strong>.</p>

<p>Why <strong>fixpoint</strong> operators? As it turns out, applying $Y$ to a function (like $F$) calculates what is called a <strong>fixpoint</strong> of its argument, like a fixpoint of $F$. A fixpoint of a function as such is easy to understand: a fixpoint of $f$ is a value $a$ such that $f(a) = a$. For our specific $F$, the fixpoint of the construction results in the factorial:</p>

\[Y\ F = f_\mathit{factorial}\]

<p>but it’s a general observation: A recursive function can be understood as fixpoint of a function representing the effect of its body, and a $Y$-combinator calculates the proper fixpoint.</p>

<p>Proper fixpoint means, the smallest fixpoint though working out in which way to understand “small” and understand why it always exists and why it is uniquely defined would require more explanations and background. Fixpoints are quite interesting, for instance, there is a connection between “eager” and finite data structures which are smallest fixpoints of some construction and “lazy” and potentially infinite data structures, like <strong>streams</strong>, which are largest fixpoints. But we leave it at that (perhaps for a later post) as the text is getting longish already…</p>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="Y combinator" /><category term="lambda calculus" /><category term="recursion" /><category term="Turing completeness" /><category term="computable functions" /><category term="foundation" /><category term="Church numerals" /><summary type="html"><![CDATA[or why Y?]]></summary></entry><entry><title type="html">Processes and procedures</title><link href="/functionalprogramming/2023/09/26/processprocedure.html" rel="alternate" type="text/html" title="Processes and procedures" /><published>2023-09-26T00:00:00+02:00</published><updated>2022-10-10T00:00:00+02:00</updated><id>/functionalprogramming/2023/09/26/processprocedure</id><content type="html" xml:base="/functionalprogramming/2023/09/26/processprocedure.html"><![CDATA[<p>From the group sessions I got feedback that the concepts of processes vs procedures and functions remained shady and a bit unclear (at least for some). Thus I write a few lines on that. I won’t repeat the examples and sentences from SICP; there is Section 1.2 (“Procedures and the processes generate”) which is intended to clarify the matter. Instead I “talk around” the concepts a bit.</p>

<p>To start with, it’s partly a terminology question, a question about (the use of) words. Using the correct words and using words correctly is course important, one needs to know the technical terms to communicate efficiently and understand texts. But terminology is only use up-to a point, and words may not and cannot be used 100% precise; natural language is not as precise like a mathematical definition or a piece of code, so there is always some slack.</p>

<p>Additionally different communities may use words differently. That applies also to the concepts discussed here, in particular “function” and “procedures”. In other programming languages, even in other Lisp/Scheme material, the words may be used slightly differently. In general, not only is Scheme a language that differs in many ways from many other languages, but the book SICP is quite idiosyncratic in its use of words, i.e., it makes choices sometimes to use words different from what the (programming languages) world outside the book does. Examples for that is the narrow definition of “tail-recursion” and the (non-)use of the word of “closures”.</p>

<p>However, the book is <strong>consistent</strong> and <strong>clear</strong> in its choices and use its words carefully.</p>

<h1 id="procedures-and-processes">Procedures and processes</h1>

<p>Now, what’s procedures and processes? Those are different concepts and can be discussed in connection with every programming language. Whether elsewhere they call the concept “procedure” or whether they dicuss “processes” at all is a separate question. One can learn a language and to use it and solve problems without thinking about it, at least to some extent. Still, as long as the programming language one is studying is real in the sense of being run on a computer (interpreted on an interpreter or on a virtual machine or also compiled and then run), the concept of process exist in principle:</p>

<blockquote>
  <p>a <strong>process is a piece of code under execution</strong></p>
</blockquote>

<p>and here, in this section, the code is arranged in a functional manner based on procedures. When saying the code is under execution, it’s not literally meant that the the syntax of the program is transformed as it seems to be the case in the illustrations of the substitution model in the section discussing processes and procedures. In the larger context, it can also mean, that the code has been compiled to some machine code (in a compiled language), and it’s the machine code that is actually being run (as or in a process). Or some byte-code corresponding to the user code is run on a virtual machine, etc.</p>

<p>The discussion about processes and procedures is done in connection with recursion, in particular distinguishing between <strong>linear recursion</strong>, <strong>tail recursion</strong>, and <strong>tree recursion</strong>. That is done by looking at how corresponding pieces of code, the procedures, are <strong>“run”</strong>. That means, how they are <strong>evaluated</strong>. A procedure being run (or executed or evaluated) corresponds to a <strong>process</strong>. That’s why section 1.2 in SICP is also called “procedures and processes they generate”. And that’s why I said all programming languages will have the concept of “processes”, whether they use that particular word, or whether they discuss at all what happens when a program is run does not matter. As long as a piece of code is run, there is a <strong>run-time entity</strong> which we call process.</p>

<p>While other textbooks may do their presentation without mentioning of processes, SICP does. One should also keep in mind that the title of the book is not called “An introductory course to Scheme programming”, but “<strong>Structure and interpretation of computer programs</strong>”, so one important part is not just to learn Scheme, or to just learn to program in a functional way, but also to understand how programs are executed, in particular interpreted, i.e., run on an interpreter.</p>

<p>The pictures in Section 1.2 SICP are of course exactly that: pictorial representations (SICP also uses the word “visualization”) of what’s going on when a procedure (here <code class="language-plaintext highlighter-rouge">fac</code>, and the iterative version of <code class="language-plaintext highlighter-rouge">fac</code> and finally <code class="language-plaintext highlighter-rouge">fib</code>) is run. In that way the pictures describe (aspects of) the corresponding processes, resp. how those processes evolve.</p>

<p>While I said, that the concept of “process” exists in all programming languages insofar all programs in all languages are supposed to be run, the concrete pictures here are <strong>more specific</strong> for the current setting in SICP. The visualizations rely on the so-called <strong>substitution model</strong>. That’s an “explanation” of the behavior of a process where applying a procedures to values means <strong>substituting</strong> the formal parameters by the actual parameters (and then continue from there). The model as presented here not only relies on replacing formal parameters by the actual parameters. Additionally, it’s required that the arguments are evaluated first, i.e., the arguments are already <strong>values</strong>. This strategy thus corresponds to what is also known as <strong>call-by-value</strong>, one important, arguably the most important <strong>parameter passing</strong> mechanism for programming languages.</p>

<p>Using <strong>substitution</strong> as explanation of what happens when calling a function is also not unique for Scheme, one can use that also for other programming languages. But explaining program behavior via substitution is rarely done, as it works only in a purely functional setting, and most languages simply are not purely functional. Indeed, as soon as we introduce side-effects and things like <code class="language-plaintext highlighter-rouge">set!</code> in week 6, substitution as evaluation mechanism also breaks down for Scheme and has to be replaced by something more complex. Thus, it’s particular for the section <strong>here</strong> to use the substitution model when discussing the behavior of the processes.</p>

<p>The <strong>intention</strong> of the discussion and visualization is to give an impression of the <strong>memory usage</strong> (for instance comparing iterative vs. recursive versions of factorial). The illustration uses a sequence of S-expressions that evolves with substitutions (because that’s what we have seen so far). But even later, when we have abandoned the substitution model (or in other languages), the message that iterative processes (or loops) have a constant memory footprint, whereas recursive ones have a growing memory usage (also called the <strong>stack</strong>…) still holds true, independent from any visualization or model.</p>

<p>One could and probably should be more precise and saying that a process is a piece of <strong>sequential</strong> code under execution, at least in standard terminology. If one starts considering concurrency or parallelism, everything gets more complex. In the lecture, side-effects are presented as a drastic departure from the functional setting. But the departure would be only really radical, when introducing <strong>concurrency</strong> (and the terminology of <strong>process</strong> would need much more elaboration and would have a wider range of meanings). Concurrency and parallelism is an immensely large field in its own and Scheme is not the language that comes first to one’s mind when talking about concurrency and parallelism. Though some Scheme variations support parallelism and concurrent programming, and functional languages hold the promise to be easily be parallelized. The lecture will only touch upon concurrency and parallelism in the most superficial way, and also in this text, we cannot go deeper and for instance discuss the word <strong>process</strong> in a concurrent or parallel setting. For us, being concurrent or parallel as the alternative is not even on the screen, so we don’t even much mention that we are dealing sequential programs (though we do), and should a Scheme program be internally be executed in parallel, so the internal parallel evaluation would be invisible to us except that it may run faster.</p>

<h1 id="procedures-and-functions">Procedures and functions</h1>

<p>SICP uses the words procedures and functions in a clear way and consistently (which is a good thing, especially for a textbook). So things are pretty clear on that front (within SICP). Functions are meant in a mathematical way, whereas procedures consist of Scheme code (using <code class="language-plaintext highlighter-rouge">lambda</code> and often using <code class="language-plaintext highlighter-rouge">define</code> if one wants to give a name to a procedure). As one of the first examples in the lecture, we had the factorial. The mathematical function is written conventionally with an exclamation mark $!$ whereas the procedure, the corresponding Scheme code, was called <code class="language-plaintext highlighter-rouge">fac</code>. Actually we had 2 procedures, one that was linear-recursive and one tail-recursive, both calculating the same function.</p>

<p>Since those two concepts are closely related, and since the whole thing is not really confusing, one sometimes of course relaxes a bit and says that <code class="language-plaintext highlighter-rouge">fac</code> is a function, namely the factorial function instead of saying <code class="language-plaintext highlighter-rouge">fac</code> is a Scheme variable giving a name to a procedure that represents an entity that is known in mathematics as the factorial function…</p>

<p>Of course, since functions as mathematical concept have <strong>no side effects</strong>, one can have procedures that do not represent mathematical functions, namely those which are not purely functional. Side-effects, for instance via <code class="language-plaintext highlighter-rouge">set!</code> in Scheme, is one way of breaking with pure functions. Another one would be <strong>non-determinism</strong>, for instance, functions that return output influenced by <strong>randomness</strong>. The procedure <code class="language-plaintext highlighter-rouge">random</code>, built-in in many Scheme dialects (though not in R5RS) is an example. Such a procedure is not purely functional, but has no side-effects either. <strong>Referential transparency</strong>, which is a characteristic property of a purely functional setting, does not hold for procedures like <code class="language-plaintext highlighter-rouge">random</code>. Side remark: it’s correct that a procedure like <code class="language-plaintext highlighter-rouge">random</code> breaks referential transparency and has no side-effects. To be more precise, it has no side-effects visible to the outside, to the user of <code class="language-plaintext highlighter-rouge">random</code>. Often random-number generators, when realized in software, generate not real random numbers, but so-called <strong>pseudo random numbers</strong>, numbers that looks random, but in fact really are not. A possible implementation might well rely on an internal state which is changed after each call to <code class="language-plaintext highlighter-rouge">random</code>, so, programmed that way, the procedure would internally make use to commands like <code class="language-plaintext highlighter-rouge">set!</code>, only that this is encapsulated (like the internal state of our bank-account examples). If realized in that way, the use of <code class="language-plaintext highlighter-rouge">set!</code> is another piece of evidence why <code class="language-plaintext highlighter-rouge">random</code> is not a mathematical function.</p>

<p>Clear as issue of functions vs. procedures is inside SICP, outside of the book and in other programming languages, the words are used often slightly differently, and one may stumble upon two other interpretations, themselves also slightly different. They don’t talk about functions in a mathematical sense at all, they focus on procedures or functions as programming constructions. One common interpretation is that procedures have <strong>no return value</strong>, and functions have a <strong>return value</strong>. Alternatively, one may find definitions that say functions don’t have <strong>side effects</strong>, procedures have. The latter is in line with our definition, because without side-effects, a procedure behaves like a mathematical function.</p>

<p>Both alternative definitions are slightly different, but hang together. If one has a procedure that does not return a value, then, to be useful at all, it will have side-effects (note that I/O or interacting with the environment count as side-effect). Analogously, if a procedures is not allowed to have side effects, it need to return a value. The only situation where the two definitions disagree is for procedures with side-effects <strong>and</strong> return values. One “definition” would call it a function, because of the returned value, the other definition would call it a procedure, because of its side-effect.</p>

<p>All is pretty simple (and uninteresting). This terminology sometimes are not (just) refer to concepts, but to actual language constructs. For instance, the slighted dated language Pascal uses <code class="language-plaintext highlighter-rouge">procedure</code> and <code class="language-plaintext highlighter-rouge">function</code> as keywords. So one could have</p>

<div class="language-pascal highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">procedure</span> <span class="n">Hello</span><span class="p">;</span>
  <span class="k">begin</span>
     <span class="n">ShowMessage</span> <span class="p">(</span><span class="s">'Hello world!'</span><span class="p">);</span>
  <span class="k">end</span><span class="p">;</span>

  <span class="k">function</span> <span class="kt">Double</span> <span class="p">(</span><span class="k">Value</span><span class="p">:</span> <span class="kt">Integer</span><span class="p">)</span> <span class="p">:</span> <span class="kt">Integer</span><span class="p">;</span>
  <span class="k">begin</span>
     <span class="kt">Double</span> <span class="p">:=</span> <span class="k">Value</span> <span class="p">*</span> <span class="m">2</span><span class="p">;</span>
  <span class="k">end</span><span class="p">;</span>
</code></pre></div></div>

<p>Most languages don’t feel the need to introduce different language level constructs or keywords to make a distinction on the programming language level. C, actually, at least the C standard, does not even talk about procedures, everything procedural is a function (with or without side-effect, with or without value). And object-oriented languages mostly call their “procedural” mechanism <strong>method</strong> (though methods often have some extra features over procedures).</p>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="procedure" /><category term="process" /><category term="function" /><summary type="html"><![CDATA[and functions too]]></summary></entry><entry><title type="html">Recursion, primitive or otherwise</title><link href="/functionalprogramming/2023/09/13/ackermann.html" rel="alternate" type="text/html" title="Recursion, primitive or otherwise" /><published>2023-09-13T00:00:00+02:00</published><updated>2023-09-13T00:00:00+02:00</updated><id>/functionalprogramming/2023/09/13/ackermann</id><content type="html" xml:base="/functionalprogramming/2023/09/13/ackermann.html"><![CDATA[<p>The SICP textbook shows in <strong>Exercise 1.10</strong> a famous function known as <strong>Ackermann’s function</strong>. Actually the code there shows one version of that function; there are minor variations of it, all doing basically the same, and all known as Ackermann function. The exercise is not on the list of exercises officially discussed in the group sessions, but perhaps you have stumbled upon it or the group teacher discusses it.</p>

<p>As said, the function is very well known, and it’s always discussed in connection with a concept called primitive recursion (and also that is not on the pensum of the lecture). So if one reads about primitive recursion, invariably the Ackermann function is mentioned and if the Ackermann function is discussed, then it’s discussed in connection with primitive recursion, namely pointing out that Ackermann’s function is not primitive recursive. Actually, Exercise 1.10 in SICP is an exception to that rule, it gives the definition of the function and asks to observe how it behaves but does not mention primitive recursion.</p>

<h1 id="primitive-recursion">Primitive recursion</h1>

<p>Ackermann’s function is the first and most prominent example of a terminating function which is not primitive recursive. That is largely the reason why it is famous. It’s also known as example for a function that grows extremely fast (that can be observed by playing around with it in Exercise 1.10). Both facts hang together; abstractly speaking, it grows too fast for any possible primitive-recursive function, while still terminating. The function is not famous for being practically useful. Also for that it grows too fast.</p>

<p>So if one has ever heard of the Ackermann function at all, it’s probably exactly for that: it’s <strong>“the”</strong> example of a function that is not primitive recursive. Also googling around in the internet, starting maybe at Wikipedia and at various different other pages that offer wisdom and answers on various questions, will confirm that. You can look for questions like “What is an example of a total function that is not primitive recursive?” (answer “Ackermann”) or “what’s the Ackermann function” (answer: an example for a non-primitive-recursive function), and on and on.</p>

<p>Alright, got it, Ackermann is not primitive recursive.</p>

<div class="org-center">
<p>
<b>But that's actually not true!</b>
</p>
</div>

<p>Or maybe I should be more modest. It’s true under only under assumptions taken for granted and left often unmentioned. It’s an assumption that maybe never even crosses the mind of people who just “know” that Ackermann is not primitive-recursive and people who write webpages explaining Ackermann, that in fact there <strong>is</strong> a restriction.</p>

<p>Participants of a course on functional programming, however, may not suffer from or at least should not suffer from that blind spot. What unspoken restriction are we talking about? I come to that in a moment, but before that, we need at least sketch what is actually meant by primitive recursion.</p>

<h3 id="primitive-recursive-functions">Primitive recursive functions</h3>

<p>General <strong>recursion</strong> is ubiquitous in the lecture, most functions halfway interesting use recursion. Primitive recursive functions are a restricted class of recursive functions. We don’t bother to give a precise definition of the concept; it’s easy to find it explained on the internet.</p>

<p>You will remember that SICP distinguishes between recursive procedures and recursive (resp. iterative) <em>processes</em>, where processes refers to what happens at run-time. Let’s focus on what the book calls “procedures”, the code representation, not the processes.</p>

<p>A recursive procedure is one that calls itself in its body. There is also indirect or mutual recursion, which is a situation where two or more procedures call each other; in software engineering circles that’s also sometimes called a “call-back” situation. Never mind. There are no restrictions on how procedures can recursively call themselves (or each other). In other words, Scheme and Lisp (and most other modern languages) support recursion in its general form, unrestricted.</p>

<p>One can use recursion to easily come up with functions that don’t terminate. The simplest example is the one from <strong>Exercise 1.5</strong>, which does in fact nothing else than recursively calling itself (and thus will never terminate):</p>

<div class="language-lisp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="nv">define</span> <span class="p">(</span><span class="nv">p</span><span class="p">)</span> <span class="p">(</span><span class="nv">p</span><span class="p">))</span>
</code></pre></div></div>

<p>One can then study restrictions on the use of recursion. One example is known as <strong>tail recursion</strong>. The book and the lecture uses that term in connection with the interpreter, stating that the scheme interpreter is an example of a <strong>tail recursive interpreter</strong>. More conventionally, one calls functions or procedures <strong>tail recursive</strong> and that characterizes functions, procedures, methods etc. which call themselves only “`at the end” of their body. In the terminology of SICP, that leads to an <em>iterative process</em>, not a <em>recursive process</em> (at least in an interpreter that knows how to deal with it adequately and efficiently).</p>

<p>So, a tail-recursive procedure is a restricted form of a recursive procedure.</p>

<p>But now to the restriction on recursion called <strong>primitive</strong>. The exact definition of primitive recursive functions involves fixing allowed elementary constructs, and projections and other details. The core of the concept, however, is the way recursion itself is allowed. It can be roughly stated as</p>

<blockquote>
  <p>A function can call itself recursively, but only on smaller arguments.</p>
</blockquote>

<p>Instead of giving the formal definition of the primitive recursion operator, we give a feeling what’s allowed and what’s not allowed by small examples. Primitive recursive functions are classically defined as functions on <strong>natural numbers</strong> as arguments and as return value. For that, being smaller is pretty obvious. Let’s look at the following function <code class="language-plaintext highlighter-rouge">f</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(define (f x y)
  (if (= x y) y
      (+ (f (+ x 1) y) 1)))

</code></pre></div></div>

<p>The function is supposed to take 2 natural numbers as argument. Additionally, let’s assume the argument for <code class="language-plaintext highlighter-rouge">x</code> is smaller or equal than <code class="language-plaintext highlighter-rouge">y</code>. Otherwise the corresponding process would not terminate. That’s a minor point, we can of course easily add a couple of lines, checking first whether the assumption is true, and if not, doing analogous calculation to cover also that situation, making it terminating for arbitrary natural numbers. But that’s not central to the discussion here.</p>

<p>Now, <code class="language-plaintext highlighter-rouge">f</code> is recursive, calling itself (and it’s not tail-recursive). Now, is the function primitive-recursive? The definition of <code class="language-plaintext highlighter-rouge">(f x y)</code> calls itself with <code class="language-plaintext highlighter-rouge">(f (+ x 1) y)</code> and that is <strong>forbidden</strong> in primitive recursive schemas. So does that mean the function is not primitive recursive?</p>

<p>Not so fast. The way it’s defined is certainly not the primitive-recursive way But in the same way, that one may transform non-tail-recursive procedure definitions into tail-recursive ones (the lecture had examples for that), one may reformulate sometimes non-primitive-recursive definitions so that they fit the schema. What function is it anyway, given above? It’s easy enough, it calculates <code class="language-plaintext highlighter-rouge">2y - x</code> (for <code class="language-plaintext highlighter-rouge">x &lt;= y</code>).</p>

<p>It turns out that this function indeed is primitive-recursive, in that one can easily define it using primitive recursion schemas. Indeed, it’s straightforward since one can define multiplication and addition and minus easily via primitive recursion. Defining the calculation <code class="language-plaintext highlighter-rouge">2y-x</code> this way seems more natural than the slightly weird recursive definition where <code class="language-plaintext highlighter-rouge">f</code> calls itself on <code class="language-plaintext highlighter-rouge">(+ n 1)</code>, but the definition was given to illustrate what is <em>not</em> allowed.</p>

<p>To illustrate what <em>is</em> allowed, let’s sketch how addition of two natural numbers can be defined with primitive recursion. Actually, it corresponds to the most straightforward definition of addition (assuming that the successor function is given as a more basic operation, here written as <code class="language-plaintext highlighter-rouge">+1</code>. So <code class="language-plaintext highlighter-rouge">x +1</code> is not meant as using binary addition on <code class="language-plaintext highlighter-rouge">x</code> and 1 as arguments, but calculating the successor of <code class="language-plaintext highlighter-rouge">x</code>. We also use infix notation and equations, not Lisp-like prefix and code, though one easily could).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   0   + y = 0
(x +1) + y = (x + y) +1
</code></pre></div></div>

<p>The primitive recursion schema generally specifies a <em>base case</em> (the first line in the above example) and an <em>induction</em> case (the second line). In the case of addition, to define <code class="language-plaintext highlighter-rouge">(x +1) + y</code>, the recursion scheme can use on the right-hand side of the equation a function <code class="language-plaintext highlighter-rouge">h</code> that takes three arguments, and allowed as arguments are <code class="language-plaintext highlighter-rouge">x</code> <code class="language-plaintext highlighter-rouge">y</code>, and <code class="language-plaintext highlighter-rouge">(x + y)</code>. Besides it could rely on earlier defined functions and some primitive operations. In our very simple example, the <code class="language-plaintext highlighter-rouge">x</code> and <code class="language-plaintext highlighter-rouge">y</code> are not needed in the construction, <code class="language-plaintext highlighter-rouge">x + y</code> is the only relevant part and the successor function <code class="language-plaintext highlighter-rouge">+1</code> is built-in. (NB: to avoid confusion: the values of <code class="language-plaintext highlighter-rouge">x</code> and <code class="language-plaintext highlighter-rouge">y</code> are not needed individually and directly as argument to the function <code class="language-plaintext highlighter-rouge">h</code>, but of course they are needed indirectly in that their sum <code class="language-plaintext highlighter-rouge">x + y</code> is used).</p>

<p>So addition is defined recursively in that the definition calls itself, and under the restriction that for defining the outcome for <code class="language-plaintext highlighter-rouge">x+1</code> in the induction case, only <code class="language-plaintext highlighter-rouge">x+y</code> is used, not an arbitrary recursive call to plus.</p>

<p>The question then is:</p>

<blockquote>
  <p>Are all recursive functions also representable by primitive recursion. Or is being primitive recursive a restriction?</p>
</blockquote>

<p>The answer is <strong>yes</strong>, it’s a restriction for sure. All primitive recursive functions terminate, which is a consequence of the fact that the recursion calls the function on a smaller argument. On the other hand, general recursion easily allows non-terminating procedures. Earlier in this post, there was a minimal example for that.</p>

<h3 id="why-is-ackermann-not-primitive-recursive-in-the-standard-set-up">Why is Ackermann not primitive recursive (in the standard set-up)?</h3>

<p>So far so good. We got a feeling that being primitive is a restriction on general recursion. To see that the Ackermann function is not primitive recursive is not obvious. Note that it’s not good enough to observe that its definition does not follow the required primitive-recursive schema: One has to make the argument that it cannot somehow be written up in a different way that fits the scheme.</p>

<p>Generally speaking, the Ackermann function is not primitive-recursive as it “grows too fast”. We don’t provide the argument formally, but the idea is quite simple. Looking at the primitive recursive schema sketched above, it has the feel of an <strong>iterative loop</strong> with a fixed <strong>bound</strong>, like <code class="language-plaintext highlighter-rouge">for i = 0 to n do ...</code>. Programming with for-loops with a fixed bound results in terminating programs, analogous to the fact that all primitive-recursive programs are terming. That’s in contrast to programs using general “while” loop, resp. programs using general recursion.</p>

<p>A primitive recursive definition builds a new function using the primitive recursion schema corresponding to a for-loop iteration and using earlier defined primitive recursive functions as building block, which themselves are iterative schemes. That corresponds to a stack of nested iteration loops.</p>

<p>For illustration: as we have seen, addition can be defined using the successor function iteratively. One could continue to define multiplication as iterative addition. And exponentiation as iterated multiplication. SICP shows how that’s done in Scheme, though without mentioning that the recursions and iterations could be classified as “primitive” (see Sections 1.1.3 and 1.1.4)</p>

<p>At any rate, taking the successor function as basic, multiplication can be represented by one loop (or using one primitive recursion scheme), exponentiation using 2 nested loops, and one could continue with iterated exponentiation, and then iterate that, piling up layer after layer of looping in a nested fashion, each layer really adds expressiveness (and the potential of faster growing functions).</p>

<p>So, using only such bounded loops for programming then leads to a <strong>hierarchy</strong> of functions. Those programmable with a nesting depths of at most one (like multiplication), one with a nesting depth of 2 (for example, exponentiation), etc., all programs terminating. It can be shown that this hierarchy is <strong>infinite</strong>. In other words, it’s not that there is some maximal looping depth, after which one does not need further nesting.</p>

<p>But where does Ackermann fit in?</p>

<blockquote>
  <p><strong>Well, that’s the whole point: Ackermann does NOT fit into this looping hierarchy!</strong></p>
</blockquote>

<p>Ackermann’s function comes in different flavors, the one from Exercise 1.10 has 2 arguments and it’s not even the one most commonly found. There are also versions with 3 arguments and for the line of argument here, let’s assume for now we have a 3-argument formulation.</p>

<p>In all formulations, the Ackermann function has one argument that corresponds roughly to the nesting level of iterative loops resp. the amount of primitive-recursive schemes. So <code class="language-plaintext highlighter-rouge">Ack(x,y,1)</code> corresponds to one looping level, and in a properly formulated 3-argument version, <code class="language-plaintext highlighter-rouge">Ack(x,y,1)</code> is <code class="language-plaintext highlighter-rouge">x+y</code> (Wikipedia starts counting at 0 instead of 1, but never mind). Continuing like that, <code class="language-plaintext highlighter-rouge">Ack(x,y,2)</code> is exponentiation <code class="language-plaintext highlighter-rouge">exp(x, y)</code> etc. This is the <strong>core</strong> of Ackermann’s idea: Define a function where one argument controls the nesting-depth of loops or the level of primitive-recursive schemes.</p>

<p>And that immediately shows that Ackermann cannot be primitive-recursive. If it were, it could be written using a fixed amount of for-loops or a given amount of primitive-recursive schemes. But that’s impossible, since we said, the hierarchy of looping constructs is a real hierarchy, each new level of nesting really adds a new class of functions. Thus, <code class="language-plaintext highlighter-rouge">Ack</code> cannot fit into any specific layer, say level <code class="language-plaintext highlighter-rouge">m</code>, since <code class="language-plaintext highlighter-rouge">Ack(x,y,m+1)</code> would have to live in level <code class="language-plaintext highlighter-rouge">m+1</code>. This was meant when stating at the start of the post, that <code class="language-plaintext highlighter-rouge">Ack</code> grows too fast to be primitive recursive. Each layer limits the order of growth of functions inside that layer, but one argument of the Ackermann function, the one we called <code class="language-plaintext highlighter-rouge">m</code>, controls the growth rate of Ackermann, and since it’s the input of the function, we can make Ackermann’s function growing arbitrarily fast and too fast to fit into any specific layer.</p>

<h3 id="wait-a-second-wasnt-that-a-convincing-argument-that-ackermann-is-not-primitive-recursive">Wait a second, wasn’t that a convincing argument that Ackermann is not primitive recursive?</h3>

<p>Indeed, that was the outline of the standard proof showing that Ackermann is <strong>not</strong> primitive recursive, and hopefully it was convincing. But then, why the claim that Ackermann <strong>can</strong> be captured primitive-recursively, it sure can’t be both ways?</p>

<p>The classic definition and the argument outlined here can be done more formally, exactly specifying what functions to use as primitive building blocks (basically successor and projection functions) and exactly the format of the primitive recursion schema (which we only sketched here on using addition as very simple example). In its standard form, primitive recursion is used to define functions over natural numbers. So functions that take natural numbers as input, and return a natural number. For instance, the Ackermann function <code class="language-plaintext highlighter-rouge">Ack(x,m)</code> is a function of that type. (BTW: Let’s switch back to a two-argument version of Ackermann, but it is not crucial for what’s being said.) So this two argument Ackermann function is of type <code class="language-plaintext highlighter-rouge">Nat * Nat -&gt; Nat</code>, and the functions definable by primitive recursion are of type <code class="language-plaintext highlighter-rouge">Nat * Nat * ... * Nat -&gt; Nat</code> (though as argued, <code class="language-plaintext highlighter-rouge">Ack</code> is not definable by primitive recursion, but it would be at least of a fitting type.)</p>

<p>In this and the whole construction and set-up lies a <strong>restriction</strong>, though one that is seldom drawn attention to. Namely not only that we focus on functions over natural numbers, but that we are dealing with <strong>first-order functions</strong> over natural numbers!</p>

<p>Ah, well, yaah, now that you mention it…</p>

<p>Is this important, are higher-order functions something to consider? Some may consider them as curious anomalies, but in a course about functional programming one sure is comfortable with higher-order functions, they are the bread and butter of functional programming. If embracing higher-order functions, instead of struggling to encode the first-order Ackermann function of type <code class="language-plaintext highlighter-rouge">Nat * Nat -&gt; Nat</code> primitive-recursively (and fail), we can look at Ackermann as a function of type <code class="language-plaintext highlighter-rouge">Nat -&gt; Nat -&gt; Nat</code>. That’s the type of a higher-order function. It’s a function that takes a natural number as argument and returns a function (of type <code class="language-plaintext highlighter-rouge">Nat -&gt; Nat</code>).</p>

<p>With this type, it’s not really the <em>same</em> function: one cannot use one version as drop-in replacement for the other. But it can be seen still as conceptionally the same function. It’s indeed easy to transform any function of type <code class="language-plaintext highlighter-rouge">A * B -&gt; C</code> into a function of type <code class="language-plaintext highlighter-rouge">A -&gt; B -&gt; C</code> and reversely. Actually, it’s not just easy to do the transformation manually, one can also easily write two functions that implement those two transformations. The transformations are known as <strong>currying</strong> and <strong>uncurrying</strong> in honor of <a href="https://en.wikipedia.org/wiki/Haskell_Curry">Haskell Brooks Curry</a> (that’s the name of a person, but of course there are also functional programming languages named after him, Haskell and the lesser known Brooks and Curry. In particular, Brooks is rather marginal. Note that Wikipedia in the article about H. Curry confuses the languages Brooks and Brook).</p>

<p>Now, with this switch of perspective and freeing one’s mind from the unspoken assumption that functions need to be first-order, one can observe:</p>

<blockquote>
  <p>With higher-order functions (and currying), <strong>Ackermann’s function can be defined by primitive recursion</strong>!</p>
</blockquote>

<p>That’s known, but I think it’s fair to say, it’s much lesser known than the common knowledge that “Ackermann is not primitive recursive.”</p>

<p>Let’s wrap it up and simply show the primitive-recursive definition for (a version of) Ackermann. It corresponds to a two argument version of Ackermann, i.e., the uncurried, first-order version would have two arguments. The higher-order version has one argument, but gives back a function. Here it is:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ack(0)       = succ
Ack(m+1)     = Iter(Ack(m))

Iter(f)(0)   = f(1)
Iter(f)(m+1) = f(Iter(f)(m))
</code></pre></div></div>

<h3 id="how-to-do-that-in-scheme">How to do that in Scheme?</h3>

<p>Ackermann can be defined in Scheme using general recursion; Exercise 1.10 in SICP shows a straightforward piece of code for that. Can one encode it primitive-recursively in Scheme, as well? Well, Scheme sure supports <strong>higher-order functions</strong> and it supports <strong>currying</strong> (defining functions using lambda-abstractions). Thus one can quite easily translate the above primitive-recursive definition into Scheme, and that is left as an exercise…</p>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="functional programming" /><category term="IN2040" /><category term="scheme" /><category term="lisp" /><category term="Ackermann" /><category term="currying" /><category term="higher-order functions" /><category term="recursion" /><category term="primitive recursion" /><summary type="html"><![CDATA[A lesser known fact on Ackermann's function, and the power of higher-order functions]]></summary></entry><entry><title type="html">Evaluation strategies</title><link href="/functionalprogramming/2023/09/11/evaluationstrategies.html" rel="alternate" type="text/html" title="Evaluation strategies" /><published>2023-09-11T00:00:00+02:00</published><updated>2023-09-12T00:00:00+02:00</updated><id>/functionalprogramming/2023/09/11/evaluationstrategies</id><content type="html" xml:base="/functionalprogramming/2023/09/11/evaluationstrategies.html"><![CDATA[<p>The post is about <strong>evaluation strategies</strong>. The concept was discussed in the lecture (in week 2) and in SICP. Especially <strong>applicative order</strong> evaluation is covered, as the standard evaluation strategy of scheme. Also, an alternative to that is discussed, namely <strong>normal order</strong> evaluation, and that’s done in connection with things that show up later in the lecture, namely delayed evaluation, streams, and also in the context of the meta-circular evaluator. That’s a scheme interpreter written in scheme and for that it will be discussed what needs to be done to have a non-standard interpreter, namely one that does normal order evaluation.</p>

<blockquote>
  <p>But what’s evaluation anyway? And why does one need a strategy for that?</p>
</blockquote>

<h1 id="values-evaluation-and-execution">Values, evaluation, and execution</h1>

<p><em>Evaluation</em> means to determine the <strong>value</strong> of something (like ``e-<strong>value</strong>-ation”), for us, the value of an expression or of (a part of) a program. The concept of evaluation is eminently functional; in absence of side effects, the value of an expression, in particular of function applications, is independent from when its evaluated, it does not depend on some state (which may change) and so it’s always the same. That property is also known as <strong>referential transparency</strong>. Since the value of an expression is always the same means, an expression represents nothing else than the value, it’s only not yet calculated. Like: <code class="language-plaintext highlighter-rouge">(fac 5)</code> <strong>is</strong> the same as 120, though <code class="language-plaintext highlighter-rouge">(fac 5)</code> is an unevaluated expression, and <code class="language-plaintext highlighter-rouge">120</code> is an evaluated expression (there’s nothing more to do): in ordinary language, we simply say</p>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">(fac 5)</code> <strong>is</strong> 120</p>
</blockquote>

<p>or write as equation</p>

<blockquote>
  <p>5! = 120</p>
</blockquote>

<p>which is shorter than to say 120 is <strong>the value of</strong> <code class="language-plaintext highlighter-rouge">(fac 5)</code> (or of 5!). One can speak of “the” value of an expression, as opposed of “a” value of an expression, as in the absence of nondeterminism (random effects), there cannot be more than one value. Those observations are also underlying the <strong>substitution model</strong> from the lecture. Actually, not just from the lecture: substitution as explanation what happens when executing a program works as long as the program is purely functional, in Scheme or another languages. Substitution means replacement, and if two things are “the same”, one can replace one by the other without that it changes anything. For instance, if one calls a procedure, say <code class="language-plaintext highlighter-rouge">square</code> on <code class="language-plaintext highlighter-rouge">(fac 5)</code> as argument, then it in a way does not matter if the body of <code class="language-plaintext highlighter-rouge">square</code> does its calculating on <code class="language-plaintext highlighter-rouge">(fac 5)</code>, the unevaluated argument expression, or on 120, because both represent the same value (namely 120). And evaluating <code class="language-plaintext highlighter-rouge">(fac 5)</code> before handing over the calculating formal parameter <code class="language-plaintext highlighter-rouge">x</code>. And referential transparency guarantees that it does not matter whether <code class="language-plaintext highlighter-rouge">(fac 5)</code> is being evaluated to 120 beforehand, i.e. before handing it over to <code class="language-plaintext highlighter-rouge">square</code> or handing over <code class="language-plaintext highlighter-rouge">(fac 5)</code> unevaluated, and let it be evaluated when evaluating the body.</p>

<p>Evaluation thus refers to the “execution mechanism” for purely functional programs and expressions. Sometimes one calls evaluation also <em>reduction</em>, like that an unevaluated expression such as <code class="language-plaintext highlighter-rouge">(fac 5)</code> is reduced in a number of steps closer and closer to it ultimate value.</p>

<p>Of course, also imperative programs need to be executed. Those are not primarily run to obtain their value, but for their side effects. Sometimes they don’t even result in a value, but are executed for side effects only.</p>

<p>Later in the lecture, we encounter <code class="language-plaintext highlighter-rouge">set!</code>, which assigns a value to a variable. Assuming that a variable <code class="language-plaintext highlighter-rouge">x</code> is introduced (via <code class="language-plaintext highlighter-rouge">define</code>, via <code class="language-plaintext highlighter-rouge">let</code>, or as formal parameter) and has some value, then <code class="language-plaintext highlighter-rouge">(set! x (+ x 1))</code> <strong>changes</strong> the value or content of <code class="language-plaintext highlighter-rouge">x</code> and replaces it via the value increased by one.</p>

<p>The shown expression <code class="language-plaintext highlighter-rouge">(set! x (+ x 1))</code> in Scheme has <strong>no</strong> value, i.e., it’s executed for its side effect alone, and trying to do something like</p>

<div class="language-lisp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="nb">*</span> <span class="mi">10</span> <span class="p">(</span><span class="nv">set!</span> <span class="nv">x</span> <span class="p">(</span><span class="nb">+</span> <span class="nv">x</span> <span class="mi">1</span><span class="p">)))</span>
</code></pre></div></div>

<p>is meaningless i.e., leads to a runtime error. Being a functional language at its very core, imperative aspects take a bit of a backseat in Scheme/Lisp, and thus the syntax for assignment is specially marked by <code class="language-plaintext highlighter-rouge">!</code> (“bang”), at least in the Scheme dialect we are using, as a warning sign to the programmer, not to expect referential transparency any longer (and, connected to that, the substitution model breaks down, as well).</p>

<p>Of course, there are many languages not centered around procedures, functions etc. but are imperative at their core. Many widely used programming languages, including object-oriented ones, are imperative. Destructive assignment is taken so much for granted in most languages that it often does not even specifically mentioned, like “let’s introduce assignment as destructive operation”, the qualifier “destructive” will not show up in any textbook about Java, maybe not even “imperative”. Also the syntax for assignment is typically less conspicuous. Since imperative operations are just the standard way of programming there’s not need to highlight them with a warning <code class="language-plaintext highlighter-rouge">!</code>, and so <code class="language-plaintext highlighter-rouge">(set! x (+ x 1))</code> is just written as <code class="language-plaintext highlighter-rouge">x = x+1</code>, using <code class="language-plaintext highlighter-rouge">=</code> as symbol for assignment.</p>

<p>As a side remark: Especially disciples of functional programming find it unfortunate that the equality sign <code class="language-plaintext highlighter-rouge">=</code> is (mis-)used in many languages for something that is not equality, but imperative assignment. For example, in C-like languages, <code class="language-plaintext highlighter-rouge">==</code> represents equality, and <code class="language-plaintext highlighter-rouge">=</code> represents assignment, but there are other languages, where assignment may be written <code class="language-plaintext highlighter-rouge">:=</code> or similar.</p>

<p>Back to evaluation and execution: as explained, some programs result in no value but are executed for their side-effects only, some have side effects and result in a value, and some, purely functional ones, have only a value and no side-effects. Details of which constructions gives a value and which not may differ from language to language. For instance, as said, <code class="language-plaintext highlighter-rouge">(set! x (+ x 1))</code> does not result in a value in Scheme (of course the sub-expression <code class="language-plaintext highlighter-rouge">(+ x 1)</code> has a value, depending on the content of <code class="language-plaintext highlighter-rouge">x</code>), but in other languages, for instance Java and C, the corresponding assignment <code class="language-plaintext highlighter-rouge">x = x+1</code> has not only a side-effect, changing <code class="language-plaintext highlighter-rouge">x</code> but <strong>also</strong> results in a value. Consequently, one can use constructions like</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span> <span class="mi">10</span> <span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<p>even though it might not be a recommended coding style.</p>

<h1 id="what-about-strategies">What about strategies?</h1>

<p>Now that we know what evaluation is, determining the value of a (purely functional) piece of code and we know that in the presence of side-effects, one more typically speaks about execution instead (“running the program”). But why do we talk about strategies, especially evaluation strategies?</p>

<p>One speaks of strategies in situations when one faces <strong>choices</strong>, how to proceed, and a strategy is a plan to make those choices. As an example from a different field, given the task to explore a graph, one can do that in different ways, for instance following a strategy of <em>depth-first</em> traversal, or <em>breadth-first</em>, to name the two most prominent strategies. The depth-first strategy, after exploring one edge , faces the choice how to proceed: to explore subsequent edges first, or explore alternative, “sibling” edges first. Depth-first traversal consistently targets the subsequent edges first.</p>

<p>For evaluation, let’s look at a simple example, like</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(6 + 4) - (5 * 2)
</code></pre></div></div>

<p>or</p>

<div class="language-lisp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="nb">-</span> <span class="p">(</span><span class="nb">+</span> <span class="mi">6</span> <span class="mi">4</span><span class="p">)</span> <span class="p">(</span><span class="nb">*</span> <span class="mi">5</span> <span class="mi">2</span><span class="p">))</span>
</code></pre></div></div>

<p>in Scheme notation. The value of the expression obviously is 0, and it’s easy enough to calculate, i.e, easy enough to evaluate. However, thinking of the evaluation as a step-by-step process, one has a choice to either calculate <code class="language-plaintext highlighter-rouge">6 + 4</code> first and <code class="language-plaintext highlighter-rouge">5 * 2</code> afterwards (and then building the difference), or the other way around. Actually, if one had one interpreter of compiler using parallelism, one could even have the left and the right sub-expression evaluated <strong>in parallel</strong> (something we don’t really touch upon in the lecture)</p>

<h2 id="but-does-it-matter">But does it matter?</h2>

<p>That’s a legitimate question, and the answer is: yes and no. Looking at the above simple numeric expression, the outcome is 0, independent of whether one calculates <code class="language-plaintext highlighter-rouge">6 + 4</code> before <code class="language-plaintext highlighter-rouge">5 * 2</code>, or the other way around. That’s what referential transparency is about: the value of, for instance <code class="language-plaintext highlighter-rouge">6 + 4</code>, namely 10, is independent from whether it’s calculated before <code class="language-plaintext highlighter-rouge">5 * 2</code> or afterward (or in parallel …), so in that sense the evaluation strategy or order does not matter. Of course, an interpreter will choose typically a particular order, like evaluating expressions like the one shown from left to right. Or a compiler realizes the same evaluation order, generating (machine) code that calculates the result of the left sub-expression before it calculates that of the one on the right (and before calculating the end result), since it has to calculate them in <em>some</em> order (if not parallelizing the task and using some multi-core architecture or similar) .</p>

<p>That was an argument that the evaluation strategy does not matter, at least is such purely functional or mathematical expressions, but actually the numerical example does not even touch on the two strategies mentioned above, applicative order vs. normal order. The reason being that the example does not really uses procedures, at least not user-defined ones, but calls only primitive procedures or operations, like <code class="language-plaintext highlighter-rouge">+</code> that do whatever needs to be done, without that one knows how they do it or how their procedure body looks like. Perhaps an operation using <code class="language-plaintext highlighter-rouge">+</code> is not even evaluated inside Scheme or the programming language , but handed over ultimately to some arithmetic hardware.</p>

<p>As said, strategy is about making choices, and the “evaluate subexpressions or arguments to a procedure from left to right” is a “strategic” choice that was not even mentioned in the lecture. Simply because it’s not really relevant. A left-to-right version of Scheme (or some other language) is not different from a right-to-left version, at least not in any relevant way that would justify to give it special attention or names like “l-order evaluation” or “r-order evaluation” (and Scheme standards are explicit about that the standard does <strong>not</strong> prescribe an order, so the programmer should not assume one particular one).</p>

<p>Of course, in a language with side-effects, calling a function on arguments, where the argument have side-effects or using expressions where sub-expressions have side effects, it matters insofar as changing the order of evaluating the arguments may well change the outcome. Indeed, some imperative programming language explicitly <em>specify</em> that the order of evaluating the arguments of a procedure is <em>unspecified</em>. In other words, a programmer should not rely on that arguments are evaluated from left to right. For arguments without side-effects it would not matter anyhow, and arguments with side effects are bad coding style anyway. And as said initially, the word “evaluation” is best use for side-effect-free expressions anyway, as only then one is interested exclusively in an expression’s value. With side-effects the word “evaluation” and thus evaluation strategy is not too fitting anyway.</p>

<p>The strategic decision connected to the evaluation order does not regulate what happens if a procedure has multiple arguments (that’s a boring decision, as argued), but</p>

<blockquote>
  <p><strong>when</strong> to evaluate an argument in a procedure application or function call (resp. the arguments of the application, if there are more than one)</p>
</blockquote>

<p>Let’s take the example of the square-function. In Scheme, it’s plausibly defined as</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">square</span> <span class="nv">n</span><span class="p">)</span> <span class="p">(</span><span class="nb">*</span> <span class="nv">n</span> <span class="nv">n</span><span class="p">))</span>
</code></pre></div></div>

<p>a purely functional procedure with one formal parameter. We may apply that to a <code class="language-plaintext highlighter-rouge">(fac 5)</code>, like</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="p">(</span><span class="nf">square</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">))</span>
</code></pre></div></div>

<p>The argument <code class="language-plaintext highlighter-rouge">(fac 5)</code> represents <code class="language-plaintext highlighter-rouge">120</code> its only not evaluated yet. One strategic decision is, that when applying a function to an unevaluated argument, one needs to evaluate the argument first, and evaluate the body afterwards, with the formal parameter replaced (= <strong>substituted</strong>) by the value. In the above example, the argument evaluates, as said, to <code class="language-plaintext highlighter-rouge">120</code> and replacing <code class="language-plaintext highlighter-rouge">n</code> by that value in the body of <code class="language-plaintext highlighter-rouge">square</code> yields</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="nb">*</span> <span class="mi">120</span> <span class="mi">120</span><span class="p">)</span>
</code></pre></div></div>

<p>That’s not yet evaluated, and requires one multiplication to reach the corresponding value <code class="language-plaintext highlighter-rouge">14400</code>.</p>

<p>That’s how <strong>applicative order</strong> chooses to handle arguments in an application, namely evaluate them first. Alternatively, one can hand over the argument <code class="language-plaintext highlighter-rouge">(fac 5)</code> unevaluated, i.e. substituting the formal parameter in the body by <code class="language-plaintext highlighter-rouge">(fac 5)</code>, yielding</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="nb">*</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">)</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">))</span>
</code></pre></div></div>

<p>That requires a number of evaluation or reduction steps, one needs to calculate <code class="language-plaintext highlighter-rouge">(fac 5)</code>, actually one needs to calculate it two times, before <code class="language-plaintext highlighter-rouge">*</code> can do its thing. To leave unevaluated arguments unevaluated, but hands them over as is, that’s <strong>normal order</strong> evaluation</p>

<p>Note that that last step in the normal order evaluation example assumes that <code class="language-plaintext highlighter-rouge">*</code> is not a standard procedure, since the arguments <code class="language-plaintext highlighter-rouge">(fac 5)</code> are evaluated before being multiplied. While <code class="language-plaintext highlighter-rouge">square</code> in the example illustrates normal order evaluation, the multiplication is assumed to be built-in and is assumed to multiply numbers, i.e., numeric <strong>values</strong>, not unevaluated numeric expressions. We could alternatively assume that multiplication is not built-in, for instance implemented by a procedure <code class="language-plaintext highlighter-rouge">multiply</code> as follows (for simplicity, it works for non-negative arguments <code class="language-plaintext highlighter-rouge">n</code> only):</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">multiply</span> <span class="nv">n</span> <span class="nv">m</span><span class="p">)</span>
  <span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="nv">n</span> <span class="mi">0</span><span class="p">)</span>
      <span class="mi">0</span>
      <span class="p">(</span><span class="nb">+</span> <span class="nv">m</span> <span class="p">(</span><span class="nf">multiply</span> <span class="p">(</span><span class="nb">-</span> <span class="nv">n</span> <span class="mi">1</span><span class="p">)</span> <span class="nv">m</span><span class="p">))))</span>
</code></pre></div></div>

<p>With that, <code class="language-plaintext highlighter-rouge">square</code> would be defined by <code class="language-plaintext highlighter-rouge">(define (square n) (multiply n n))</code> and calling <code class="language-plaintext highlighter-rouge">(square (fac 5))</code> leads with applicative order to</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="nf">multiply</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">)</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">))</span>
</code></pre></div></div>

<p>which in turn leads to</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">if</span> <span class="p">(</span><span class="nb">=</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">)</span> <span class="mi">0</span><span class="p">)</span>
    <span class="mi">0</span>
    <span class="p">(</span><span class="nb">+</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">)</span> <span class="p">(</span><span class="nf">multiply</span> <span class="p">(</span><span class="nb">-</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">)</span> <span class="mi">1</span><span class="p">)</span> <span class="p">(</span><span class="nf">fac</span> <span class="mi">5</span><span class="p">))))</span>
</code></pre></div></div>

<p>One could continue from here, doing further steps. It would require to remember that <code class="language-plaintext highlighter-rouge">if</code> is a special form, not a standard procedure, and thus the rules of applicative or normal order don’t apply in their pure form. If we did the same for <code class="language-plaintext highlighter-rouge">+</code> as we did for <code class="language-plaintext highlighter-rouge">*</code> namely redefining it maybe calling it <code class="language-plaintext highlighter-rouge">plus</code>, the evaluation would continue substituting unevaluated expressions to <code class="language-plaintext highlighter-rouge">plus</code> and the other functions. But I won’t do a further exploration of the normal order evaluation process on the example here, coming back to the initial question: AO or NO, does it matter?</p>

<p>In some way, no, it does not matter. Like in the example before, where left-to-right or right-to-left evaluation of sub-expressions did not matter, also for the strategic choice between AO vs NO in the example <code class="language-plaintext highlighter-rouge">(square (fac 5))</code> does not matter, <strong>as far as the resulting value is concerned</strong>, namely <code class="language-plaintext highlighter-rouge">14400</code>. That’s a general observation for purely functional programs: if the program results in a value under AO and under NO, it’s the same value.</p>

<p>In other ways, the choice between AO and NO does indeed matter! The end value may be the same, but the two strategies make different choices how to get there and that could mean, some strategy may get there <strong>quicker</strong>. The <code class="language-plaintext highlighter-rouge">square</code> example is a good illustration of that. It multiplies in its body <code class="language-plaintext highlighter-rouge">(* n n)</code> the argument <code class="language-plaintext highlighter-rouge">n</code> with itself. If, following NO, one hands over an unevaluated expression, like <code class="language-plaintext highlighter-rouge">(fac 5)</code> it means that <code class="language-plaintext highlighter-rouge">(fac 5)</code> needs to be evaluated (at least) two times, maybe more, if one uses a self-made <code class="language-plaintext highlighter-rouge">multiply</code> instead of the built-in <code class="language-plaintext highlighter-rouge">*</code>. For NO, the argument is evaluated only once, namely before handing it over to the caller. To avoid the potential performance penalty of repeatedly evaluated an expression, one could of course use <strong>memoization</strong> and the combination of NO and memoization is called <strong>lazy evaluation</strong>. Memoization can be used with AO as well, but it’s less urgent there, and there seems no specific word for that combination.</p>

<p>Of course, evaluating an argument only later, when unavoidable, can also lead to a situation that an argument is not evaluated at all under NO, whereas AO insists on evaluating it even if it turns out not being needed. As an example, take the following procedure that takes two arguments but returning only the first.</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">first</span> <span class="nv">x</span> <span class="nv">y</span><span class="p">)</span> <span class="nv">x</span><span class="p">)</span>
</code></pre></div></div>

<p>If we apply that to 2 numeric expressions, say <code class="language-plaintext highlighter-rouge">42</code> and <code class="language-plaintext highlighter-rouge">(/ 10 0)</code>, then AO will crash with a division-by-zero error or numerical overflow, whereas NO gives back <code class="language-plaintext highlighter-rouge">42</code> without crashing as the crashing division is never evaluated.</p>

<p>Of course, one could make the argument that <code class="language-plaintext highlighter-rouge">(/ 10 0)</code> is not a numerical expression, at least not a proper one, insofar that it does <strong>not evaluate</strong> to some value, it raises an error and potentially derails the overall evaluation. Actually, one can make the argument, that what happens when <code class="language-plaintext highlighter-rouge">(/ 10 0)</code>, namely raising an exception, is <strong>not a purely functional behavior</strong>, and the “result”, the exception, is not a value, but a <strong>side-effect</strong>. Taking that view would basically say that it’s not a good example for distinguishing AO vs NO in the substitution model and for purely functional programs.</p>

<p>Fair enough, but the next example is harder to argue away. Instead of raising an error like division-by-zero, there are other programs that don’t yield a value. That’s programs that <strong>do not terminate</strong>. The simplest one in Scheme is probably a procedure without parameters that simply calls itself:</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="k">define</span> <span class="p">(</span><span class="nf">infiniteloop</span><span class="p">)</span>  <span class="p">(</span><span class="nf">infiniteloop</span><span class="p">))</span>
  <span class="p">(</span><span class="nf">infiniteloop</span><span class="p">)</span>         <span class="c1">;; this never terminates</span>
</code></pre></div></div>

<p>It hard to argue that this should not be a purely functional program, it does not change any state with things like <code class="language-plaintext highlighter-rouge">set!</code>, it does not produces output like with <code class="language-plaintext highlighter-rouge">display</code>, it does not crash or raise an exception. It simply keeps on evaluating without ever producing a value. If we use the procedure <code class="language-plaintext highlighter-rouge">first</code> from above with the infinite-loop program as its second argument</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="nf">first</span> <span class="mi">42</span>   <span class="p">(</span><span class="nf">infiniteloop</span><span class="p">))</span>
</code></pre></div></div>

<p>it will not terminate under AO, but produces <code class="language-plaintext highlighter-rouge">42</code> under NO. That’s clearly an example where AO vs NO makes a difference. In a way it’s just an extreme example for the observation that AO and NO can make a difference in the number of steps it takes to reach at a value. If we had an program that takes an enormous amount of steps to evaluate and used the same set-up, like</p>

<div class="language-scheme highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="p">(</span><span class="nf">first</span> <span class="mi">42</span>   <span class="nv">expr-that-takes-super-long-to-evaluate</span><span class="p">)</span>
</code></pre></div></div>

<p>then NO terminates very quick to produce 42, whereas AP takes super long before it produces 42. In the infinite-loop example, that super-long just means “forever” or infinitely long.</p>

<h2 id="evaluation-strategies-in-imperative-programming-languages">Evaluation strategies in imperative programming languages?</h2>

<p>The discussion about evaluation strategies like AO and NO focused on functional languages, drawing examples mostly from the functional core of Scheme. Well, as explained evaluation is about reducing an expression to obtain its value. That’s an eminently functional way of explaining what happens when a program runs. Imperative programs may not result in a value, or if they yield a value, it’s the side-effects, like state-change, changing the value of variables, that is what primarily happens. Thus, we discussing a “standard” programming language (and most programming languages are imperative at their core), the word “evaluation” is seldom used, and no one speaks of evaluation strategies. A Java program is not evaluated, its run or executed, resp. it compiled mostly to byte-code and then run or executed, resp. interpreted on a virtual machine.</p>

<p>Not only is one much less interested in the resulting value of a program in an imperative, sequential setting, there is also not much room for (evaluation or execution) strategies. A strategy is a plan to resolve choices or alternatives, but in an sequential, imperative program, there is no room for such choices. Often code is arrange in sequences of <strong>statements</strong>, maybe using also loops and conditionals etc. The statements are separated (in many languages) syntactically by <code class="language-plaintext highlighter-rouge">;</code> (semicolon). The semicolon is also called the <strong>sequential composition</strong> operator. And it goes without saying that of course the statements are evaluated one after the other from the beginning to end, leaving no room for an “strategic decisions”. It’s just how a program is executed, from beginning to end, and there’s loops, then of course the running progam starts at the beginning of the loop when reaching the end of the loop (if not exiting).</p>

<p>Note incidentally, that at the current state of the lecture (in week 2) we have not even used commposition in Scheme! In a purely functional language, it somehow makes no sense in explicitly programming to do ``first-this, then that’’. One does not specify the evaluation order, as mostly it does not matter, and where it matters to some extent, with procedure calls, the chosen evaluation strategy fixes the order. In Scheme, AO. Only somewhat later in week 6, when we introduce imperative feature, then there will be a need for sequential composition, and we will introduce the corresponding Scheme syntax: it will not be <code class="language-plaintext highlighter-rouge">;</code>, but, you may guessed it, an S-expression. They keyword is <code class="language-plaintext highlighter-rouge">begin</code>, which you may guessed also that, is a <strong>special form</strong>…</p>

<p>Here is an example of some factorial in C, programmed very non-functional, and also doing input-output (something that we have not touched upon in Scheme).</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span> 
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
  <span class="kt">int</span> <span class="n">c</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">f</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
 
  <span class="n">printf</span><span class="p">(</span><span class="s">"Enter a number to calculate its factorial</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
  <span class="n">scanf</span><span class="p">(</span><span class="s">"%d"</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">n</span><span class="p">);</span>

  <span class="k">for</span> <span class="p">(</span><span class="n">c</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">c</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">;</span> <span class="n">c</span><span class="o">++</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">f</span> <span class="o">*</span> <span class="n">c</span><span class="p">;</span>
 
  <span class="n">printf</span><span class="p">(</span><span class="s">"Factorial of %d = %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">f</span><span class="p">);</span>
 
  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>However, when we said that there are no strategic decisions in an imperative language, like C, to make, that was an <strong>exaggeration</strong>. Also in imperative languages, one can nest expressions (as one commonly does on Scheme). Likewise one of course uses procedure calls, and of course can use procedures. Then the question arises: what is handed over when calling a function or procedure? The answer is often (like in C, Java, and most other languages): it’s a value of the argument expression, so the <strong>parameter passing</strong> mechanism is <strong>call-by-value</strong>. It corresponds to <strong>applicative order evaluation strategy</strong>, though, as said, in imperative languages, one does not much speak about evaluation (and consequently one does not speak about applicative order or normal order, as this refers to evaluation strategies).</p>

<p>So, call-by-value though it corresponds to AO, is not seen as an evaluation strategy, but a decision about <strong>parameter passing</strong>. And one main alternative to call-by-value is <strong>not</strong> something that corresponds to NO, but something called <strong>call-by-reference</strong> (which is never used in connection with Scheme). On the other hand, NO, which corresponds to the core of lazy evaluation, has <strong>no place</strong> in imperative languages. It’s not that it’s impossible to do, but basically imperative side effects and the loss of referential transparency messes things up, so to lazy evaluation unusable (it had been done, and called <strong>call-by-name</strong>, but abandoned as useless). That’s the reason why the only significant programming language based on lazy evaluation is <strong>purely</strong> function (Haskell). Scheme, and most other functional languages support side effects, and therefore <strong>must</strong> do call-by-value resp. applicative order.</p>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="functional programming" /><category term="IN2040" /><category term="scheme" /><category term="lisp" /><category term="evaluation strategy" /><category term="normal-order evaluation strategy" /><category term="applicative-order evaluation strategy" /><category term="referential transparency" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Welcome to Functional programming (IN2040), autumn 2023</title><link href="/functionalprogramming/2023/08/18/fpwelcome-2023.html" rel="alternate" type="text/html" title="Welcome to Functional programming (IN2040), autumn 2023" /><published>2023-08-18T00:00:00+02:00</published><updated>2022-06-18T00:00:00+02:00</updated><id>/functionalprogramming/2023/08/18/fpwelcome-2023</id><content type="html" xml:base="/functionalprogramming/2023/08/18/fpwelcome-2023.html"><![CDATA[<h1 id="about-this-semester">About this semester</h1>

<h3 id="lectures">Lectures</h3>

<p>Corona is over (and let’s hope it won’t come back any time soon). So lectures, will be held the way it used to be, in the lecture hall (Simula@OJD).</p>

<h3 id="youtube">youtube</h3>

<p>One perhaps positive effect of the virus times was that many lectures produced video-ed versions of the presentations, like screencasts or recorded lectures. This lecture as well. We will not make a new version of the videos, there is no reason for doing that (and lot of effort went into it), but we will link in the versions produced mostly 2020, uploaded at youtube.</p>

<h3 id="language">language</h3>

<p>The lecture will be given in Norwegian, at least that’s the plan. Previous round, autumn 2022, actually was my first lecture ever given in Norwegian, so this is the second time. We’ll see how it goes, maybe my Norwegian improved. In these (inofficial) pages, however, I’ll write in English, it takes too much time otherwise.</p>

<h2 id="exercises-and-group-work">Exercises and group work</h2>

<p>The videos are fine as supplementary information and electronic format. Though reading the book and in particular doing the exercises and obligs is central for mastering the material. I like to compare that with learning how to play the guitar. No particular reason for exactly choosing guitars as comparison, except that since some time I try to learn doing that. Of course one can watch and listen to Eric Clapton, <a href="https://www.youtube.com/watch?v=RmdRCywCtbs">Andrés Segovia</a>, or Eddie van Halen on youtube (or whatever your top guitar hero might be), maybe watching the close-ups of the finger plays, or listening to some guitar teacher. All that may be instructive, it may help to correct the way you hold your guitar or place and move your fingers, or you may see new techniques, and it sure will be inspiring and motivating, to see and listen to some master or instructor.</p>

<p>Seing enough youtube and reading enough material, one may be able to convincingly talk about what’s important when playing guitar, describe techniques, using words like a pro (finger picking, leganto, arpeggio, whatever). But a talk about how to play guitar is not a live gig. So <strong>unless one strums the six strings with one’s own fingers</strong>, starting with simple chords, and gradually advancing the level of difficulty, <strong>one will never get far</strong>.</p>

<p>Same here: talking about programs like a pro (tail-recursion, applicative order, higher-order functions, stream-programming, to mention a few topics covered by the lecture…) is not the same as programming . So, doing the exercises is important!</p>

<blockquote>
  <p>Learning is not the product of teaching. Learning is the product of the activity of learners. (John Holt)</p>
</blockquote>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="functional programming" /><category term="IN2040" /><category term="scheme" /><category term="lisp" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Welcome to Functional programming (IN2040), autumn 2022</title><link href="/functionalprogramming/2022/06/17/fpwelcome-2022.html" rel="alternate" type="text/html" title="Welcome to Functional programming (IN2040), autumn 2022" /><published>2022-06-17T00:00:00+02:00</published><updated>2022-06-18T00:00:00+02:00</updated><id>/functionalprogramming/2022/06/17/fpwelcome-2022</id><content type="html" xml:base="/functionalprogramming/2022/06/17/fpwelcome-2022.html"><![CDATA[<h1 id="about-this-semester">About this semester</h1>

<p>After a couple of corona semesters, the forthcoming one seems to be unaffected by any viruses, and things are back to normal. So right now, at the end of the spring semester, we plan for a semester in a standard, non-corona set-up.</p>

<p>We should, however, keep in mind the the virus plague is not over yet and right now, towards end of June, the infection rates go up in many countries throughout Europe. Currently, there seems politically no push towards (re-)introducing restrictions, as the variants responsible for the current rise in incidences are of a ``milder’’ variety. So no cause of alarm, they say.</p>

<p>I suspect, however, not even experts can foresee the future, and they base their prognostications of what will happen next autumn on what had happened last autumn. Still, the rise is disquieting, because at the beginning of this year, experts seems sure, that at least it will be a hassle-free summer, perhaps or probably there might be a next wave in autumn or winter, but in the meantime, we can all forget about viruses. But now the numbers are rising already before the calendaric summer has started.</p>

<p>So we can hope for a normal and relaxed semester, but keep in mind it could turn out otherwise (again).</p>

<h2 id="lectures">Lectures</h2>

<p>Lectures will be held the way it used to be before corona, if someone still remembers, i.e., in the lecture hall.</p>

<h3 id="youtube">youtube</h3>

<p>One perhaps positive effect of the virus times was that many lectures produced video-ed versions of the presentations, like screencasts or recorded lectures. This lecture as well. We will not make a new version of the videos, there is no reason for doing that, but will link in the versions produced mostly 2020, uploaded at youtube.</p>

<h3 id="language">language</h3>

<p>The lecture will be given in Norwegian, at least that’s the plan. It’s actually my first lecture ever given in Norwegian. We have to see how it goes. If it’s incomprehensible, or the pronounciations unbearable, we’ll have to consider alternative solutions. In these (inofficial) pages, however, I’ll write in English, it takes too much time otherwise.</p>

<h2 id="exercises-and-group-work">Exercises and group work</h2>

<p>The videos are a fine supplementary information and format. Though reading the book and in particular doing the exercises is central for mastering the material. I like to compare that with learning to play the guitar. No particular reason for exactly choosing guitars as comparison, except that at the moment and since some time I try to learn doing that. Of course one can watch and listen to Eric Clapton, <a href="https://www.youtube.com/watch?v=RmdRCywCtbs">Andrés Segovia</a>, or Eddie van Halen on youtube (or whatever your top guitar hero might be), maybe watching the close-ups of the finger plays, or listening to some guitar teacher. That may be instructive, watching and reading and listening may help to correct the way you hold your guitar or your fingers, or you may see new techniques, and it sure will be inspiring and motivating, to see and listen to some masters.</p>

<p>But unless one strums the six strings with one’s own fingers, starting with simple chords, and gradually advancing the level of difficulty, one will never get far.</p>

<p>And the same here. Therefore, doing the exercises is important!</p>

<blockquote>
  <p>Learning is not the product of teaching. Learning is the product of the activity of learners. (John Holt)</p>
</blockquote>]]></content><author><name> </name></author><category term="functionalprogramming" /><category term="functional programming" /><category term="IN2040" /><category term="scheme" /><category term="lisp" /><summary type="html"><![CDATA[]]></summary></entry></feed>